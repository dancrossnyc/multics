/****^  ***********************************************************
        *                                                         *
        * Copyright, (C) Honeywell Bull Inc., 1987                *
        *                                                         *
        * Copyright, (C) Honeywell Information Systems Inc., 1982 *
        *                                                         *
        *********************************************************** */
/* format: style2,indcomtxt */
/* use: pl1_macro pc.pl1.pmac  -target l68 */
pc:
     procedure;

/* *	PC -- the utility procedure of pl1 page control.
   *
   *	Last modified (date and reason):
   *
   *      1985-03-28, BIM: assume that all modified pages of synch segments
   *		  are synch held until proven otherwise by page$pwrite.
   *	841220 by Keith Loepere to count dirs pages against its own quota.
   *	840623 by Keith Loepere for nullify entry for bce.
   *	840417 E. A. Ranzenbach to correct page_read zero event problem that caused crashes in the segment mover.
   *      84-01-19 BIM to remove unworkable synch segmove support.
   *      84-01-03 BIM to finish segmove.
   *	831219 by E. N. Kittlitz, for segmove
   *      09/19/83 by E. N. Kittlitz, per UofC SGH, periodically unlock PTL during long flushes.
   *      08/22/83 by E. N. Kittlitz, per UofC GM&SGH, don't hedge-write per-process pages.
   *      10/27/82 by J. Bongiovanni to reset damaged, fm_damaged on truncate
   *               and for synchronized pages
   *      08/17/82 by J. Bongiovanni for scavenger
   *      06/09/82 by J. Bongiovanni to fix shutdown quota problem
   *      03/07/82 by J. Bongiovanni for record stocks
   *      01/23/82 by BIM for truncate_count
   *	12/29/81 by C. Hornig to remove Page Multilevel and fix fencepost error in flush.
   *	08/11/81 by W. Olin Sibert, to fix get_file_map to not report nulled addresses as modified.
   *	   This fix actually provided by Steve Harris, University of Calgary
   *	02/20/81 by W. Olin Sibert, to conditionalize page-multilevel (phase one of ADP conversion)
   *	11/17/80 by ENK for new dtu/dtm calculation
   *	11/06/80 by ENK for loop_up_fms honouring of aste.gtms.
   *	03/16/78 by BSG for phm1, incore null non-reportage.
   *	08/01/77 by Greenberg for badd_types, pc_recover_sst.
   *	05/03/77 by BSG for page$pcleanup
   *	01/27/77 by TVV for non-fatal unprotected addresses
   *	11/01/76 by D. Vinograd to add entry for volume dumper which returns special null addresses
   *	   and does not deposit.
   *	10/31/76 by BSG for truncate_deposit_all entry
   *	05/13/76 by BSG for seg-by-seg PD flush.
   *	04/13/76 by REM for Cleanup Metering
   *	10/11/75 by BSG for fault_time_withdraws
   *	03/04/75 by BSG for new storage system (incl. no pdht).
   *	12/11/74 by BSG for new CME/PTW protocols and new core control.
   *	06/19/74 by BSG for page$pwait and page$cam.
   *	08/21/73 by RBS to put in checks for reused addresses.
   *	08/03/73 by RBS to cause pc$flush to index thru cmes rather than follow threads.
   *	08/10/73 by SHW to use 18 bit device addresses
   *	07/15/73 by RBS to cause pages that are in core to be written to disk by pd_flush_all
   *	10/04/72 by RBS to make page waits go to device control to accomodate bulk store logic
   *	06/06/72 by RBS to modify for follow-on
   *	10/26/71 by RHG to fix move_page_table for pages which are in core when moved
   *	10/07/71 by SHW to add ptwp to pdme (increase entry size to 3 words)
   *	10/05/71 by RHG to initialize pdmap and to skip the first sst.nrecs_pdmap entries in pd_flush_all
   *	09/22/71 by RHG to make null devadds include a ptr for page
   *	09/20/71 by RHG to fix bug in pc$get_file_map which lost all pages of file except first at deactivation
   *	09/03/71 by Steve Webber to make calls to page$withdraw be fixed bin(4), not bit(4)
   *	08/10/71 by Richard H. Gumpertz to add code for page multi-level
*/

	dcl     Astep		 ptr parameter;
	dcl     Copy_Astep		 ptr parameter;
	dcl     File_Mapp		 ptr parameter;
	dcl     Listp		 ptr parameter;
	dcl     Pageno_Listp	 ptr parameter;
	dcl     Deposit_Count	 fixed bin parameter;
	dcl     First_Page		 fixed bin parameter;
	dcl     Last_Page		 fixed bin parameter;
	dcl     N_Pages		 fixed bin parameter;
	dcl     N_In_Core		 fixed bin parameter;
	dcl     Records		 fixed bin parameter;
	dcl     Pvtx		 fixed bin parameter;
	dcl     Vtocx		 fixed bin parameter;
	dcl     Move_Astep		 pointer parameter;
	dcl     Old_Astep		 ptr parameter;
	dcl     New_Astep		 ptr parameter;
	dcl     Code		 fixed bin (35) parameter;
	dcl     New_Vtocx		 fixed bin (17) parameter;
	dcl     New_Pvtx		 fixed bin (17);

	dcl     (records, first_page, last_page, i)
				 fixed bin;
	dcl     ind		 fixed bin (35);
	dcl     temp_ind		 fixed bin (35);
	dcl     pvtx		 fixed bin;
	dcl     dumper		 bit (1);
	dcl     return_pageno	 bit (1) aligned;
	dcl     add_to_dmpr_map	 bit (1);
	dcl     (getfmap_csl, getfmap_np, getfmap_nrec)
				 fixed bin (9);
	dcl     offed_sw		 bit (1);
	dcl     j			 fixed bin;
	dcl     segmove_records_used	 fixed bin;
	dcl     (cmp, ptwp)		 ptr;
	dcl     curtime		 fixed bin (71);
	dcl     n_in_core		 fixed bin (18);
	dcl     n_io_started	 fixed bin;
	dcl     pageno		 fixed bin;
	dcl     (from_core, count)	 bit (1);
	dcl     (old_astep, new_astep, old_ptp, new_ptp, move_ptp)
				 ptr;
	dcl     oldmask		 fixed bin (71);
	dcl     no_deposit_no_return	 bit (1) aligned;
	dcl     tr_count_sw		 bit (1) aligned;
	dcl     segmove_records_needed fixed bin;
	dcl     segmove_records_in_hand
				 fixed bin;
	dcl     segmove_total_records	 fixed bin;
	dcl     code		 fixed bin (35);
	dcl     new_pvtx		 fixed bin;
	dcl     new_vtocx		 fixed bin;
	dcl     move_tries		 fixed bin;

	dcl     1 copy_aste		 like aste aligned;

	dcl     fword		 (0:99) fixed bin based;

	dcl     Address_Array	 (0:255) bit (22) aligned based (Listp);
	dcl     (deposit_list, segmove_deposit_list)
				 (0:255) bit (22) aligned;
	dcl     rfm		 (0:255) bit (22) aligned;
	dcl     1 Devadd_Array	 (0:255) aligned based (Listp),
		2 record_no	 bit (18) unaligned,
		2 add_type	 bit (4) unaligned;
	dcl     Pageno_List		 (0:255) fixed bin aligned based (Pageno_Listp);
	dcl     pageno_list		 (0:255) fixed bin aligned;

	dcl     devadd		 bit (22) unaligned;
	dcl     devadd_record_no	 bit (18) unaligned defined (devadd);
	dcl     devadd_record_no_proper
				 bit (17) defined (devadd) pos (2);
	dcl     devadd_add_type	 bit (4) unaligned defined (devadd) position (19);
	dcl     devadd_null_flag	 bit (1) defined (devadd) position (1);


	dcl     1 devadd_bits	 unal based (addr (devadd_add_type)) like badd_type;


	dcl     cleanup_start_time	 fixed bin (71);	/* Cleanup Metering */

	dcl     error_table_$bad_arg	 fixed bin (35) ext static;
	dcl     error_table_$action_not_performed
				 fixed bin (35) ext static;
	dcl     error_table_$synch_seg_segmove
				 fixed bin (35) external static;
	dcl     dbm_man$set_incr	 entry (fixed bin, fixed bin, fixed bin (35));
	dcl     (
	        lock$lock_fast,
	        lock$unlock_fast
	        )			 entry (pointer);
	dcl     page$cam		 ext entry;
	dcl     page$deposit_list	 entry (fixed bin, ptr, fixed bin, fixed bin, fixed bin, ptr);
	dcl     page$pcleanup	 entry (ptr, fixed bin);
	dcl     page$pread		 entry (ptr, fixed bin, fixed bin (35));
	dcl     page$pwait		 ext entry (fixed bin (35));
	dcl     page$pwrite		 ext entry (ptr, fixed bin);
	dcl     page$withdraw_list	 entry (fixed bin, ptr, fixed bin, fixed bin, fixed bin (35), fixed bin (35));
	dcl     pmut$lock_ptl	 ext entry (fixed bin (71), ptr);
	dcl     pmut$unlock_ptl	 ext entry (fixed bin (71), ptr);
	dcl     pxss$notify		 ext entry (fixed bin);
	dcl     pxss$relinquish_priority
				 ext entry;
	dcl     quotaw$cu_for_pc	 entry (ptr, fixed bin, bit (1) aligned);
	dcl     syserr		 ext entry options (variable);
	dcl     trace		 ext entry options (variable);

	dcl     null_devadd_not_in_core
				 bit (36) aligned internal static options (constant) init ("000000000001"b3);
	dcl     line_of_words	 char (23) internal static options (constant) init ("^w ^w ^w ^w ^w ^w ^w ^w");
	dcl     half_line_of_words	 char (11) defined (line_of_words);

	dcl     (addr, addrel, addwordno, bit, clock, divide, fixed, max, min, null, ptr, rel, size, unspec, wordno)
				 builtin;
%page;
cleanup:
     entry (Astep);					/* Entry to get segment out of core. */
						/* Caller guarantees no access to segment */

/* Note that synchronized pages which are modified and cannot be written yet
   are left in memory. If this happens during shutdown, it is fine. Otherwise,
   the caller must detect this situation and handle it appropriately. It
   can be detected by checking that aste.np is non-zero. */

	sstp = addr (sst_seg$);
	astep = Astep;
	cmp = sst.cmp;				/* get a pointer to the core map */
	cleanup_start_time = clock ();		/* Cleanup Metering */

	sst.cleanup_count = sst.cleanup_count + 1;	/* Cleanup Metering */
	call pmut$lock_ptl (oldmask, ptwp);		/* mask */
	records = 0;
	if pc_trace
	then call trace ("cleanup^-^-astep = ^p", astep);
loopc:
	ptp = addrel (astep, sst.astsize);		/* get a pointer to the page table */
	ind = -1;					/* index of page to wait on */
	do i = 0 to sst.pts (fixed (aste.ptsi, 2)) - 1;	/* loop over all pages in the segment */
	     if atptw.core
	     then do;				/* In core, includes all O/S */

		     if ^ptw.os
		     then do;			/* Not out of service */
			     if ^(ptw.phm | ptw.phm1)
			     then /* Attempt to clean up the page */
				call page$pcleanup (astep, i);
						/* Do it, cam the cache */
						/* He turns off PTW access, SDW'S gone, so no race. */
			     else call page$pwrite (astep, i);
						/* Start a write */
			end;

		     if ptw.os
		     then ind = fixed (rel (ptp), 18);	/* Set wait event */

		end;

	     ptp = addrel (ptp, size (ptw));		/* Next ptw, please */
	end;

	if ind > 0
	then call wait_then_go_to (loopc);

	sst.cleanup_real_time = sst.cleanup_real_time /* Cleanup Metering */ + clock () - cleanup_start_time;
						/* Cleanup Metering */

quit:
	call pmut$unlock_ptl (oldmask, ptwp);		/* unlock and unmask */
	return;
%page;
nullify:
     entry (Astep);					/* Entry to nullify a bce/hardcore segment.
						   Part of disk optimization for bce. */

/* The idea is to mark the pages of the segment unmodified, clean them up
   (to disk) and then mark the disk addresses as null.  This is done just to
   optimize the later filling in of this segment.  We don't guarantee perfection
   in this, but it doesn't matter.  Anyone who calls this ensures that the
   segment is not in use so we don't expect a problem with pages being
   referenced between ptl lockings. */

/* First unmodify the pages.  Note that os pages are not affected, but these
   either aren't yet modified (being read) or will become unmodified (after
   write). */

	sstp = addr (sst_seg$);
	astep = Astep;

	call pmut$lock_ptl (oldmask, ptwp);		/* mask */
	ptp = addrel (astep, sst.astsize);		/* get a pointer to the page table */
	do i = 0 to sst.pts (fixed (aste.ptsi, 2)) - 1;	/* loop over all pages in the segment */
	     if atptw.core
	     then /* In core, includes all O/S */
		if ^ptw.os			/* Not out of service */
		then ptw.phm, ptw.phm1 = "0"b;

	     ptp = addrel (ptp, size (ptw));		/* Next ptw, please */
	end;
	call pmut$unlock_ptl (oldmask, ptwp);		/* unlock and unmask */

	call cleanup (astep);			/* free all memory frame; make into disk addresses */

	call pmut$lock_ptl (oldmask, ptwp);		/* mask */
	ptp = addrel (astep, sst.astsize);		/* get a pointer to the page table */
	do i = 0 to sst.pts (fixed (aste.ptsi, 2)) - 1;	/* loop over all pages in the segment */
	     if atptw.disk
	     then substr (ptw.add, 1, 1) = "1"b;	/* make null */

	     ptp = addrel (ptp, size (ptw));		/* Next ptw, please */
	end;
	call pmut$unlock_ptl (oldmask, ptwp);		/* unlock and unmask */
	return;
%page;
fill_page_table:
     entry (Astep, File_Mapp, N_Pages);


	astep = Astep;				/* Copy args */
	fmp = File_Mapp;
	pvtx = astep -> aste.pvtx;
	last_page = N_Pages - 1;			/* arg is csl */
	sstp = addr (sst_seg$);
	records = 0;

	ptp = addrel (astep, sstp -> sst.astsize);
	do i = 0 to last_page;
	     devadd = file_map.fm (i);		/* No need to lock here */
	     if devadd_null_flag
	     then do;				/* Outside world null address, */
		     devadd_null_flag = "0"b;		/* This is not NULLED, but null. */
		     devadd_add_type = "0000"b;	/* Internal null address representation */
		end;
	     else do;				/* real disk address */
		     devadd_add_type = add_type.disk;	/* Assume protected. */
		     records = records + 1;
		end;
	     ptp -> ptwa_bits (i) = devadd | null_devadd_not_in_core;
						/* save final result in ptw */
	end;


	do i = last_page + 1 to sstp -> sst.pts (fixed (astep -> aste.ptsi, 2)) - 1;
						/* Fill up rest of page table with nulls */
	     ptp -> ptwa_bits (i) = null_devadd_not_in_core;
	     ptp -> mptwa (i).devadd = fill_page_table_null_addr;
	end;
	aste.records = bit (fixed (records, 9), 9);
	if pc_trace
	then do;
		call trace ("fill_page_table^-astep = ^p", astep);
		if last_page <= 4
		then call trace (half_line_of_words, ptp -> fword (0), ptp -> fword (1), ptp -> fword (2),
			ptp -> fword (3));
		else do;
			do i = 0 to last_page by 8;
			     call trace (line_of_words, ptp -> fword (i), ptp -> fword (i + 1),
				ptp -> fword (i + 2), ptp -> fword (i + 3), ptp -> fword (i + 4),
				ptp -> fword (i + 5), ptp -> fword (i + 6), ptp -> fword (i + 7));
			end;
		     end;
	     end;
	return;
%page;
truncate:
     entry (Astep, First_Page);			/* entry to truncate a page table */


	tr_count_sw = "0"b;
	go to truncate_join;

truncate_count:
     entry (Astep, First_Page, N_In_Core);


	tr_count_sw = "1"b;

truncate_join:
	sstp = addr (sst_seg$);			/* get a pointer to the sst */

	astep = Astep;				/* copy args into wired down stack */
	ptp = addrel (astep, sstp -> sst.astsize);
	cmp = sstp -> sst.cmp;			/* and core map pointer */
	first_page = First_Page;
	last_page = sstp -> sst.pts (fixed (astep -> aste.ptsi, 3)) - 1;
						/* get pt end for last page */

	records = 0;
	if pc_trace
	then call trace ("truncate^-^-astep = ^p", astep);

/* the segment has an AST entry -- must clean up page tables and core map */

	call pmut$lock_ptl (oldmask, ptwp);		/* lock and mask */

	if pc_trace
	then do;
		if last_page <= 4
		then call trace (half_line_of_words, ptp -> fword (0), ptp -> fword (1), ptp -> fword (2),
			ptp -> fword (3));
		else do;
			do i = 0 to last_page by 8;
			     call trace (line_of_words, ptp -> fword (i), ptp -> fword (i + 1),
				ptp -> fword (i + 2), ptp -> fword (i + 3), ptp -> fword (i + 4),
				ptp -> fword (i + 5), ptp -> fword (i + 6), ptp -> fword (i + 7));
			end;
		     end;
	     end;
	n_in_core = 0;
retry:
	ind = 0;

	do i = first_page to last_page;		/* loop through all pages going */
	     if ptp -> ptwa (i).os
	     then do;				/* if out of service, must wait for io */
		     ind = fixed (rel (addr (ptp -> ptwa (i))), 18);
						/* get event to wait on */
		     call wait_then_go_to (retry);	/* must go back to top after waiting */
		end;
	     count = "0"b;				/* Assume no truncation */

/* At this point, page is not o/s. If in core, devadd has core address. */

	     from_core = atptwa (i).core;		/* Remember in_coreness */
	     devadd = ptp -> mptwa (i).devadd;		/* pick up the device address */

/* At this point, devadd has disk or null address, unless in core */

	     if from_core
	     then do;				/* Page is in core */
		     n_in_core = n_in_core + 1;
		     cmep = addr (cmp -> cma (ptp -> core_ptwa (i).frame));
						/* Get pointer to cme */
		     devadd = cmep -> cme.devadd;	/* and get the devadd for cleanup */
		     if ptp -> ptwa (i).wired
		     then sstp -> sst.wired = sstp -> sst.wired - 1;
		     call page$pcleanup (astep, i);	/* Fix up data bases, count quota, csl */
		     count = "0"b;			/* page$cleanup did all work */
		end;


/* At this point, page is not in core. devadd has disk, null, or nulled */

	     if devadd_bits.disk
	     then if ^devadd_null_flag		/* if nulling ... */
		then do;
			devadd_null_flag = "1"b;	/* Null the address */
			count = "1"b;
		     end;

	     ptp -> mptwa (i).devadd = devadd;		/* Insert right devadd in ptw */
	     if count
	     then records = records + 1;

	end;
	call loop_up_fms;
	if records ^= 0
	then do;
		astep -> aste.fmchanged = "1"b;	/* Make sure we get an update_vtoce */
		if ^astep -> aste.nqsw
		then if astep -> aste.dirsw
		     then call quotaw$cu_for_pc (astep, -records, "1"b);
		     else if astep -> aste.par_astep
		     then call quotaw$cu_for_pc (ptr (astep, astep -> aste.par_astep), -records, "0"b);
		astep -> aste.records = bit (fixed (fixed (astep -> aste.records, 9) - records, 9), 9);
	     end;

/* Now update the current segment length */

	do i = min (first_page - 1, last_page) to 0 by -1;/* min traps truncate to addr > aste size */
	     devadd = ptp -> mptwa (i).devadd;
	     if ptp -> atptwa (i).core
	     then goto update_csl;
	     if devadd_add_type & add_type.non_null
	     then if ^devadd_null_flag
		then go to update_csl;
	end;
update_csl:
	astep -> aste.csl = bit (fixed (i + 1, 9), 9);

	if first_page = 0
	then do;
		astep -> aste.damaged = "0"b;		/* empty is undamaged */
		astep -> aste.fm_damaged = "0"b;
	     end;

	call page$cam;				/* make sure our work takes */
	call pmut$unlock_ptl (oldmask, ptwp);		/* unlock and unmask */
	if tr_count_sw
	then N_In_Core = n_in_core;			/* return for meter for callers that want. */
	return;
%page;
dumper_get_file_map:
     entry (Astep, Copy_Astep, File_Mapp, Deposit_Count, Listp, Pageno_Listp);
						/* dumper entry for VTOCE update */

	dumper = "1"b;
	goto get_file_map_common;

get_file_map:
     entry (Astep, Copy_Astep, File_Mapp, Deposit_Count, Listp, Pageno_Listp);
						/* entry for VTOC update */


	dumper = "0"b;
get_file_map_common:
	astep = Astep;				/* Copy astep */
	add_to_dmpr_map = "0"b;
	sstp = addr (sst_seg$);			/* get SST base ptr */
	fmp = File_Mapp;
	cmp = sstp -> sst.cmp;			/* get core map ptr */
	last_page = sstp -> sst.pts (fixed (astep -> aste.ptsi, 2)) - 1;
	no_deposit_no_return = (Listp = null) | aste.ddnp;
	getfmap_csl, getfmap_np, getfmap_nrec = 0;	/* Init counters */
	offed_sw = "0"b;				/* Don't need cam */
	return_pageno = (Pageno_Listp ^= null ());

	call pmut$lock_ptl (oldmask, ptwp);		/* Lock the pagetable lock */

	sstp = addr (sst_seg$);
	j = 0;					/* Init deposit index */
	do i = 0 to last_page;			/* Walk the table */
	     ptp = addrel (astep, sstp -> sst.astsize + i);
						/* Get one page tbl ptr */
	     devadd = ptp -> mptw.devadd;		/* Get address from ptw */
	     if devadd_bits.disk
	     then do;				/* Disk addr, could be nulled */
		     if devadd_null_flag & ^no_deposit_no_return
		     then do;			/* put in deposit list */
			     devadd_null_flag = "0"b; /* zero the special internal flag */
			     deposit_list (j) = devadd;
						/* set to give to outside world */
			     if return_pageno
			     then pageno_list (j) = i;

			     j = j + 1;		/* one more depositable address processed */
			     devadd = get_file_map_vt_null_addr;
			     ptp -> mptw.devadd = devadd;
						/* coded null to file map and page table */
			end;
		     else if devadd_null_flag & dumper
		     then devadd = get_file_map_vt_null_addr;
		end;
	     if devadd_bits.core
	     then do;				/* A core address- move on up storage levels */
		     if ptw.phm
		     then do;			/* Must off phm */
			     ptw.phm1 = "1"b;	/* Mark mod status */
			     ptw.phm = "0"b;	/* OFF PHM */
			     offed_sw = "1"b;
			end;
		     cmep = addr (cmp -> cma (core_ptw.frame));
		     devadd = cmep -> cme.devadd;	/* Reconsider this devadd */
		     if devadd_null_flag & ^ptw.phm1 & ^(ptw.os & cme.io)
		     then devadd = get_file_map_vt_null_addr;
						/* This avoids damage to pure nulls incore */
		end;
	     if devadd_null_flag
	     then if dumper
		then devadd = get_file_map_dumper_non_null_addr;
		else do;
			devadd = get_file_map_vt_null_addr;
			devadd_null_flag = "1"b;
		     end;				/* if page is not on disk yet, or trunced,
						   we cannot fault in this page should we crash */
	     else devadd_null_flag = (devadd_add_type = "0000"b);
						/* Set outside-world null representation */

	     if ^devadd_null_flag
	     then do;				/* Real page */
		     getfmap_nrec = getfmap_nrec + 1;
		     getfmap_csl = i + 1;
		     if atptw.core
		     then getfmap_np = getfmap_np + 1;
		end;

	     rfm (i) = devadd;			/* Send out agreed-upon devadd */
	end;
	curtime = clock ();				/* loop_up_fms MAY do this, but we must be sure */
	if offed_sw
	then do;
		call loop_up_fms;			/* Pages were noted as modified. */
		call page$cam;			/* We turned off phm bits. */
	     end;

	if aste.fms
	then add_to_dmpr_map = "1"b;
	if ^aste.gtus
	then if aste.np | aste.infp
	     then /* have pages in, or subordinate astes */
		aste.dtu = bit (fixed (curtime, 52), 52);
						/* call it -in use- */
	copy_aste = astep -> aste;			/* Copy ASTE structure */

/* Update perishable items consistently to caller */

	astep -> aste.fms = "0"b;			/* copy_aste has old value - this
						   assignment constitutes segment control's
						   recognition of modification */
	if ^dumper
	then do;
		astep -> aste.fmchanged1 = astep -> aste.fmchanged;
						/* Dont' lose fmchanged until updatev
						   turns this off, but ... */
		astep -> aste.fmchanged = "0"b;	/* turn off p_c maintained bit. */
	     end;
	call pmut$unlock_ptl (oldmask, ptwp);		/* And unlock the pagetables */
						/* Use following items to avoid damaging */
						/* segments with incore nonmod nulls. */
						/* Copy out data to caller */

	copy_aste.np = bit (fixed (getfmap_np, 9), 9);
	copy_aste.records = bit (fixed (getfmap_nrec, 9), 9);
	copy_aste.csl = bit (fixed (getfmap_csl, 9), 9);

	unspec (Copy_Astep -> aste) = unspec (copy_aste); /* Copy the s  into our callers copy */

	do i = 0 to last_page;
	     fmp -> file_map.fm (i) = rfm (i);		/* Upper bits into file map */
	end;

	do i = 0 to j - 1;				/* copy out depositable addresses */
	     Address_Array (i) = deposit_list (i);
	     if return_pageno
	     then Pageno_List (i) = pageno_list (i);
	end;
	Deposit_Count = j;				/* deposit count */
	if add_to_dmpr_map & ^aste.nid & ^aste.per_process & ^aste.hc_sdw
	then call dbm_man$set_incr (fixed (aste.pvtx, 17), fixed (aste.vtocx, 17), (0));

	if pc_trace
	then do;
		call trace ("get_file_map^-astep = ^p, fmp = ^p", astep, fmp);
		if last_page <= 4
		then call trace (half_line_of_words, ptp -> fword (0), ptp -> fword (1), ptp -> fword (2),
			ptp -> fword (3));
		else do;
			do i = 0 to last_page by 8;
			     call trace (line_of_words, ptp -> fword (i), ptp -> fword (i + 1),
				ptp -> fword (i + 2), ptp -> fword (i + 3), ptp -> fword (i + 4),
				ptp -> fword (i + 5), ptp -> fword (i + 6), ptp -> fword (i + 7));
			end;
		     end;
	     end;
	return;
%page;
updates:
     entry (Astep);					/* Entry to set file modified switches. */

	astep = Astep;				/* Copy arg to avoid page fault. */
	sstp = addr (sst_seg$);
	call pmut$lock_ptl (oldmask, ptwp);		/* lock and mask */
	call loop_up_fms;
	go to quit;

update_incore_fms:
     entry (Astep);					/* used to get fms as accurate as possible */


	astep = Astep;
	sstp = addr (sst_seg$);
	ptp = addrel (astep, sst.astsize);

	if aste.np = "000"b3
	then return;
	offed_sw = "0"b;


	do i = 0 to fixed (aste.csl, 9) - 1;
	     if ptwa (i).phm
	     then do;
		     offed_sw = "1"b;		/* remeber to cam */
		     ptwa (i).phm1 = "1"b;		/* Needed for real write */
		     ptwa (i).phm = "0"b;		/* This statement order is critical */
		end;
	end;

	if offed_sw
	then do;
		call loop_up_fms;
		call page$cam;
	     end;

	return;

loop_up_fms:
     proc;					/* Set fms up tree for hierarchy dumper. */

	dcl     astep1		 pointer;

	if aste.gtms
	then return;
	curtime = clock ();
	astep1 = astep;
	do while (rel (astep1));
	     astep1 -> aste.fms = "1"b;
	     astep1 -> aste.dtm = bit (fixed (curtime, 52), 52);
	     astep1 = ptr (astep1, astep1 -> aste.par_astep);
	end;

     end loop_up_fms;

/* You do not have to lock the page table or clear the AM for any of this. Phm1 will
   always be taken as a signal to write, and page$pwrite will turn them both off when
   camming. Once phm1 is on, failure to set phm, for not camming, is invisible. However, we
   do cam at the end so that the next call to this will get phms. */
%page;
flush:
     entry;					/* here to write out all of core */

/* Synchronized pages are handled as follows:

   flush_core - Page Control (page$pwrite) does the right thing, based on
   the time stamp in the page.

   flush - Modified synchronized pages are abandoned. This is safe, due to
   Ring-2 Data Management protocols.

*/

	dcl     flushing_for_pleasure	 bit (1);
	dcl     hedonism		 fixed bin;
	dcl     pleasure_flush_count	 fixed bin;

	flushing_for_pleasure = "0"b;
	go to flush_join;

flush_core:
     entry;					/* here to start writes for all core. */

	flushing_for_pleasure = "1"b;

flush_join:
	sstp = addr (sst_seg$);			/* get pointers, and lock */
	pvt_arrayp = addr (pvt$array);
	cmp = sstp -> sst.cmp;
	if flushing_for_pleasure
	then hedonism = divide (sst.write_limit, 2, 17, 0);
	pleasure_flush_count = 0;
	call pmut$lock_ptl (oldmask, ptwp);		/* lock and mask */
start_flush:
	do i = sst.first_core_block to sst.last_core_block;
						/* index thru all cmes */
	     ind = -1;				/* no wait event */
	     cmep = addr (cmp -> cma (i));

	     if (cme.ptwp ^= "000000"b3)
	     then do;				/* has real page */
		     ptp = ptr (sstp, cme.ptwp);	/* get ptp */
		     astep = ptr (sstp, cme.astep);	/* get astep */
		     if ^aste.hc_part
		     then do;			/* Don't bother with HC part segs */
			     if ptw.os
			     then ind = fixed (rel (ptp), 18);
						/* if event, wait on it */
			     else do;
				     pageno =
					fixed (rel (ptp), 18) - fixed (rel (astep), 18) - sstp -> sst.astsize;
				     devadd = cme.devadd;
				     if ptw.phm | ptw.phm1
				     then /* Needs writing */
					if drive_ok ((aste.pvtx))
					then /* dont io bad disk */
					     if flushing_for_pleasure
					     then if cme.phm_hedge
						then do;
							call page$pwrite (astep, pageno);
							sst.hedge_writes = sst.hedge_writes + 1;
							pleasure_flush_count = pleasure_flush_count + 1;
						     end;
						else cme.phm_hedge = ^aste.per_process;
						/* change when we prevail across crashes */
						/* if significant, write next time, if not written */
					     else do;
						/* shutdown */
						     if aste.synchronized
						     then ptw.phm, ptw.phm1 = "0"b;
						/* Abandon modified synch pages */
						     else call page$pwrite (astep, pageno);
						end;
				     if ^flushing_for_pleasure
						/* shutdown */
				     then if ^(ptw.phm | ptw.phm1 | ptw.os)
						/* Unmodified */
					then if devadd_null_flag
						/* Null address */
					     then call page$pcleanup (astep, pageno);
						/* Reflect quota */
				     if ptp -> ptw.os
				     then /* if still being written, wait for it */
					ind = fixed (cmp -> cma (i).ptwp, 18);
				     if sstp -> sst.wtct > sstp -> sst.write_limit
				     then /* if too many queued then */
					if (ind > 0) & ^flushing_for_pleasure
					then call wait_then_go_to (start_flush);
						/* wait for one */
				     if pleasure_flush_count >= hedonism
				     then do;	/* All done with PTW */
					     pleasure_flush_count = 0;
						/* time for a nap */
					     call pmut$unlock_ptl (oldmask, ptwp);
					     if flushing_for_pleasure
					     then call pxss$relinquish_priority;
					     call pmut$lock_ptl (oldmask, ptwp);
					end;
				end;
			end;
		end;
	end;					/* end of cme array loop */

	if (ind > 0) & ^flushing_for_pleasure
	then call wait_then_go_to (start_flush);	/* Wait if shutdown and there is stuff to wait for */
	go to quit;				/* done */
%page;
list_deposited_add:
     entry (Astep, First_Page, Last_Page, Records, Listp, Pageno_Listp);
						/* output deposits to seg ctl */


	astep = Astep;				/* copy params */
	first_page = First_Page;			/* place to start */
	last_page = Last_Page;			/* place to stop */
	return_pageno = (Pageno_Listp ^= null ());
	sstp = addr (sst_seg$);			/* set up sstp */
	ptp = addrel (astep, sstp -> sst.astsize);

	records = 0;				/* init count of depositable records */

	call pmut$lock_ptl (oldmask, ptwp);		/* lock the PTL for real work */

	if last_page < 0				/* Scan whole page table */
	then last_page = sst.pts (fixed (astep -> aste.ptsi, 2)) - 1;

	do i = first_page to last_page;		/* loop thru all ptws in ptl */

	     devadd = ptp -> mptwa (i).devadd;		/* assume devadd in ptw -- */

/* Any page in core or on the PD which has a nulled address
   has a right to it: hence, we only list those in the PTW */

	     if devadd_bits.disk
	     then if devadd_null_flag
		then do;				/* a real deposited address */
			deposit_list (records) = devadd;
						/* move to output array */
			if return_pageno
			then pageno_list (records) = i;
			records = records + 1;	/* bump counter */
			ptp -> mptwa (i).devadd, devadd = list_deposit_null_addr;
		     end;
	end;

	call pmut$unlock_ptl (oldmask, ptwp);		/* unlock the page tables */
	do i = 0 to records - 1;
	     Address_Array (i) = deposit_list (i);	/* return to argument array */
	     if return_pageno
	     then Pageno_List (i) = pageno_list (i);
	end;

	Records = records;				/* return the count */
	return;
%page;
deposit_list:
     entry (Pvtx, Records, Listp, Vtocx, Pageno_Listp);	/* entry to deposit a list of addresses */


	records = Records;				/* number of records to be deposited */
	pvtx = Pvtx;				/* phys volume index */

/* The paged fsdct strategy states that the page table lock need
   not be locked to deposit. Nobody can withdraw our bit unless we
   have a problem, and if we find an unprotected address at
   the time we deposit, this will be the case irrespective
   of the page table lock. */

	do i = 0 to records - 1;
	     Devadd_Array (i).add_type = add_type.disk;	/* Make up for sins of vtoc_man */
	end;

	call page$deposit_list ((pvtx), Listp, 1, records, Vtocx, Pageno_Listp);

	return;


/*  Auxiliary entry for truncation/deposition of vtoceless segs */

truncate_deposit_all:
     entry (Astep);


	astep = Astep;				/* Copy astep */

	if aste.uid
	then call syserr (1, "pc: truncate_deposit_all call on VTOCed seg at ^p", astep);
	call truncate (astep, 0);			/* Clean up w.r.t. pc */

	if aste.hc_sdw
	then return;				/* Don't attempt semi-hc deposit */

	call list_deposited_add (astep, 0, -1, records, addr (deposit_list), null ());

	call page$deposit_list ((aste.pvtx), addr (deposit_list), 1, records, -1, null ());

	return;
%page;
move_page_table:
     entry (Old_Astep, New_Astep);


	sstp = addr (sst_seg$);
	cmp = sstp -> sst.cmp;
	old_astep = Old_Astep;
	new_astep = New_Astep;
	call pmut$lock_ptl (oldmask, ptwp);		/* lock and mask */

	if pc_trace
	then call trace ("move_page_table^-old astep = ^p, new astep = ^p", old_astep, new_astep);

	old_ptp = addrel (old_astep, sstp -> sst.astsize);/* get pointer to old page table */
	new_ptp = addrel (new_astep, sstp -> sst.astsize);/* get pointer to new page table */
	do i = 0 to sstp -> sst.pts (fixed (old_astep -> aste.ptsi, 3)) - 1;
	     new_ptp -> ptwa_bits (i) = old_ptp -> ptwa_bits (i);
						/* copy page table words */

	     old_ptp -> ptwa_bits (i) = null_devadd_not_in_core;
	     old_ptp -> mptwa (i).devadd = pc_move_page_table_1_null_addr;
	     ptp = addr (new_ptp -> ptwa (i));		/* point to specific ptw */
	     if atptw.core
	     then do;				/* ptw describes core */
		     cmep = addr (cmp -> cma (core_ptw.frame));
						/* address CME */
		     cme.ptwp = rel (ptp);		/* associate CME with new PTW */
		     cme.astep = rel (new_astep);	/* ditto ASTE */
		     devadd = cme.devadd;		/* get devadd from cme if in core */
		     if cme.notify_requested		/* if someone was waiting on old PTW event, then notify .. */
		     then call pxss$notify (fixed (rel (addr (old_ptp -> ptwa (i))), 18));
						/* him, causing him to rewait on new event */
		end;
	     else devadd = mptw.devadd;		/* get devadd out of ptw if not in core */
	end;

	do i = sstp -> sst.pts (fixed (old_astep -> aste.ptsi, 3))
	     to sstp -> sst.pts (fixed (new_astep -> aste.ptsi, 3)) - 1;

	     new_ptp -> ptwa_bits (i) = null_devadd_not_in_core;
	     new_ptp -> mptwa (i).devadd = pc_move_page_table_2_null_addr;
	end;

/* Now copy the old ASTE into the new ASTE, except fp, bp, ptsi and marker */

	new_astep -> aste_part.two = old_astep -> aste_part.two;

	go to quit;
%page;


segmove:
     entry (Move_Astep, Old_Astep, New_Astep, New_Pvtx, New_Vtocx, Records, Listp, Pageno_Listp, Code);

	astep = Move_Astep;				/* aste under segmove */
	old_astep = Old_Astep;			/* put old addresses here for pcrsst */
	new_astep = New_Astep;			/* put new addresses here for pcrsst or caller to deposit */
	new_pvtx = New_Pvtx;			/* we can reference them without the */
	new_vtocx = New_Vtocx;			/* AST lock */
	sstp = addr (sst_seg$);
	cmp = sst.cmp;
	new_ptp = addwordno (new_astep, sst.astsize);	/* use that page table
						   to store up addresses on new volume */
	old_ptp = addwordno (old_astep, sst.astsize);	/* use that page table
						   to remember old addesses for the purposes of pcrsst */
	move_ptp = addwordno (astep, sst.astsize);	/* this is the page table of affliction. */

	if astep -> aste.ptsi ^= new_astep -> aste.ptsi | new_astep -> aste.ptsi ^= old_astep -> aste.ptsi
	then do;
		Code = error_table_$bad_arg;
		return;
	     end;

	last_page = sst.pts (fixed (astep -> aste.ptsi, 2)) - 1;

	call lock$lock_fast (addr (sst.segmove_lock));	/* Only one at a time */
	sst.segmove_new_addr_astep = new_astep;		/* pc_check_tables_ should deposit anything in here
						   or at least bang on the pvte inconsistency count. */

	call pmut$lock_ptl (oldmask, ptwp);		/* will be unlocked if we have to wait */

/**** Note that deposit_list is declared 0:255 and page$deposit_list expects a
      1:256 array. withdraw_list expects 0:255. Shouldn't be any trouble */

	segmove_records_in_hand = 0;
	segmove_total_records,			/* This many is the grand total that we have accumulated */
	     segmove_records_needed			/** This many are the number that we need to add to the record pile */
	     = fixed (astep -> aste.records, 9);	/* This is the first guess as to the total number of records needed */
						/* However, the guess may be too low since the PTL is unlocked. So */
						/* even when we get records_in_hand up and records_needed to 0, we may */
						/* have to add to total_records and reset records_needed to get the rest */


	move_tries = 0;

augment_record_pile:
/**** + Debug
      call syserr (ANNOUNCE, "pc: (at ARP) aste: np = ^d, records = ^d, csl = ^d", fixed (aste.np), fixed (aste.records), fixed (aste.csl));
*/
	code = 0;
	do while (segmove_records_needed > 0 & code = 0); /* keep calling until free_store gives all we want */
	     call page$withdraw_list (new_pvtx, new_ptp, segmove_records_in_hand, segmove_records_needed, ind, code);
						/* since parm(3) is zero based, zero records_in_hand is interpreted */
						/* as "put the next record in slot zero" which deposit addresses as  */
						/* slot one. */

	     if ind ^= 0
	     then /* wait for volmap */
		call wait_then_go_to (augment_record_pile);
	end;
	if code ^= 0
	then do;					/* out-of-volume */
		Code = code;
		go to SEGMOVE_ABORT_RETURN;
	     end;

/**** At this point, we own all the records we need. We can release the
      PTL while we drag the segment into memory. */

/****  NOTE -- at this point new_ptp contains segmove_total_records records.
      segmove_records_needed can be re-used.
      if we find that we need more records, total_records will grow,
      but in_hand will continue to be the number of addresses in new_addr_aste. */

move_retry:
	segmove_records_needed = 0;			/* re-count the number we need under the PTL */

/**** + Debug
      call syserr (ANNOUNCE, "pc: (at MRT) aste: np = ^d, records = ^d, csl = ^d", fixed (aste.np), fixed (aste.records), fixed (aste.csl));
*/

	move_tries = move_tries + 1;
	if move_tries > 1000
	then go to SEGMOVE_ABORT_RETURN;

	n_io_started = 0;
SEGMOVE_EXAMINE_PAGES:
	do i = 0 to last_page;			/* get all pages into memory */
RE_EXAMINE_PAGE:
	     if move_ptp -> ptwa (i).os
	     then do;				/* wait for i and  also o (quiesce) */

		     ind = wordno (addr (move_ptp -> ptwa (i)));
						/* event to wait on */
		     n_io_started = n_io_started + 1;
		     if n_io_started > sst.segmove_io_limit
		     then call wait_then_go_to (move_retry);
		end;
	     else if move_ptp -> atptwa (i).disk
	     then do;
		     sst.segmove_n_reads = sst.segmove_n_reads + 1;
		     call page$pread (astep, i, temp_ind);
						/* put event into temporary... */
		     if temp_ind ^= 0
		     then do;
			     ind = temp_ind;	/* OK to mung it now... */
			     n_io_started = n_io_started + 1;
			     if n_io_started > sst.segmove_io_limit
			     then call wait_then_go_to (move_retry);
			end;
		     else go to RE_EXAMINE_PAGE;	/* ZERO! */
		end;
	     else if move_ptp -> atptwa (i).core
	     then do;				/* in memory - keep it there */
		     segmove_records_needed = segmove_records_needed + 1;
						/* got another real one in memory */
		     cmep = addr (cmp -> cma (move_ptp -> core_ptwa (i).frame));
		     cme.pin_counter = 1000;
		     if astep -> aste.synchronized & (move_ptp -> core_ptwa (i).phm | move_ptp -> core_ptwa (i).phm1)
						/* any modified page of a synch segment is held until proven elsewise */
		     then call segmove_synch_page (astep, cmep, i);
		end;
	     else if move_ptp -> ptwa (i).add_type ^= "0000"b
						/* mysterious non-null */
	     then /* but unknown! */
		call syserr (CRASH, "pc$segmove: unexpected address type ^4b", move_ptp -> ptwa (i).add_type);
	end SEGMOVE_EXAMINE_PAGES;

/**** At arrival here, the PTL is locked (nothing can be evicted)
      and either all the pages are in memory, or we have some read-ahead
      activity. */

	if n_io_started > 0
	then call wait_then_go_to (move_retry);		/* ind is last read ahead page */

	sst.segmove_max_tries = max (move_tries, sst.segmove_max_tries);

/**** No read aheads. all pages found in core, PTL is locked.
      Start final countdown. Unless, somehow, the segment grew ... */

	if segmove_records_needed > segmove_total_records
	then do;					/* When we counted under the PTL and made them stand still, we found more of them. */
		segmove_total_records = segmove_records_needed;
						/* new count is the right count */
		segmove_records_needed = segmove_records_needed - segmove_records_in_hand;
						/* count of additional records required */
		go to augment_record_pile;		/* get 'em */

	     end;

/**** We have an adequate supply of records on the new volume,
      and everything is in memory. Here we go... */

/**** Since the move segment page table is in its final state
      (all addresses null or in core) we can copy all the ptw's
      to the old_addr_aste. pcrsst will find them there and
      put them back. All the new addreses have been accumulated
      in the new_addr_aste, where shutdown can deposit them.

      Thus the rules are:  if new_addr_astep ^= null (), deposit
      all the non-null addresses in its page table. pc_check_tables_
      does not currently concern itself with deposits, so these
      addresses are abandoned.

      if the move_astep ^= null (), then copy the page table
      from the old_addr_aste to the move_aste. The old_addr_astep
      is guaranteed to be non-null.

      if the old_addr_astep ^= null(), then zap all its ptw's
      to be null addresses. */

	sst.segmove_old_addr_astep = old_astep;		/* still full of nulls */
						/* now, pcrsst will zero all these ptw's */

	begin;					/* copy the page table wholesale from move to old astep */
	     declare pt		      (0:last_page) bit (36) aligned based;
	     old_ptp -> pt = move_ptp -> pt;
	end;					/* this can be copied back verbatim by pc_check_tables_
						   since we are under the PTL and nothing can change. */

	sst.segmove_pvtx = astep -> aste.pvtx;
	sst.segmove_vtocx = astep -> aste.vtocx;
	sst.segmove_astep = astep;			/* now, pcrsst will copy all the devadds from old to here */

/**** Now it only takes one loop to put the new disk devadds into
      the move aste. */

	segmove_records_used = 0;

	if segmove_total_records < fixed (aste.np)
	then call syserr (CRASH, "pc$segmove: miscounted pages.");

	do i = 0 to last_page;			/* now swap addresses */
	     devadd = move_ptp -> mptwa (i).devadd;	/* either core or null */
/**** + Debug
      call syserr (ANNOUNCE, "sgm: page ^d ptw devadd ^.3b",
      i, devadd);
*/
	     if (devadd_add_type & add_type.core) ^= ""b	/* core */
	     then do;
		     if segmove_records_used > segmove_records_in_hand
		     then call syserr (CRASH, "pc$segmove: out of records during move");
		     cmep = addr (cmp -> cma (move_ptp -> core_ptwa (i).frame));
		     move_ptp -> core_ptwa (i).phm1 = "1"b;
						/* modify! */
						/* it will get hierarchy incrementalled, which is unfortunate */
		     segmove_deposit_list (segmove_records_used) = cme.devadd;
/**** + Debug
      call syserr (ANNOUNCE, "sgm: old cme devadd ^.3b", cme.devadd);
*/
		     pageno_list (segmove_records_used) = i;
		     devadd = new_ptp -> mptwa (segmove_records_used).devadd;
						/* new record address + disk flag */
/**** + Debug
      call syserr (ANNOUNCE, "sgm: new devadd ^.3b", devadd);
*/
		     new_ptp -> mptwa (segmove_records_used).devadd = segmove_new_addr_null_addr;
						/* order here is noncritical,
						   pc check tables will zonk all of these anyway */
		     devadd_null_flag = "1"b;		/* you're not on disk yet, buddy! */
		     cme.devadd = devadd;
		     cme.phm_hedge = "1"b;
/**** + Debug
      call syserr (ANNOUNCE, "sgm: new devadd in CME ^.3b", devadd);
*/
		     cme.pin_counter = 0;		/* don't hold page any longer */
		     segmove_records_used = segmove_records_used + 1;
		end;
	end;

	if sst.crash_test_segmove
	then call syserr (CRASH, "pc$segmove: crashing in segment mover.");

	astep -> aste.pvtx = new_pvtx;		/* finish the swap */
	astep -> aste.vtocx = new_vtocx;		/* ... */
	astep -> aste.fmchanged = "1"b;		/* ... */

	sst.segmove_astep = null;			/* dont fix addresses, pvtx, or vtocx.
						   and dont copy page table from old_addr_aste */
	sst.segmove_pvtx = 0;
	sst.segmove_vtocx = 0;

/**** Now cleanup the old addresses, unbinding them from PTW's etc. */

	begin;
	     declare pt		      (0:last_page) bit (36) based;
	     declare px		      fixed bin;

	     declare 1 nptw		      aligned like l68_ptw;
	     declare ptwp		      pointer;

	     unspec (nptw) = ""b;
	     nptw.add = segmove_old_addr_null_addr;	/* thats whats left */
	     do px = 0 to last_page;
		ptwp = addr (old_ptp -> pt (px));	/* all are core addresses, we are under PTL after verifying that */
		devadd = ptwp -> mptw.devadd;
		if (devadd_add_type & add_type.non_null) ^= ""b
		then do;
			if (devadd_add_type & add_type.core) = ""b
			then call syserr (CRASH, "pc$segmove: non-memory PTW in old_addr_aste.");
			old_ptp -> pt (px) = unspec (nptw);
		     end;
	     end;
	end;
	sst.segmove_old_addr_astep = null ();

	call pmut$unlock_ptl (oldmask, ptwp);

	if segmove_records_in_hand > segmove_records_used
	then /* some records on new pvt left over */
	     call page$deposit_list (new_pvtx, new_ptp, segmove_records_used + 1,
		segmove_records_in_hand - segmove_records_used, -1, null ());

	call lock$unlock_fast (addr (sst.segmove_lock));

	Address_Array = segmove_deposit_list;		/* out from under PTL */
	Pageno_List = pageno_list;			/* so we can copy to unwired stack_0 */
	Records = segmove_records_used;		/* starts at zero, used as index
						   to zero-based array, then bumped. */

	return;

SEGMOVE_ABORT_RETURN:
	call pmut$unlock_ptl (oldmask, ptwp);
	if segmove_records_in_hand > 0
	then call page$deposit_list (new_pvtx, new_ptp, 1, segmove_records_in_hand, -1, null ());
						/* Abandon all the records that we collected */
	if Code = 0
	then					/** we may have a specific code */
	     Code = error_table_$action_not_performed;
	call lock$unlock_fast (addr (sst.segmove_lock));
	return;


segmove_synch_page:
     procedure (astep, cmep, pagex);

	declare (astep, cmep)	 pointer;
	declare pagex		 fixed bin;



/**** Call page control to write the page itself. If the synch_hold
      is legit, then .synch_hold will still be on when pwrite returns.
      If .synch_hold is off, the page is no longer held. */

	call page$pwrite (astep, pagex);

	if ^cmep -> cme.synch_held
	then do;
		sst.segmove_synch_disappeared = sst.segmove_synch_disappeared + 1;
		return;				/* page is fine, we can move it */
	     end;

	Code = error_table_$synch_seg_segmove;
	go to SEGMOVE_ABORT_RETURN;
     end segmove_synch_page;


%page;
drive_ok:
     proc (pvtx) returns (bit (1) aligned);		/* test drive state */

	dcl     pvtx		 fixed bin;

	return (^pvt_array (pvtx).device_inoperative);

     end drive_ok;
%page;
wait_then_go_to:
     procedure (lab);				/* quick internal proc to trace and wait for
						   page control events */
	dcl     lab		 label local;

	if ind = 0
	then call syserr (CRASH, "pc: waiting for zero event.");

	if pc_trace
	then call trace ("wait for i/o");
	call page$cam;				/* make sure any work done so far gets done */
	call page$pwait (ind);			/* wait for event */
	go to lab;

     end wait_then_go_to;

/* format: off */
%page; %include sst;
%page; %include pvte;
%page; %include cmp;
%page; %include aste;
%page; %include fm;
%page; %include null_addresses;
%page; %include add_type;
%page; %INCLUDE "ptw.macro";
%page; %include syserr_constants;
%page;
/* BEGIN MESSAGE DOCUMENTATION

   Message:
   pc: unprotected address DDDDD in DSKX_NN VTOCX

   S:	$info

   T:	$run

   M:	The disk address DDDDD
   is not marked as protected
   in the record usage map for the volume mounted on DSKX_NN.
   This condition has been discovered
   while activating the segment with VTOC index VTOCX.
   The segment's damaged switch is turned on, and a page of zeros will
   replace the bad address. This condition may be symptomatic of disk
   or other hardware failure.

   A:	$inform


   Message:
   pc: truncate_deposit_all call on VTOCed seg at ASTEP

   S:	$crash

   T:	$run

   M:	A call to pc$truncate_deposit_all
   has been made on a segment for which this operation is not allowed.
   The AST entry at ASTEP should have a zero unique ID
   but it does not.
   $err
   $crashes

   A:	$recover


   END MESSAGE DOCUMENTATION */

     end pc;
