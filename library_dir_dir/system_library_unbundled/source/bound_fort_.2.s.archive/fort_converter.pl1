/****^  ******************************************************
        *                                                    *
        * Copyright, (C) Honeywell Limited, 1983             *
        *                                                    *
        * Copyright (c) 1972 by Massachusetts Institute of   *
        * Technology and Honeywell Information Systems, Inc. *
        *                                                    *
        ****************************************************** */



/****^  HISTORY COMMENTS:
  1) change(86-07-14,BWong), approve(86-07-14,MCR7286), audit(86-07-17,Ginter),
     install(86-07-28,MR12.0-1105):
     Fix fortran bug 463.
                                                   END HISTORY COMMENTS */


/* format: style3,^delnl,linecom */
fort_converter:
     proc (a_ptr);

/* Written:	Oct 77 - May 78, GDC & PES			*/

/* Modified:
   02 Aug 85, BW - 463: Removed code to set must_save_stack_extent.
		The saving will no longer be done because of fortran_io_
		problems.
   25 Oct 84, HH - 444: Remove generation of 'sub_index' operators for
		substring lengths.
   22 Jun 84, MM - Install typeless functions support.
   18 Aug 83, HH - 399: 'effectively_constant' doesn't free quads correctly.
   14 Aug 83, HH - 398: Leave loop index defined when removing implied loops
		from I/O statements.
   27 Jul 83, HH - 392: Prevent replacement of named string constants by the
		string value in 'opt_subscript_op's.
   17 Jun 83, HH - 383: Add support for 'process_param_list_op'.
   14 Apr 83, HH - 376: Move support of 'len' builtin to the code generator.
   31 Jan 83, HH - Install LA/VLA support.
   28 Nov 82, HH - 361: ASSIGNment of a format which the parser has made
	into a named constant is not handled correctly.
   11 Nov 82, HH - 363: 'optimize_vector' used 'dimension.size (i)' even
	when one of the bounds of that dimension was variable, and the
	code to unthread the final opt statement neglected to link the
	previous operator of the opt statement to the first operator.
	Also, 'optimize_vector' forgot to remove calculation of the virtual
	origin of an array that was to be written as a vector starting at
	its first word.
    5 May 82, TO   - Add runtime_stack_extent required for character*(*) function.
   25 Mar 82, TO   - Fixed navy bug 3 - "end if" not processed by "process_hold_stack_entry"
	if statement following does not have "put_in_map" set.  Typically failed
	if following statement was "else if" without code.
   16 Nov 81, MEP  - Fixed bug 343, cat now looks at subrprog options.ansi_77
   28 October 1981, CRD - Support inquire statement.
   20 October 1981, CRD - Internal files.
   3 August 1981, CRD - Fix bug 332.
   28 July 1981, CRD - Change assign_label to replace format label with
	associated format variable.
   13 July 1981, CRD - Force creation of back targets for zero trip DO loops.
   10 June 1981, CRD - New polish for backspace/endfile/rewind.
   12 May 1981, CRD - Add equiv_op, not_equiv_op.
   13 March 1981, CRD - Implement assumed size arrays.
   25 February 1981, CRD - Implement array lower bounds ^= 1.
   9 December 1980, CRD - Implement Fortran 77 block IF statement.
   19 November 1980, CRD - Implement Fortran 77 zero trip DO loops.  Also fix
	a bug in which star extent arrays only got a virtual_origin symbol
	if they had variable extents.  Also fix optimize_vector to handle
	star extent arrays correctly.
   17 August 1980, CRD - Fix bug in subscript handling.
   14 August 1980, CRD - Fix bug in handling of CHAR builtin.
   29 July 1980, CRD - Change many calls to create_constant to
	create_integer_constant instead.
   28 July 1980, CRD - Add code for LEN builtin.
   30 June 1980, MEP - Add code for substr'ing 
   23 June 1980, CRD - Add code to compute must_save_stack_extent.
   23 June 1980, CRD - Check ansi77 mode for concatenation.
   18 June 1980, CRD - Change concatenation routines to generate sub_index
	operators for the length.
   6 June 80, CRD - Changes for new concatenation representation in the quads.
   5 May 80, CRD - Rewrote compress_concat, fixing bugs.
   2 May 80, MEP+CRD - Fix bug 258.  Changed new_free_object to use currentsize
	builtin instead of size.
   1 May 80, CRD - Fix unreported bug (the main loop was not handling counts
	properly.)
   31 Mar 80, MEP - Add code to recognize the sharing of virtual origins.
   18 Dec 79, PES - Change to accept (read write)_namelist_op rather than namelist_op, to fix
	bug 249, in which the optimizer appears to ignore the fact that a namelist read sets
	the values in the namelist.  Also, make string_op an illegal input.
   17 Sept 79, RAB - change last_assigned_op from 97 to 99 for register optimizer
   13 Aug 79, RAB - change last_assigned_op from 95 to 97 in preparation for concatenation & substr
   12 Jul 79, PES - Make encode_op processing bump the ref_count of it's output operand
	if it's an array ref node.  Part of making encode/decode work as documented.
   26 Jun 79, PES - Fix bug 217, in which the appearance of a reference to an element of
	a logical array in a compound if statement condition might cause compiler
	error 446, uninitialized array subscript.
   21 Jun 79, RAB - Fix bug 216, in which the conversion rules are not properly obeyed
	for <non-integer>**<integer> in that the integer will be converted to match
	the data type of <non-integer>.
   05 Feb 79, PES - Fix bug 201, in which incorrect code is generated when optimizing
	for <expression>**<positive_integer_constant> except when the positive
	integer constant is a power of two, or one greater than a power of two.
   13 Dec 78, PES - Fix bug 199, in which implied do loops in i/o statements may
	not optimize properly if there is more than one variable contained at a
	given level of nesting.
   08 Dec 78, PES - Fix bug in handling of nested statement function invocations.
   25 Oct 78, PES - Changes for larger common blocks and arrays.
   04 Sep 78, PES - Fix bug in handling of division in subscripts, and
   bug in handling of statement functions in subscripts.
   28 Jul 78, PES - Audit changes, fix bug in handling of character string
   temporaries (167).
*/

/* In the comments, the construction <phrase> stands for a single token which is described by
   phrase; the construction <...> stands for an arbitrary number of stack entries of irrelevant nature;
   braces {} are used to enclose a group which is repeated one or more times;
   and the top of the stack is enclosed in parens--typically (<>) since the top of the stack is normally
   the first unused item rather than the last used item. */


/*   arguments   */

dcl	a_ptr		ptr;

/*   automatic   */

dcl	(
	block_if_clause_count,
	block_if_offset,
	combination_type,
	dim_size_offset,
	eol_offset,
	exit_offset,
	first_free_object	init (1),
	hold_offset,
	i,
	j,
	last_io_op,
	last_op_index,
	next_statement_index,
	n_ops,
	one,
	op_index,
	polish_offset,
	rand_data_type	(8),
	rand_node_type	(8),
	save_polish_offset,
	sf_num_args,
	sf_offset,
	sub_offset,
	temp_index,
	true_rand,
	tkx,
	virtual_origin_offset,
	work_stack_offset,
	zero
	)		fixed bin (18);

dcl	(subscript_processing, first_statement_function_done, suspend_subscript,
	calls_local_entries, concatenates_star_extents)
			bit (1) aligned init ("0"b);

dcl	1 sub_stack	aligned based (sub_stack_p),
	  2 last		fixed bin (18),
	  2 nested	bit (1),
	  2 symbol_node	ptr unaligned,
	  2 dim_node	ptr unaligned,
	  2 n_dimensions	fixed bin (18),
	  2 dimension	fixed bin (18),
	  2 element,
	    3 constant	fixed bin (18),
	    3 var		fixed bin (18),
	  2 cum,
	    3 temp	fixed bin (18),
	    3 constant	fixed bin (18),
	  2 dim,
	    3 mult	fixed bin (18),
	    3 temp	fixed bin (18),
	    3 offset	fixed bin (18);

dcl	1 sf_stack	aligned based (sf_stack_p),
	  2 last		fixed bin (18),
	  2 polish_offset	fixed bin (18),
	  2 sf		fixed bin (18),
	  2 current_arg	fixed bin (18),
	  2 cur_sf_param	fixed bin (18),
	  2 def_chain	ptr unaligned,
	  2 num_args	fixed bin (18),
	  2 arg_info	(sf_num_args refer (sf_stack.num_args)),
	    3 operand	fixed bin (18),
	    3 chain_start	fixed bin (18),
	    3 chain_end	fixed bin (18);

dcl	1 exit_stack	aligned based (exit_stack_p),
	  2 last		fixed bin (18),
	  2 op		fixed bin (18),
	  2 count		fixed bin (18),
	  2 do_label	fixed bin (18),
	  2 xmit_at_this_level
			fixed bin (18),
	  2 ptr		ptr unaligned,
	  2 zero_trip_branch
			fixed bin (18);

dcl	1 eol_stack	aligned based (eol_stack_p),
	  2 last		fixed bin (18),
	  2 op		fixed bin (18),
	  2 work_stack_offset
			fixed bin (18);

dcl	1 hold_stack	aligned based (hold_stack_p),
	  2 last		fixed bin (18),
	  2 op_code	fixed bin (18),
	  2 ptr		ptr unaligned;

dcl	stack		(0:511) fixed bin (18);

dcl	1 fort_data$builtin_name
			aligned external static structure,
	  2 number_of_names fixed bin (15),
	  2 description	(100),
	    3 name	char (8) aligned,
	    3 generic_name	bit (1) unaligned,
	    3 reserved	bit (35) unaligned,
	    3 generic_func	(4) fixed bin (18),
	    3 result_type	fixed bin (18);

declare	1 virtual_origin_list
			aligned based (virtual_origin_list_ptr),
	  2 last		fixed binary (18),
	  2 symbol_node	pointer unaligned,
	  2 element_size	fixed binary (17),
	  2 numb_of_dims	fixed binary (17),
	  2 units		fixed binary (3) unsigned;

declare	1 block_if_stack	aligned based (block_if_stack_p),
	  2 last		fixed binary (18),
	  2 n_clauses	fixed binary (18),
	  2 clause	fixed binary (18),
	  2 test_op	fixed binary (18),
	  2 n_jumps	fixed binary (18),
	  2 jump		(block_if_clause_count refer (block_if_stack.n_clauses)) fixed binary (18);

declare	1 dim_size_list	aligned based (dim_size_list_ptr),
	  2 last		fixed binary (18),
	  2 bits		aligned,
	    3 var		unaligned,
	      4 lower	bit (1) unaligned,
	      4 upper	bit (1) unaligned,
	    3 pad		bit (34) unaligned,
	  2 lower_bound	fixed binary (24),
	  2 upper_bound	fixed binary (24),
	  2 size		fixed binary (24);

dcl	(array_ptr, block_if_stack_p, dim_size_list_ptr, eol_stack_p,
	exit_stack_p, hold_stack_p, last_opt_statement, last_quad_p, opst,
	r, s, sf_stack_p, sf_substitute_ptr, shared_struc_ptr, stm_ptr,
	sub_stack_p, subp_ptr, temp_node_ptr, temp_ptr, virtual_origin_base,
	virtual_origin_list_ptr)
			ptr;

/*   based   */

dcl	p		(0:polish_max_len - 1) fixed bin (18) aligned based (polish_base),
	q		(0:quad_max_len - 1) fixed bin (18) aligned based (quadruple_base),
	w		(0:object_max_len - 1) fixed bin (18) aligned based (object_base),
	x		(0:operand_max_len - 1) fixed bin (18) aligned based (operand_base);

dcl	(polish_base, quadruple_base, object_base, operand_base)
			ptr;

dcl	(polish_max_len, quad_max_len, object_max_len, operand_max_len)
			fixed bin (18);

/*   builtin   */

dcl	(addr, binary, bit, char, currentsize, fixed, hbound, index, max, null, ptr, rel, size, string, substr, unspec)
			builtin;

/*   include files   */

%include fort_utilities;

%include fort_nodes;

%include fort_system_constants;

dcl	1 shared_globals	aligned based (shared_struc_ptr),
%include fort_shared_vars;

%include fort_options;

%include fort_opt_nodes;

	call count_cases (i);
	if i ^= last_assigned_op
	then do;
		call print_message (382, "The number of operator cases", "last_assigned_op");
		return;
	     end;

	shared_struc_ptr = a_ptr;

	polish_base = shared_globals.polish_base;
	quadruple_base = shared_globals.quadruple_base;
	object_base = shared_globals.object_base;
	operand_base = shared_globals.operand_base;

	polish_max_len = shared_globals.polish_max_len;
	quad_max_len = shared_globals.quad_max_len;
	object_max_len = shared_globals.object_max_len;
	operand_max_len = shared_globals.operand_max_len;

	eol_offset = 0;
	eol_stack_p = addr (w (eol_offset));
	hold_offset = 0;
	hold_stack_p = addr (w (hold_offset));
	sf_offset = 0;
	sf_stack_p = addr (w (sf_offset));
	exit_offset = 0;
	exit_stack_p = addr (w (exit_offset));
	sub_offset = 0;
	sub_stack_p = addr (w (sub_offset));
	virtual_origin_offset = 0;
	virtual_origin_list_ptr, virtual_origin_base = addr (w (virtual_origin_offset));
	block_if_offset = 0;
	block_if_stack_p = addr (w (block_if_offset));
	dim_size_offset = 0;
	dim_size_list_ptr = addr (w (dim_size_offset));

	one = create_integer_constant (1);

	zero = create_integer_constant (0);

	do cur_subprogram = shared_globals.first_subprogram repeat subp_ptr -> subprogram.next_subprogram
	     while (cur_subprogram > 0);

	     subp_ptr = addr (x (cur_subprogram));
	     unspec (last_opt_statement) = "0"b;
	     last_op_index = 0;
	     work_stack_offset = 0;

	     do cur_statement = subp_ptr -> subprogram.first_polish repeat fixed (stm_ptr -> statement.next, 18)
		while (cur_statement > 0);

		stm_ptr = addr (p (cur_statement));

/* Make the statement node for the current statement. */

		opst = create_opt_statement ();

		next_statement_index = fixed (stm_ptr -> statement.next, 18);
		if next_statement_index = 0
		then next_statement_index = subp_ptr -> subprogram.last_polish + 1;
		last_io_op = 0;

		calls_local_entries = "0"b;
		concatenates_star_extents = "0"b;

		polish_offset = cur_statement + size (statement);

/* Check for a label, and add it on if present.  The first test is needed as the top of the
   polish might be <increment_polish> followed by a count which happens to look like a label op. */

		if p (polish_offset) > last_assigned_op
		then if p (polish_offset + 1) = label_op
		     then do;
			     opst -> opt_statement.label = p (polish_offset);
			     addr (x (p (polish_offset))) -> label.statement = last_op_index;
			     polish_offset = polish_offset + 2;
			end;

		call process_hold_stack_entry ();
		opst -> opt_statement.processed_by_converter = "1"b;

/* Copy tokens from the polish to the working stack one at a time.  When an operator is found,
   process_operator is called to process it.  Symbols are checked to see if they are statement_function
   dummy arguments, and if so the substitution is made.  The first time a particular dummy
   argument is substituted, the quads which were used to evaluate it are rechained so they
   immediately precede its use. */

		do polish_offset = polish_offset by 1 while (polish_offset < next_statement_index);

		     stack (work_stack_offset) = p (polish_offset);
		     call bump_work_stack_offset (+1);

		     if p (polish_offset) <= last_assigned_op & p (polish_offset) > 0
		     then call process_operator ();
		     else if p (polish_offset) > 0
		     then if addr (x (stack (work_stack_offset - 1))) -> node.node_type = symbol_node
			then if addr (x (stack (work_stack_offset - 1))) -> symbol.dummy_arg
			     then do;
				     do sf_substitute_ptr = sf_stack_p
					repeat (addr (w (sf_substitute_ptr -> sf_stack.last)))
					while (sf_substitute_ptr ^= addr (w (0)));

					j = 0;

					do i = sf_substitute_ptr -> sf_stack.def_chain -> symbol.next_member
					     repeat (addr (x (i)) -> symbol.next_member) while (i ^= 0);

					     j = j + 1;
					     if i = stack (work_stack_offset - 1)
					     then go to GOT_THE_SF_VAR;
					end;
				     end;

				     call print_message (203);

GOT_THE_SF_VAR:
				     if sf_substitute_ptr ^= addr (w (0))
				     then do;
					     if sf_substitute_ptr -> sf_stack.arg_info (j).chain_start ^= 0
					     then call rechain_arg (sf_substitute_ptr, j);
					     stack (work_stack_offset - 1) =
						sf_substitute_ptr -> sf_stack.arg_info (j).operand;
					end;
				end;
		end;				/* Loop over polish for one statement */

	     end;					/* Loop over statements */

	end;					/* Loop over program units */

	if virtual_origin_offset ^= 0			/* if virtual origin list created */
	then call free_virtual_origin_list ();

	if dim_size_offset ^= 0			/* if dimension size list created */
	then call free_dim_size_list ();

	return;					/* end of converter */

process_operator:
     proc ();

dcl	op_code		fixed bin (18);

	op_code = stack (work_stack_offset - 1);
	if op_code < 0 | op_code > last_assigned_op
	then go to case (0);
	go to case (op_code);

count_cases:
     entry (number_of_cases);

dcl	number_of_cases	fixed bin (18);

	number_of_cases = hbound (case, 1);
	return;

case (0):						/*   ERROR   */

/* No such thing as operator with op_code of 0. */

	call print_message (200, char (op_code));
	return;

case (1):						/*   ASSIGN   */

/* Stack is (<>) <assign_op> <right_hand_value> <target> <...>
   Create an assignment op quad, with conversion if needed, and reduce stack
   to (<>) <...> */

	call process_assign ();
	return;

case (2):						/*   ADD   */
case (3):						/*   SUB   */
case (4):						/*   MULT   */
case (5):						/*   DIV   */

/* Stack is (<>) <binary_arith_op> <right_operand> <left_operand> <...>
   Process the operation as appropriate, and reduce stack to (<>) <result_temporary> <...> */

	call process_arith (subscript_processing & ^suspend_subscript);
	return;

case (6):						/*   EXP   */

/* Stack is (<>) <exp_op> <right_operand> <left_operand> <...>
   Process the operation and reduce stack to (<>) <result_temporary> <...> */

	call process_expo (subscript_processing & ^suspend_subscript);
	return;

case (7):						/*   NEG   */

/* Stack is (<>) <neg_op> <operand> <...>  In the case where we are not currently evaluating
   a subscript expression, or we are evaluating a subscript expression but we have a true (non-zero) operand,
   we share code with the not_op case.  If we are evaluating a subscript expression at present, and the operand
   in the stack is a zero, it indicates that the true operand of the minus is the accumulated
   subscript value in sub_stack, and we negate it directly. */

	if ^subscript_processing | suspend_subscript
	then go to case (16);
	else if stack (work_stack_offset - 2) ^= 0
	then go to case (16);
	else do;
		sub_stack.dim.offset = -sub_stack.dim.offset;
		if sub_stack.dim.temp ^= 0
		then sub_stack.dim.mult = -sub_stack.dim.mult;
		call bump_work_stack_offset (-1);
	     end;
	return;

case (8):						/*   LESS   */
case (9):						/*   LESS_OR_EQUAL   */
case (10):					/*   EQUAL   */
case (11):					/*   NOT_EQUAL   */
case (12):					/*   GREATER_OR_EQUAL   */
case (13):					/*   GREATER   */

/* Stack is (<>) <rel_op> <right_operand> <left_operand> <...>
   we will simply make sure that the data types match, then share code with logical ops. */

	call get_data_type (2);
	call conversion;

case (14):					/*   OR   */
case (15):					/*   AND   */
case (103):					/*   EQUIV   */
case (104):					/*   NOT_EQUIV   */

/* Stack is (<>) <rel_or_log_op> <right_operand> <left_operand> <...>
   Create an appropriate quad, and reduce the stack to
   (<>) <logical_temporary_result> <...> */

	op_index = create_operator (2);
	stack (work_stack_offset) = create_temporary ((logical_mode));
	call bump_work_stack_offset (+1);
	return;

case (16):					/*   NOT   */

/* Stack is (<>) <unary_minus_or_not> <operand> <...>
   Create an appropriate quad, and reduce the stack to (<>) <result_temp> <...> */

	call get_data_type (1);
	op_index = create_operator (1);
	stack (work_stack_offset) = create_temporary (rand_data_type (1));
	call bump_work_stack_offset (+1);
	return;

case (17):					/*   JUMP   */

/* Stack is (<>) <jump_op> <label> <...>
   First check to see if this is a backwards reference, and if so, flag the target stmt.
   If this jump was contained in a statement of form "if expr goto label,"
   we will simply invert the sense of the containing if jump and replace its label  with
   the label from the stack.  Otherwise, create a jump_op quad.
   In any case, the stack is reduced to (<>) <...> */

	call search_label (stack (work_stack_offset - 2));
	if exit_offset > 0
	then if exit_stack.op = jump_false_op
	     then do;
		     exit_stack.op, exit_stack.ptr -> operator.op_code = jump_true_op;
		     exit_stack.ptr -> operator.operand (2) = stack (work_stack_offset - 2);
		     call bump_work_stack_offset (-2);
		     next_free_quad = next_free_quad - size (opt_statement);
		     op_index = addr (q (last_op_index)) -> opt_statement.prev_operator;
		     last_opt_statement = ptr (quadruple_base, addr (q (last_op_index)) -> opt_statement.back);
		     last_op_index = op_index;
		end;
	     else op_index = create_operator (1);
	else op_index = create_operator (1);
	return;

case (18):					/*   JUMP_LOGICAL   */

/* Stack is (<>) <jump_logical_op> <logical_expression> <...>
   We are processing the start of a logical if.  The conditionally executed part is terminated with
   an exit_op, so push the exit stack.  Create a jump_false_op quad whose first operand
   is the jump_logical_op and whose second operand is the logical expression.
   Keep the pointer to this quad in the exit_stack so that we can replace the jump_logical_op with the
   label of the next statement when we find out what it is.  In any case, reduce the stack
   to (<>) <...> */

	call push_exit_stack ();
	exit_stack.op, stack (work_stack_offset) = jump_false_op;

/*   The j_l_op will be replaced by a label */

	call bump_work_stack_offset (+1);
	op_index = create_operator (2);
	exit_stack.count = 0;
	exit_stack.ptr = last_quad_p;
	return;

case (19):					/*   JUMP_ARITHMETIC   */

/* Stack is (<>) <jump_arithmetic_op> <label1> <label2> <label3> <expression_value> <...>
   Check the labels which were supplied to see if any of them are backward references, and if so flag the targets.
   Create a jump_arithmetic_op quad, and make a hold_stack entry to note that any labels which
   were not supplied will have to be filled in with the following statement's label.
   Reduce stack to (<>) <...> */

	do i = work_stack_offset - 4 to work_stack_offset - 2;
	     if stack (i) > last_assigned_op
	     then call search_label (stack (i));
	end;
	op_index = create_operator (4);
	call push_hold_stack ();
	hold_stack.op_code = jump_arithmetic_op;
	hold_stack.ptr = last_quad_p;
	return;

case (20):					/*   JUMP_COMPUTED   */

/* Stack is (<>) <jump_computed_op> <count (of labels)> <...>
   List of labels will be terminated with eol_op, and the expression will be terminated with exit_op,
   so push both eol_stack and exit_stack.  Stack is reduced to
   (<>) <count> <...> */

	call push_exit_stack ();
	call push_eol_stack ();
	exit_stack.op = jump_computed_op;
	exit_stack.count = stack (work_stack_offset - 1);
	return;

case (21):					/*   JUMP_ASSIGNED   */

/* Stack is (<>) <jump_assigned_op> <label_variable> <...>
   Generate jump_assigned quad with label_var as operand and reduce stack  to (<>) <...> */

	op_index = create_operator (1);
	return;

case (22):					/*   ASSIGN_LABEL   */

/* Stack is (<>) <assign_label_op> <label_variable> <label> <...>
   Create assign_label_op quad with label as operand and label_variable as output
   (This necessitates swapping them in the stack, for create_operator.)  If label_variable is
   an array reference, increment it's ref_count.  Reduce stack to (<>) <...> */

	if addr (x (stack (work_stack_offset - 3))) -> node.node_type = label_node
	then if addr (x (stack (work_stack_offset - 3))) -> label.format
	     then stack (work_stack_offset - 3) = addr (x (stack (work_stack_offset - 3))) -> label.format_var;
	stack (work_stack_offset) = stack (work_stack_offset - 2);
	stack (work_stack_offset - 2) = stack (work_stack_offset - 3);
	stack (work_stack_offset - 3) = stack (work_stack_offset);
	op_index = create_operator (1);
	call bump_work_stack_offset (-1);
	last_quad_p -> operator.output = stack (work_stack_offset);
	if stack (work_stack_offset) > last_assigned_op
	then if addr (x (stack (work_stack_offset))) -> node.node_type = array_ref_node
	     then addr (x (stack (work_stack_offset))) -> array_ref.ref_count =
		     addr (x (stack (work_stack_offset))) -> array_ref.ref_count + 1;
	return;

case (23):					/*   READ   */
case (24):					/*   WRITE   */

/* Stack is (<>) <read or write> <constant> <expression> <...>
   Create a read or write node with 2 operands, and remember in last_io_op whether we are
   currently processing a read or a write io operation.  Reduce stack to (<>) <...> */

	last_io_op = stack (work_stack_offset - 1);
	op_index = create_operator (2);
	return;

case (25):					/*   FORMAT   */
case (26):					/*   END_LABEL   */
case (27):					/*   ERROR_LABEL   */

/* Stack is (<>) <one of above 3 ops> <appropriate operand> <...>
   Create the appropriate quad and reduce stack to (<>) <...> */

	op_index = create_operator (1);
	return;

case (28):					/*   XMIT_SCALAR   */
case (29):					/*   XMIT_ARRAY   */

/* Stack is (<>) <xmit_op> <variable> <...>
   (This code is also used by xmit vector stuff, which has one extra operand...hence, n_ops.)
   If the current io_statement is a read statement, generate an appropriate read_xx node, with
   the given variable as the output.  If the variable is an array ref, increment its ref_count.
   If the current io_statement is a write statement, generate an appropriate write_xx node,
   with the given variable as an operand.
   Stack is reduced to (<>) <...> */
/* NOTE that this requires a certain ordering of the (xmit read write)_xx_ops */

	n_ops = 0;
xmit_ops:
	if last_io_op = read_op
	then do;
		stack (work_stack_offset - 1) = stack (work_stack_offset - 1) + read_scalar_op - xmit_scalar_op;
		op_index = create_operator (n_ops);
		call bump_work_stack_offset (-1);
		last_quad_p -> operator.output = stack (work_stack_offset);
		if stack (work_stack_offset) > last_assigned_op
		then if addr (x (stack (work_stack_offset))) -> node.node_type = array_ref_node
		     then addr (x (stack (work_stack_offset))) -> array_ref.ref_count =
			     addr (x (stack (work_stack_offset))) -> array_ref.ref_count + 1;
	     end;
	else do;
		stack (work_stack_offset - 1) = stack (work_stack_offset - 1) + write_scalar_op - xmit_scalar_op;
		op_index = create_operator (n_ops + 1);
	     end;
	if exit_offset ^= 0
	then if exit_stack.op = do_op
	     then exit_stack.xmit_at_this_level = exit_stack.xmit_at_this_level + 1;
	return;

case (30):					/*   XMIT_VECTOR   */

/* Stack is (<>) <xmit_vector_op> <length> <variable_start> <...>
   Set n_ops and then we can use xmit_op code above. */

	n_ops = 1;
	go to xmit_ops;

case (31):					/*   ENDFILE   */
case (32):					/*   REWIND   */
case (33):					/*   BACKSPACE   */

/* Stack is (<>) <one of above 3 ops> <job bits> <unit number> <...>
   Create an appropriate quad with two operands as given, and reduce stack to (<>) <...> */

	op_index = create_operator (2);
	return;

case (34):					/*   MARGIN   */

/* Stack is (<>) <margin_op> <expr1> <expr2> <...>
   Create an appropriate node with the 2 given operands, and reduce the stack
   to (<>) <...> */

	op_index = create_operator (2);
	return;

case (35):					/*   OPENFILE   */

/* Stack is (<>) <openfile_op> <operand1> <operand2> <operand3> <...>
   Create an openfile_op node with 3 operands, and reduce stack to (<>) <...> */

	op_index = create_operator (3);
	return;

case (36):					/*   CLOSEFILE   */
case (37):					/*   RECORD_NUMBER   */

/* Stack is (<>) <one of above 2 ops> <operand> <...>
   Create an appropriate node with 1 operand, reduce stack to (<>) <...> */

	op_index = create_operator (1);
	return;

case (38):					/*   STRING   */

/* The parse should not make these when optimizing.  Crawl off and die. */

	go to case (0);

case (39):					/*   STRING_LENGTH   */

/* Stack is (<>) <string_length_op> <operand> <...>
   Create the node with 1 operand and reduce stack to (<>) <...> */

	op_index = create_operator (1);
	return;

case (40):					/*   TERMINATE   */

/* end of io statement.  Reset last_io_op. */

	last_io_op = 0;

case (41):					/*   RETURN   */

/* Stack is (<>) <terminate or return> <...>
   Generate node with no operands, reduce stack to (<>) <...> */

	op_index = create_operator (0);
	return;

case (42):					/*   PAUSE   */
case (43):					/*   STOP   */

/* Stack is (<>) <stop or pause> <operand> <...>
   Generate node with 1 operand, reduce stack to (<>) <...> */

	op_index = create_operator (1);
	return;

case (44):					/*   ITEM   */

/* Stack is (<>) <item_op> <...>   Further details and action taken depend upon the type of
   list being processed, which information is held in eol_stack.op */

/* If current list is a subscript_op list then top of stack is
   (<>) <item_op> <subscript_expr> <array_var> <...>
   If this is the last dimension, process_1_subscript will return stack
   (<>) <array_ref_node> <...>
   Otherwise, it will return with stack (<>) <array_var> <...>
   The subscript information is accumulated in the sub_stack entry .*/

	if eol_stack.op = subscript_op
	then call process_1_subscript ();

/* If current list is  related to an open_op, close_op, or inquire_op, then top of
   stack is (<>) <item_op> {<count> <halfword>} <...>
   Throw away the item op, and increment the count of items (parse didn't count 'em).
   Stack becomes (<>) {<count> <halfword>} <...> */

	else if eol_stack.op = open_op | eol_stack.op = close_op | eol_stack.op = inquire_op
	then do;
		stack (eol_stack.work_stack_offset) = stack (eol_stack.work_stack_offset) + 1;
		call bump_work_stack_offset (-1);
	     end;

/* If the current list is related to an active statement_function reference op, then top of stack
   is (<>) <item_op> <statement_func argument> <...>
   If too many arguments have been supplied, we simply throw this one away.  Otherwise, we
   determine whether the argument data_type matches that of the corresponding dummy argument, and
   if not, generate an appropriate conversion.  The argument is remembered in the arg_info array of
   the sf_stack.  The current pointer into the quad chain is remembered as the end of the
   calculations involved in evaluating this argument and as the start of the calculations involved
   in calculating the next argument, if another is expected.  (If there were no calculations, i.e.
   an element argument, these chain ptrs are set to zero.) These chains are used to allow
   rechaining of the argument calculation in at the point of first use later on.  Both the item_op
   and the argument are popped from the stack, leaving (<>) <...> */

	else if eol_stack.op = sf_op
	then do;
		if sf_stack.cur_sf_param = 0
		then do;
			call bump_work_stack_offset (-2);
			return;
		     end;
		i = sf_stack.cur_sf_param;
		sf_stack.cur_sf_param = addr (x (i)) -> symbol.next_member;

		if addr (x (i)) -> symbol.data_type ^= addr (x (stack (work_stack_offset - 2))) -> node.data_type
		then do;
			stack (work_stack_offset - 1) = convert_to_int_op + addr (x (i)) -> symbol.data_type - 1;
			op_index = create_operator (1);
			stack (work_stack_offset) = create_temporary ((addr (x (i)) -> symbol.data_type));
			call bump_work_stack_offset (+2);
		     end;
		sf_stack.arg_info (sf_stack.current_arg).operand = stack (work_stack_offset - 2);
		if sf_stack.arg_info (sf_stack.current_arg).chain_start = last_op_index
		then sf_stack.arg_info (sf_stack.current_arg).chain_start = 0;
		else do;
			sf_stack.arg_info (sf_stack.current_arg).chain_end = last_op_index;
			sf_stack.arg_info (sf_stack.current_arg).chain_start =
			     addr (q (sf_stack.arg_info (sf_stack.current_arg).chain_start)) -> operator.next;
		     end;
		sf_stack.current_arg = sf_stack.current_arg + 1;
		if sf_stack.current_arg <= sf_stack.num_args
		then sf_stack.arg_info (sf_stack.current_arg).chain_start = last_op_index;
		call bump_work_stack_offset (-2);
	     end;

/* If the current list is related to a block IF statement, then we have
   reached the end of a clause.  If this is not the last clause of the block
   IF, then we emit a jump_op to skip the remaining clauses.  If the clause
   was started with an IF or ELSE IF, we create a hold_stack entry so that
   the conditional branch to skip the clause may be filled in.  Also, if the
   clause was started with an IF or ELSE IF, and this is not the last clause,
   then we create a dummy opt_statement operator so that the test can branch
   to the proper location. */

	else if eol_stack.op = block_if_op
	then do;
		block_if_stack.clause = block_if_stack.clause + 1;

		if block_if_stack.clause < block_if_stack.n_clauses
		then do;
			stack (work_stack_offset - 1) = 0;
			stack (work_stack_offset) = jump_op;
			call bump_work_stack_offset (+1);
			op_index = create_operator (1);
			block_if_stack.n_jumps = block_if_stack.n_jumps + 1;
			block_if_stack.jump (block_if_stack.n_jumps) = op_index;
			opst -> opt_statement.removable = "1"b;
		     end;
		else call bump_work_stack_offset (-1);

		if block_if_stack.test_op ^= 0
		then do;
			call push_hold_stack ();
			hold_stack.op_code = jump_false_op;
			hold_stack.ptr = addr (q (block_if_stack.test_op));
			if block_if_stack.clause < block_if_stack.n_clauses
			then do;
				opst = create_opt_statement ();
				opst -> opt_statement.put_in_profile = "0"b;
				opst -> opt_statement.put_in_map = "1"b;
				call process_hold_stack_entry ();
			     end;

		     end;
	     end;

/* In any other case, stack is (<>) <item_op> <some list item> <...>
   We simply toss the item op, leaving (<>) <some_list_item> <...> */

	else call bump_work_stack_offset (-1);
	return;

case (45):					/*   EXIT   */

/* Top of stack is (<>) <exit_op> <...>   Further details and action taken depend upon the type
   of operation with which this exit_op is associated.  This information is held in exit_stack. */

/* If the exit_op is related to a jump_true or jump_false op, then the top of stack
   is (<>) <exit_op> <...>    Create a hold_stack entry, indicating that we will need to fill
   in a label in the jump when we know the label of the next statement.  Throw away the exit op,
   leaving (<>) <...> */

	if exit_stack.op = jump_false_op | exit_stack.op = jump_true_op
	then do;
		call push_hold_stack ();
		hold_stack.op_code = exit_stack.op;
		hold_stack.ptr = exit_stack.ptr;
		call bump_work_stack_offset (-1);
	     end;

/* If the current exit_op is related to a jump_computed_op, it terminates the expression calculation.
   Top of stack is (<>) <exit_op> <expr> {<label>} <count> <...>   We convert the expr to integer, if it is not already,
   check each of the labels to see if it involves a backwards reference, create a
   jump_computed node with the expr, labels, and count as operands, and pop the whole mess off
   the work stack, leaving (<>) <...> */

	else if exit_stack.op = jump_computed_op
	then do;
		call get_data_type (1);
		if rand_data_type (1) ^= int_mode
		then do;
			stack (work_stack_offset - 1) = convert_to_int_op;
			op_index = create_operator (1);
			call bump_work_stack_offset (+2);
			stack (work_stack_offset - 2) = create_temporary ((int_mode));
		     end;
		stack (work_stack_offset - 1) = jump_computed_op;

		do i = 1 to exit_stack.count + bias;
		     call search_label (stack (work_stack_offset - exit_stack.count - bias - 3 + i));
		end;

		op_index = create_operator (exit_stack.count + bias + 2);
	     end;

/* If the current exit_op is related to an sf_op, it means we have been evaluating a statement_function
   reference, which is done by saving the pointer into the polish at the point of reference and resetting
   it to run through the sf_definition, which is terminated by the exit_op.  We must move the pointer
   back to the point in the polish following the reference which is being evaluated.  The top of stack
   is (<>) <exit_op> <sf_result> <...>
   We check to see if the result data type matches that of the statement function, and if not, force  conversion.
   We pop the sf_stack entry corresponding to this sf reference, since the evaluation is done.
   The exit_op is tossed, leaving (<>) <sf_result> <...> */

	else if exit_stack.op = sf_op
	then do;
		polish_offset = sf_stack.polish_offset;
		if subscript_processing
		then do;
			if stack (work_stack_offset - 2) = 0 & sf_stack.def_chain -> symbol.data_type = int_mode
			     & (sub_stack.dim.temp = 0
			     | addr (x (sub_stack.dim.temp)) -> temporary.data_type = int_mode)
			then ;
			else do;
				true_rand = 1;
				call compress_subscript ();
			     end;
		     end;

		if stack (work_stack_offset - 2) ^= 0
		then do;
			if addr (x (stack (work_stack_offset - 2))) -> node.data_type
			     ^= sf_stack.def_chain -> symbol.data_type
			then do;
				stack (work_stack_offset - 1) =
				     convert_to_int_op - 1 + sf_stack.def_chain -> symbol.data_type;
				op_index = create_operator (1);
				stack (work_stack_offset) =
				     create_temporary ((sf_stack.def_chain -> symbol.data_type));
				if sf_stack.def_chain -> symbol.data_type = char_mode
				then addr (x (stack (work_stack_offset))) -> temporary.length =
					get_char_size ((sf_stack.def_chain)) + bias;
				call bump_work_stack_offset (+1);
			     end;
			else call bump_work_stack_offset (-1);
		     end;
		else call bump_work_stack_offset (-1);
		call pop_sf_stack ();
	     end;

/*   If the current exit_op is related to a do_op,  we've reached the end of a do-group.
   Top of stack is (<>) <exit_op> <*> <incr> <upper> <lower> <index_var> <...>
   The entry <*> is a do_op if the do_index var is also being used as the iteration counter, and is a
   compiler-generated unnamed symbol if a separate counter has been generated.
   We generate code to increment the formal index variable.  If a separate counter is being used, it is also
   incremented.  Nodes are then generated to test the index variable/counter and branch back if
   not done.  If the next operation in the polish is not a statement op (i.e. if this is an implied do)
   then we must generate a pseudo-statement to follow the do_group, so as not to confuse the optimizer.
   We must also arrange for that statement or the next statement to come along to get a label, which
   is used as the target of the zero_trip_branch generated at the beginning of the loop.
   The stack is left containing (<>) <...> */

	else if exit_stack.op = do_op
	then do;
		if hold_offset ^= 0 & last_io_op = 0
		then do;
			opst = create_opt_statement ();
			opst -> opt_statement.put_in_profile = "0"b;
			opst -> opt_statement.put_in_map = "1"b;
			call process_hold_stack_entry ();
		     end;

		stack (work_stack_offset - 1) /*   increment loop variable   */,
		     stack (work_stack_offset) = stack (work_stack_offset - 6);
		stack (work_stack_offset + 1) = stack (work_stack_offset - 3);
		stack (work_stack_offset + 2) = add_op;
		call bump_work_stack_offset (+3);
		call process_arith ("0"b);

		stack (work_stack_offset) = assign_op;
		call bump_work_stack_offset (+1);
		call process_assign ();

		if stack (work_stack_offset - 1) ^= do_op
						/*   a counter   */
		then do;
			stack (work_stack_offset) /*   increment counter   */,
			     stack (work_stack_offset + 1) = stack (work_stack_offset - 1);
			stack (work_stack_offset + 2) = one;
			stack (work_stack_offset + 3) = add_op;
			call bump_work_stack_offset (+4);
			call process_arith ("0"b);

			stack (work_stack_offset) = assign_op;
			call bump_work_stack_offset (+1);
			call process_assign ();
			stack (work_stack_offset - 5) = stack (work_stack_offset);
		     end;

		stack (work_stack_offset) = stack (work_stack_offset - 5);
		stack (work_stack_offset + 1) = stack (work_stack_offset - 3);
		stack (work_stack_offset + 2) = greater_op;
		call bump_work_stack_offset (+3);
		call get_data_type (2);
		call conversion;
		op_index = create_operator (2);

		stack (work_stack_offset) = create_temporary ((logical_mode));
		call bump_work_stack_offset (+1);
		stack (work_stack_offset) = exit_stack.do_label;
		stack (work_stack_offset + 1) = jump_false_op;
		call search_label (stack (work_stack_offset));

		call bump_work_stack_offset (+2);
		op_index = create_operator (2);

		if p (polish_offset + 1) ^= stat_op
		then do;
			opst = create_opt_statement ();
			opst -> opt_statement.put_in_profile = "0"b;
			opst -> opt_statement.put_in_map = "1"b;
			if exit_stack.zero_trip_branch ^= 0
			then do;
				i, addr (q (exit_stack.zero_trip_branch)) -> operator.operand (2) =
				     create_label (last_op_index);
				addr (x (i)) -> label.referenced_executable = "1"b;
				opst -> opt_statement.label = i;
			     end;
		     end;
		else if exit_stack.zero_trip_branch ^= 0
		then do;
			call push_hold_stack ();
			hold_stack.op_code = jump_false_op;
			hold_stack.ptr = addr (q (exit_stack.zero_trip_branch));
		     end;
		call bump_work_stack_offset (-5);
	     end;

/* If an exit_op shows up under any other circumstances, it's a level 4 error.  Go bomb out!!!!! */

	else call print_message (200, "45");

/* Having processed the exit_op, pop its entry from the exit_stack. */

	call pop_exit_stack ();
	return;

case (46):					/*   EOL   */

/* Top of stack is (<>) <eol_op> <...>   Further details and action taken depend upon the type
   of operation with which this eol_op is associated.  This information is held in eol_stack.
   Note that process_eol_stack also pops the eol_stack. */

/* If the eol is associated with a jump_computed op, it terminates the list of labels.  Stack is
   (<>) <eol_op> {<label>} <count> <...>    We can't create the node until we have
   evaluated the controlling expression.  Simply throw out the eol_op and pop the eol_stack,
   leaving the stack as (<>) {<label>} <count> <...> */

	if eol_stack.op = jump_computed_op
	then do;
		call bump_work_stack_offset (-1);
		call pop_eol_stack ();
	     end;

/*   If the eol_op is associated with a chain_op, the top of the stack is
   (<>) <eol_op> {<expression>} <count> <string expr> <string expr> <...>
   Call process_eol_stack to combine the whole mess into a chain_op node, and clean up the stack.
   Stack will be left containing (<>) <...> */

	else if eol_stack.op = chain_op
	then call process_eol_stack (1, 3);

/* If the eol_op is associuated with an open or close op, the top of the stack is
   (<>) <eol_op> {<count> <halfword>} <count> <const> <const> <expr> <...>
   Call process_eol_stack to combine the whole mess into an appropriate node, and clean up the stack.
   Stack will be left containing (<>) <...> */

	else if eol_stack.op = open_op | eol_stack.op = close_op
	then call process_eol_stack (2, 4);

/* If the eol_op is associated with a call, top of the stack is
   (<>) <eol_op> {<args>} <count> <entry> <...>
   Call process_eol_stack to produce an appropriate node, and clean up the stack.
   Stack will be left containing (<>) <...> */

	else if eol_stack.op = call_op
	then call process_eol_stack (1, 2);

/* If the eol_op is associated with a process_param_list_op, top of stack is
   (<>) <eol_op> {<args>} <count> <...>
   Call process_eol_stack to produce an appropriate node, and clean up the stack.
   Stack will be left containing (<>) <...> */

	else if eol_stack.op = process_param_list_op
	then call process_eol_stack (1, 1);

/* If the eol_op is associated with a func_ref_op, the top of the stack is
   (<>) <eol_op> {<arg>} <count> <func> <...>
   Call process_eol_stack to create the func_ref_node, and create_temporary to create a temp for its output.
   Stack is left containing (<>) <function_value> <...> */

	else if eol_stack.op = func_ref_op
	then do;
		call process_eol_stack (1, 2);
		temp_node_ptr = addr (x (addr (q (op_index)) -> operator.operand (1)));
		stack (work_stack_offset) = create_temporary ((temp_node_ptr -> symbol.data_type));
		if temp_node_ptr -> symbol.data_type = char_mode
		then addr (x (stack (work_stack_offset))) -> temporary.length = get_char_size (temp_node_ptr) + bias;
		call bump_work_stack_offset (+1);
	     end;

/* If the eol_op is associated with a builtin_op, the top of the stack is
   (<>) <eol_op> {<arg>} <count> <entry> <...>
   Call process_builtin to process the stack, build a builtin_node, pop the eol_stack,
   and clean up the work stack leaving (<>) <result> <...> */

	else if eol_stack.op = builtin_op
	then do;
		call process_builtin ();
	     end;

/* If the eol_op is associated with a subscript_op, we've already done all the work when we saw the item_op.
   Top of stack is (<>) <eol_op> <array_ref_node> <...>
   We pop the sub_stack and the eol_stack, and clean up the work stack, leaving
   (<>) <array_ref_node> <...> */

	else if eol_stack.op = subscript_op
	then do;
		call bump_work_stack_offset (-1);
		call pop_sub_stack ();
		call pop_eol_stack ();
	     end;

/* If the eol_op is associated with a statement_function reference, all needed info will have been placed into the sf_stack
   by now.  The top of the stack is merely (<>) <eol_op> <...>   Process_sf_stack will cause the sf_to
   be evaluated by saving the current pointer into the polish, setting it to point back into the sf definition
   and cleaning the eol off of the work stack, leaving (<>) <...>.  The converter will process happly thru the sf definition
   generating cnodes with appropriate subscript substitutions, until it hits the exit_op
   at the end of the definition.  Then the polish pointer will be reset.  process_sf pops the eol_stack and
   pushes an entry onto the exit_stack. */

	else if eol_stack.op = sf_op
	then call process_sf ();

/* If the eol_op is associated with a block IF statement, we have reached the
   end of the entire block IF (i.e. the ENDIF statement).  The jump_ops
   which appear at the end of each clause but the last must now be filled in.
   This is accomplished by creating a hold_stack entry for the block_if_op.
   When the hold_stack entry is processed, the block_if_stack will be popped.
   The eol_stack is popped explicitly here. */

	else if eol_stack.op = block_if_op
	then do;
		call pop_eol_stack ();
		call push_hold_stack ();
		hold_stack.op_code = block_if_op;
		hold_stack.ptr = null ();
		call bump_work_stack_offset (-1);
		opst -> opt_statement.removable = "1"b;
	     end;

/* If the eol_op is associated with an inquire_op, the top of the stack is
   (<>) <eol_op> {<count> <halfword>} <count> <fields specified> <job bits> <...>
   Call process_eol_stack to combine all of this into a single operator, popping
   the eol_stack and leaving the operand stack as (<>) <...> */

	else if eol_stack.op = inquire_op
	then call process_eol_stack (2, 3);

/* Any other eol_op which may turn up is a level 4 error.  Go away and die!!! */

	else call print_message (200, "46");
	return;

case (47):					/*   DO_OP   */

/* Top of stack is (<>) <do_op> <incr> <upper> <lower> <index var> <...>
   The do group will be terminated by an exit_op, so we push the exit_stack to remember that we expect it.
   Match_index_type is called to convert the upper, lower, and incr to match the index var, if needed.
   If the increment is an integer constant (which implies index is integer) then if the upper bound is
   not constant we assign it to a frozen_for_do temporary.  If the increment is not an integer constant,
   we generate the nodes necessary to compute a counter value which will actually be used for loop control.
   If it is necessary to generate such a counter, it will replace the do_op in the stack.
   If the increment is not constant, and we are compiling in ansi77 mode, the value of the increment
   must be assigned to a frozen_for_do temporary, which replaces the original increment in the stack.
   Whether or not a counter is generated, we must compile a conditional branch to skip the entire
   loop if it should be executed zero times.  The offset of the branch is remembered in
   exit_stack.zero_trip_branch, so that the correct label may be filled in later.
   After the conditional jump is emitted, a statement op is emitted to force the creation of a new
   flow unit, which will serve as the back target of the loop.
   If last_io_op ^= 0 we are processing an implied do in an io statement.  Optimize_vector will be called
   to see if the implied do can be optimized into an xmit_vector op.  If this optimization is done
   the assorted do info will be purged from the stack, and the polish input stack will be modified to contain
   an xmit_vector_op and appropriate count and vector info.  This is the one case where the converter may
   modify the polish input.
   If this is not an implied do, or is an unoptimizable implied do, a node will be generated to initialize the loop
   variable.  If not an implied do, a hold_stack entry will be generated, to remember that the label of the
   next statement must be kept as it begins the do-group; if an implied do, a statement_node will be generated,
   and it's label remembered, for the end_of_loop code to branch back to.
   The stack will be left as is, with the possible exception of a count  (if generated) replacing the do_op. */

	call push_exit_stack ();
	exit_stack.op = do_op;
	exit_stack.xmit_at_this_level = 0;
	exit_stack.ptr = null;
	exit_stack.zero_trip_branch = 0;
	call match_index_type ();
	r = addr (x (stack (work_stack_offset - 2)));

	if r -> node.node_type = constant_node & r -> node.data_type = int_mode
	then do;
		s = addr (x (stack (work_stack_offset - 3)));
		if s -> node.node_type ^= constant_node
		then do;
			stack (work_stack_offset) = stack (work_stack_offset - 3);
			stack (work_stack_offset + 1) = assign_op;
			call bump_work_stack_offset (+2);
			op_index = create_operator (1);
			stack (work_stack_offset - 3) = create_temporary ((int_mode));
			temp_ptr -> temporary.frozen_for_do = "1"b;
		     end;
	     end;
	else do;
		if r -> node.node_type ^= constant_node
		then if subp_ptr -> subprogram.options.ansi_77
		     then do;
			     stack (work_stack_offset) = stack (work_stack_offset - 2);
			     stack (work_stack_offset + 1) = assign_op;
			     call bump_work_stack_offset (+2);
			     op_index = create_operator (1);
			     stack (work_stack_offset - 2) = create_temporary ((r -> node.data_type));
			     temp_ptr -> temporary.frozen_for_do = "1"b;
			end;

		stack (work_stack_offset) = stack (work_stack_offset - 3);
		stack (work_stack_offset + 1) = stack (work_stack_offset - 4);
		stack (work_stack_offset + 2) = sub_op;
		call bump_work_stack_offset (+3);
		call process_arith ("0"b);

		stack (work_stack_offset) = stack (work_stack_offset - 3);
		stack (work_stack_offset + 1) = div_op;
		call bump_work_stack_offset (+2);
		call process_arith ("0"b);

		if addr (x (stack (work_stack_offset - 1))) -> node.data_type ^= int_mode
		then do;
			stack (work_stack_offset) = convert_to_int_op;
			call bump_work_stack_offset (+1);
			op_index = create_operator (1);
			call bump_work_stack_offset (+1);
			stack (work_stack_offset - 1) = create_temporary ((int_mode));
		     end;

		call bump_work_stack_offset (-1);

/* replace <upper> with the loop count just computed */

		stack (work_stack_offset - 3) = stack (work_stack_offset);

/* initialize counter to zero */

		stack (work_stack_offset - 1) = create_var ();
		stack (work_stack_offset) = zero;
		stack (work_stack_offset + 1) = assign_op;
		call bump_work_stack_offset (+2);
		call process_assign ();
		call bump_work_stack_offset (+1);
	     end;
	if last_io_op ^= 0
	then do;
		save_polish_offset = polish_offset;
		call optimize_vector ();
		if polish_offset < save_polish_offset
		then return;
	     end;

/*   initialize loop variable   */

	stack (work_stack_offset) = stack (work_stack_offset - 5);
	stack (work_stack_offset + 1) = stack (work_stack_offset - 4);
	stack (work_stack_offset + 2) = assign_op;
	call bump_work_stack_offset (+3);
	call process_assign ();
	exit_stack.ptr = last_quad_p;

/* generate conditional branch for zero trip loop */

	if subp_ptr -> subprogram.options.ansi_77
	then do;
		if r -> node.node_type = constant_node & r -> node.data_type = int_mode
		then do;
			stack (work_stack_offset) = stack (work_stack_offset - 3);
			stack (work_stack_offset + 1) = stack (work_stack_offset - 4);
			if substr (r -> constant.value, 1, 1)
						/* if < 0 */
			then stack (work_stack_offset + 2) = less_or_equal_op;
			else stack (work_stack_offset + 2) = greater_or_equal_op;
		     end;
		else do;
			stack (work_stack_offset) = stack (work_stack_offset - 3);
			stack (work_stack_offset + 1) = zero;
			stack (work_stack_offset + 2) = greater_or_equal_op;
		     end;
		call bump_work_stack_offset (+3);
		op_index = create_operator (2);
		stack (work_stack_offset) = create_temporary ((logical_mode));
		stack (work_stack_offset + 1) = 0;
		stack (work_stack_offset + 2) = jump_false_op;
		call bump_work_stack_offset (+3);
		op_index = create_operator (2);
		exit_stack.zero_trip_branch = op_index;

		opst = create_opt_statement ();
		opst -> opt_statement.put_in_profile = "0"b;
		opst -> opt_statement.put_in_map = "1"b;
	     end;

	if last_io_op ^= 0
	then do;
		opst = create_opt_statement ();
		opst -> opt_statement.put_in_profile = "0"b;
		opst -> opt_statement.put_in_map = "1"b;
		opst -> opt_statement.label, i = create_label (last_op_index);
		opst -> opt_statement.referenced_backwards = "1"b;
		addr (x (i)) -> label.referenced_executable = "1"b;
		exit_stack.do_label = i;
	     end;
	else do;
		call push_hold_stack ();
		hold_stack.op_code = stat_op;
		hold_stack.ptr = opst;
	     end;
	return;

case (48):					/*   BUILTIN   */

/* Top of stack is (<>) <builtin_op> <count> <function> <...>
   Processing happens when we see the eol_op.  Push the eol_stack and pitch the builtin_op, leaving the stack as
   (<>) <count> <function> <...> */
	call push_eol_stack ();
	return;

case (49):					/*   SF   */

/* Top of stack is (<>) <sf_op> <count> <function> <...>
   Processing occurs when we see the eol_op.  Push the eol_stack and pitch the sf_op.  We must also
   create an entry in the sf_stack to hold info about the arguments as they are evaluated, and to
   remember the function name and count.  Stack becomes (<>) <...> */

	call push_eol_stack ();
	call push_sf_stack ();
	return;

case (50):					/*   SF_DEF   */

/* Nothing to do for statement function definitions.  Stack is (<>) <sf_def_op> <function> <...>
   Set symbol.initial for the function name to point to the definition in the polish.
   If this is the first sf_def, set put_in_map on the statement node
   for the jump around the definitions to 0 in order to prevent anomalies in the object listing.
   Pitch the statement node since there will be no statement.  Skip past the definition in the
   polish stack.  Clean up the work stack, leaving (<>) <...> */

	addr (x (stack (work_stack_offset - 2))) -> symbol.initial = polish_offset + 1;
	call bump_work_stack_offset (-2);
	do polish_offset = polish_offset + 1 by 1 while (p (polish_offset) ^= exit_op);
	end;

	if ^first_statement_function_done
	then unspec (addr (q (fixed (opst -> opt_statement.back, 18))) -> opt_statement.bits) = "0"b;
	first_statement_function_done = "1"b;
	next_free_quad = next_free_quad - size (opt_statement);
	op_index = addr (q (last_op_index)) -> opt_statement.prev_operator;
	last_opt_statement = ptr (quadruple_base, addr (q (last_op_index)) -> opt_statement.back);
	last_op_index = op_index;
	opst = last_opt_statement;
	profile_size = profile_size - 1;
	return;

case (51):					/*   SUBSCRIPT   */

/* Top of stack is (<>) <subscript_op> <count> <array_var> <...>
   We set up an eol_stack entry, since this construct will be terminated with an eol, and a
   sub_stack entry to keep track of the subscript calculations.  Set the subscript_processing flag
   for the arithmetic_op processing routines.  We call initialize_subscript to give the array
   its dimension sizes and virtual origin.  The stack becomes (<>) <array_var> <...> */

	call push_eol_stack ();
	call push_sub_stack ();
	subscript_processing = "1"b;
	call bump_work_stack_offset (-1);
	sub_stack.n_dimensions = stack (work_stack_offset) + bias;
	sub_stack.symbol_node = addr (x (stack (work_stack_offset - 1)));
	sub_stack.dim_node = addr (x (sub_stack.symbol_node -> symbol.dimension));
	sub_stack.dim.mult = 1;
	sub_stack.dimension = 1;
	sub_stack.cum.temp = 0;
	sub_stack.cum.constant = 0;
	sub_stack.dim.temp = 0;

	if sub_stack.symbol_node -> symbol.star_extents
	then do;
		sub_stack.element.constant = 1;
		sub_stack.element.var = sub_stack.symbol_node -> symbol.v_length;
	     end;
	else do;
		sub_stack.element.constant = sub_stack.symbol_node -> symbol.element_size;
		sub_stack.element.var = 0;
	     end;

	call initialize_subscript ((sub_stack.symbol_node));

/*  If this is a VLA, generate a quad to subtract the virtual origin from    */
/*  the base address of the VLA and leave the difference in 'cum.temp'.  We  */
/*  don't need to treat a constant virtual origin of zero specially, since   */
/*  the optimizer ignores a subtraction of zero!                             */

	if sub_stack.symbol_node -> symbol.VLA
	then do;
		stack (work_stack_offset) = sub_stack.dim_node -> dimension.VLA_base_addressor;
		if sub_stack.dim_node -> dimension.variable_virtual_origin
		then stack (work_stack_offset + 1) = sub_stack.dim_node -> dimension.virtual_origin;
		else stack (work_stack_offset + 1) =
			create_integer_constant (sub_stack.dim_node -> dimension.virtual_origin
			- sub_stack.symbol_node -> symbol.offset);
		stack (work_stack_offset + 2) = sub_op;
		call bump_work_stack_offset (+3);
		call process_arith ("0"b);
		call bump_work_stack_offset (-1);
		sub_stack.cum.temp = stack (work_stack_offset);
	     end;

	return;

case (52):					/*   FUNC_REF   */

/* Top of stack is (<>) <func_ref_op> <count> <function> <...>   Simply create an eol_stack
   entry, and pitch the func_ref_op, leaving (<>) <count> <function> <...> */

	calls_local_entries = is_local ((stack (work_stack_offset - 3)));
	call push_eol_stack ();
	return;

case (53):					/*   BLOCK_DATA   */

/* Top of stack is (<>) <block_data_op> <...>   Create a node of 0 operands, and pop the op,
   leaving (<>) <...>*/

	op_index = create_operator (0);
	return;

case (54):					/*   INCREMENT_POLISH   */

/* Top of stack is (<>) <increment_polish_op> <...  and the next item in the polish stack
   is the number of polish entries to skip over.  Move the polish pointer ahead the given
   amount, and toss the increment_polish_op, leaving the stack as (<>) <...> */

	call bump_work_stack_offset (-1);
	polish_offset = polish_offset + p (polish_offset + 1) + 1;
	if polish_offset > polish_max_len
	then call print_message (201);
	return;

case (55):					/*   MAIN   */
case (56):					/*   FUNC   */
case (57):					/*   SUBR   */

/* Top of stack is (<>) <main or func or subr> <count> <entry> <...>
   Create an appropriate quad with the 2 given operands, and reduce the
   stack to (<>) <...> */

	op_index = create_operator (2);
	return;

case (58):					/*   STAT   */
case (59):					/*   LABEL   */

/* Stat and label ops are supposed to be processed by the calling program.  If any show up here
   something foul has occurred.  Go crawl into a hole and die. */

	go to case (0);

case (60):					/*   CALL   */

/* Top of stack is (<>) <call_op> <count> <external> <...>.  Push an eol_stack
   entry, since processing has to await the list, and pop the call_op leaving
   (<>) <count> <external> <...>. */

	calls_local_entries = is_local ((stack (work_stack_offset - 3)));
	call push_eol_stack ();
	return;

case (61):					/*   CHAIN   */

/* Top of stack is (<>) <chain_op> <count> <string_expr> <string_expr> <...>.
   Push an eol_stack entry, since processing has to await the list, and pop
   the chain_op, leaving (<>) <count> <string_expr> <string_expr> <...>. */

	call push_eol_stack ();
	return;

case (62):					/*   ENDUNIT   */

/* Top of stack is (<>) <endunit_op> <...>  Make a node of 0 operands, pop the op,
   leaving (<>) <...>  and set subprogram.last_quad to point to the node. */

	op_index = create_operator (0);
	subp_ptr -> subprogram.last_quad = op_index;
	return;

case (63):					/*   NON_EXECUTABLE   */
case (64):					/*   NO_OP   */

/* Top of stack is (<>) <one of above 2 ops> <...>   Make a node of 0 operands, and pop the op,
   leaving (<>) <...> */

	op_index = create_operator (0);
	return;

case (65):					/*   INDIRECT_SCAN   */
case (66):					/*   OPT_SUBSCRIPT   */
case (67):					/*   LEFT_SHIFT   */
case (68):					/*   RIGHT_SHIFT   */
case (69):					/*   STORE_ZERO   */
case (70):					/*   STORAGE_ADD   */
case (71):					/*   STORAGE_SUB   */
case (72):					/*   NEG_STORAGE_ADD   */
case (73):					/*   STORAGE_ADD_ONE   */
case (74):					/*   NAMELIST   */

/* None of the above 10 ops is supposed to be output by the parse.  If they show up, we've
   screwed up somewhere.  Crawl off and die. */

	go to case (0);

case (75):					/*   OPEN   */
case (76):					/*   CLOSE   */

/* Top of stack is (<>) <open or close _op> <count> <constant> <constant> <expr> <...>
   Push an eol_stack entry, and toss the op, leaving the stack as
   (<>) <count> <constant> <constant> <expr> <...> */

	call push_eol_stack ();
	return;

case (77):					/*   IO_STAT   */

/* Top of stack is (<>) <iostat_op> <var> <...>   Iostat takes no operands, and uses var as its
   output.  Create a node of 0 variables, attach var as its output, and increment var's reference count if
   var is an array_ref.  Clean stack, leaving (<>) <...> */

	op_index = create_operator (0);
	call bump_work_stack_offset (-1);
	last_quad_p -> operator.output = stack (work_stack_offset);
	if stack (work_stack_offset) > last_assigned_op
	then if addr (x (stack (work_stack_offset))) -> node.node_type = array_ref_node
	     then addr (x (stack (work_stack_offset))) -> array_ref.ref_count =
		     addr (x (stack (work_stack_offset))) -> array_ref.ref_count + 1;
	return;

case (78):					/*   CONVERT_TO_INT   */
case (79):					/*   CONVERT_TO_REAL   */
case (80):					/*   CONVERT_TO_DP   */
case (81):					/*   CONVERT_TO_CMPX   */
case (82):					/*   READ_SCALAR   */
case (83):					/*   READ_ARRAY   */
case (84):					/*   READ_VECTOR   */
case (85):					/*   WRITE_SCALAR   */
case (86):					/*   WRITE_ARRAY   */
case (87):					/*   WRITE_VECTOR   */
case (88):					/*   JUMP_TRUE   */
case (89):					/*   JUMP_FALSE   */
case (90):					/*   SUB_INDEX   */
case (91):					/*   LOOP_END_OP   */

/* Last 14 ops are not output by parse.  If we see one here, it's an error. Go off and die! */

	go to case (0);

case (92):					/*   READ_NAMELIST_OP   */
case (93):					/*   WRITE_NAMELIST_OP   */

/* Top of stack is (<>) <(read write)_namelist_op> <expr> <...>   Create the node with one operand.
   Clean off the stack, leaving (<>) <...> */

	op_index = create_operator (1);
	return;

case (94):					/*   DECODE_STRING_OP   */
case (105):					/*   READ_INTERNAL_FILE   */

/* Top of stack is (<>) <decode_string_op> <operand> <...>
   Create a node of 1 operand, and clean up the stack, leaving (<>) <...> */

	op_index = create_operator (1);
	return;

case (95):					/*   ENCODE_STRING_OP   */
case (106):					/*   WRITE_INTERNAL_FILE   */

/* Top of stack is (<>) <encode_string_op> <output_operand> <...>
   Create a node of 0 operands, and fill in the output.
   Clean up the stack, leaving (<>) <...> */

	op_index = create_operator (0);
	call bump_work_stack_offset (-1);
	last_quad_p -> operator.output = stack (work_stack_offset);
	if stack (work_stack_offset) > last_assigned_op
	then if addr (x (stack (work_stack_offset))) -> node.node_type = array_ref_node
	     then addr (x (stack (work_stack_offset))) -> array_ref.ref_count =
		     addr (x (stack (work_stack_offset))) -> array_ref.ref_count + 1;
	return;

case (96):					/*   CAT_OP   */

/* Top of stack is (<>) <cat_op> <right_operand> <left_operand> <...>
   Create a quad to compute the length of the result, and run it through a
   sub_index operator.  Then create a quad for the concatenation itself.
   Linearize adjacent concatenation operators by calling compress_concat.
   The stack is left (<>) <output_temp> <...> */

	if ^subp_ptr -> subprogram.options.ansi_77
	then call print_message (153);

	concatenates_star_extents = is_star_extent ((stack (work_stack_offset - 3)))
	     | is_star_extent ((stack (work_stack_offset - 2)));

	i = get_char_size (addr (x (stack (work_stack_offset - 3))));
	if i < 0
	then i = create_integer_constant (i + bias);
	stack (work_stack_offset - 1) = i;

	i = get_char_size (addr (x (stack (work_stack_offset - 2))));
	if i < 0
	then i = create_integer_constant (i + bias);
	stack (work_stack_offset) = i;

	stack (work_stack_offset + 1) = add_op;
	call bump_work_stack_offset (+2);
	call process_arith ("0"b);
	stack (work_stack_offset) = sub_index_op;
	call bump_work_stack_offset (+1);
	op_index = create_operator (1);
	stack (work_stack_offset) = create_temporary ((int_mode));
	stack (work_stack_offset + 1) = cat_op;
	call bump_work_stack_offset (+2);
	op_index = create_operator (3);
	stack (work_stack_offset) = create_temporary ((char_mode));
	call bump_work_stack_offset (+1);
	call compress_concat ();
	return;

case (97):					/*   SUBSTR_OP   */

/* Top of stack is (<>) <substr_op><upper_bound><lower_bound><parent>...
    Create an opt_substr node in the quads with 4 operand: symbol, constant-offset,
    variable offset, and length.  All this processing is done in process_substr,
    and the stack is left as: (<>) <array_ref> ... */

	call process_substr ();
	return;

case (98):					/* LOAD_XREG_OP */
case (99):					/* LOAD_PREG_OP */

/* The parse should not create either of the last two ops.  Crawl off and die. */

	go to case (0);

case (100):					/* BLOCK_IF_OP */

/* Top of stack is (<>) <block_if_op> <clause_count> <predicate> <...>
   We push the eol_stack, since the block_if_op begins a list of clauses,
   and we push an entry onto the block_if_stack to remember various things
   about this block IF statement.  A jump_false_op based on the predicate
   is generated to skip the first clause.  The stack is left (<>) <...> */

	call push_eol_stack ();

	block_if_clause_count = stack (work_stack_offset - 1) + bias;
	call push_block_if_stack ();
	block_if_stack.clause = 0;
	block_if_stack.n_jumps = 0;

	stack (work_stack_offset - 1) = 0;
	stack (work_stack_offset) = jump_false_op;
	call bump_work_stack_offset (+1);
	op_index = create_operator (2);

	block_if_stack.test_op = op_index;

	return;

case (101):					/* ELSE_IF_OP */

/* Top of stack is (<>) <else_if_op> <predicate> <...>
   We emit a jump_false_op based on the predicate to skip this clause of
   the block IF.  The stack is left (<>) <...> */

	stack (work_stack_offset - 1) = 0;
	stack (work_stack_offset) = jump_false_op;
	call bump_work_stack_offset (+1);
	op_index = create_operator (2);
	block_if_stack.test_op = op_index;
	return;

case (102):					/* ELSE_OP */

/* The else_op takes no arguments, and does nothing except mark the beginning
   of a simple ELSE clause.  We need do nothing with it here. */

	block_if_stack.test_op = 0;
	call bump_work_stack_offset (-1);
	return;

case (107):					/* INQUIRE */

/* Top of stack is (<>) <inquire op> <count> <fields specified> <job bits> <...>
   Push an eol_stack entry, and pop the inquire op, leaving the stack as
   (<>) <count> <fields specified> <job bits> <...> */

	call push_eol_stack ();
	return;

case (108):					/* PROCESS_PARAM_LIST */

/* Top of stack is (<>) <process_param_list_op> <count> <...>
   Push an eol_stack entry and toss the operator, leaving the stack as
   (<>) <count> <...> */

	call push_eol_stack ();
	return;

case (109):					/* LHS_FLD */

/* Top of stack is (<>) <lhs_fld_op> <right_hand_side> <argument3>
   <argument2> <argument1> <...> */

	call process_lhs_fld ();
	return;

     end process_operator;

process_assign:
     proc ();

/* Called with the top of stack (<>) <assign_op> <right_side> <target> <...>
   Does appropriate things with the assignment, as indicated below, and Cleans out the stack,
   leaving (<>) <...> */

/* Get rand_data_type(1) (= data type of target), rand_data_type(2) (= data type of source), and combination_type, which is
   a function of rand_data_type(1) and rand_data_type(2) */

	call get_data_type (2);
	go to assign_l (combination_type);

assign_l (1):					/*  INTEGER = INTEGER   */
	go to no_convert;
assign_l (2):					/*  REAL = INTEGER  */
assign_l (3):					/*  DP = INTEGER  */
assign_l (4):					/*  CMPX = INTEGER  */
assign_l (5):					/*  INTEGER = REAL  */
	go to convert;
assign_l (6):					/*  REAL = REAL  */
assign_l (7):					/*  DP = REAL  */
assign_l (8):					/*  CMPX = REAL  */
	go to no_convert;
assign_l (9):					/*  INTEGER = DP  */
	go to convert;
assign_l (10):					/*  REAL = DP  */
assign_l (11):					/*  DP = DP  */
assign_l (12):					/*  CMPX = DP  */
	go to no_convert;
assign_l (13):					/*  INTEGER = CMPX  */
convert:

/* Explicit convert generated iff one side of assign is integer
   and the other side is non_integer arithmetic data_type. */

/* NOTE: This block requires a certain ordering of the convert_to_xx operators. */

	stack (work_stack_offset) = stack (work_stack_offset - 2);
	stack (work_stack_offset + 1) = convert_to_int_op - 1 + rand_data_type (1);
	call bump_work_stack_offset (+2);
	op_index = create_operator (1);
	stack (work_stack_offset - 2) = create_temporary (rand_data_type (1));

assign_l (14):					/*  REAL = CMPX  */
assign_l (15):					/*  DP = CMPX  */
assign_l (16):					/*  DP = DP  */
assign_l (17):					/*  anything = data_type>complex  */
assign_l (18):					/*  data_type>complex = data_type<=complex  */
no_convert:

/* IF the target is an array_ref, we must increment its reference count */

	if stack (work_stack_offset - 3) > last_assigned_op
	then if addr (x (stack (work_stack_offset - 3))) -> node.node_type = array_ref_node
	     then addr (x (stack (work_stack_offset - 3))) -> array_ref.ref_count =
		     addr (x (stack (work_stack_offset - 3))) -> array_ref.ref_count + 1;

/* If the assignment is of a function return value to a variable of the same data type, then we
   will simply place the target of the assignment into the output entry of the function_ref node
   and not generate an assignment node. */

	if rand_data_type (1) = rand_data_type (2)
	then do;
		call get_node_type (2);
		if rand_node_type (2) = temporary_node
		then if addr (q (addr (x (stack (work_stack_offset - 2))) -> temporary.output_by)) -> operator.op_code
			= func_ref_op
		     then if rand_data_type (1) ^= char_mode
			     | (get_char_size (addr (x (stack (work_stack_offset - 2))))
			     = get_char_size (addr (x (stack (work_stack_offset - 3)))))
			then do;
				addr (q (op_index)) -> operator.output = stack (work_stack_offset - 3);
				call bump_work_stack_offset (-3);
				return;
			     end;
	     end;

/* Make the assignment node, and clean up the stack. */

	op_index = create_operator (1);
	call bump_work_stack_offset (-1);
	last_quad_p -> operator.output = stack (work_stack_offset);
	return;
     end process_assign;

process_arith:
     proc (subscript_mode);

dcl	constant_value	fixed bin (18);
dcl	subscript_mode	bit (1) aligned;

/* Called with top of stack (<>) <+|-|/|*> <right_hand_rand> <left_hand_rand> <...>
   Does appropriate things with the binary op, and returns leaving the result in the stack,
   as (<>) <value> <...> */

	call get_data_type (2);
	call get_node_type (2);

/* If the operator is add or multiply, we'll put the operands into a consistent order
   to improve the likelihood of finding common sub_expressions. */

	if stack (work_stack_offset - 1) = add_op | stack (work_stack_offset - 1) = mult_op
	then if rand_node_type (1) > rand_node_type (2)
		| (rand_node_type (1) = rand_node_type (2)
		& stack (work_stack_offset - 3) > stack (work_stack_offset - 2))
	     then do;
		     stack (work_stack_offset) = stack (work_stack_offset - 3);
		     stack (work_stack_offset - 3) = stack (work_stack_offset - 2);
		     stack (work_stack_offset - 2) = stack (work_stack_offset);
		     call get_data_type (2);
		     call get_node_type (2);
		end;

/* If we are not currently processing a subscript expression, the two operands in the stack are
   the true operands, and we must simply create an appropriate node with 2 operands,
   with an appropriate conversion if needed, create a temporary for the output value,
   and go away. */

	if ^subscript_mode
	then do;
		call conversion;
		op_index = create_operator (2);
		stack (work_stack_offset) = create_temporary (max (rand_data_type (1), rand_data_type (2)));
		call bump_work_stack_offset (+1);
		return;
	     end;
	if stack (work_stack_offset - 1) <= 1 | stack (work_stack_offset - 1) > 5
	then call print_message (200, char (stack (work_stack_offset - 1)));

/* If we are currently processing a subscript expression, the situation becomes more complex.  In
   an effort to minimize calculation at run time, an attempt is made to pull any constant parts of
   the subscript calculation out at compile time.  To this end, thefollowing is done:

   It is assumed that the "effective element length" of the current dimension can be represented by
   the expression <constant>*<variable>, stored in sub_stack entries element.constant and
   element.var, respectively.

   It is assumed that the cumulative effective subscript, including the effect of all dimensions up
   to and including the latest one completely processed, can be represented by the expression
   <constant>+<variable>, stored in sub_stack entries cum.constant and cum.temp respectively.  This
   form was chosen because it is the form ultimately needed when the array_ref_op node is created.

   It is assumed that the current subscript being evaluated can be expressed by the expression
   <constant_multiplier>*<variable>+<constant_offset>, stored in sub_stack entries dim.mult,
   dim.temp, and dim.offset, respectively.  This expression will be refered to in the following
   documentation as the accumulated current dimension.

   A value of true binary 0 is placed in the workstack in place of a normal operand to indicate
   that the accummulated current dimension is to be used for that operand. */

/* true_rand indicates which of the 2 operands is a normal operand if the accumulated current
   dimension is one of the operands.  If both operands are true operands, true_rand is set to -1 */

	if rand_data_type (1) = 0
	then true_rand = 2;
	else if rand_data_type (2) = 0
	then true_rand = 1;
	else do;
		true_rand = -1;
		call conversion;
		call get_data_type (2);
	     end;
	call get_node_type (2);
	go to case (stack (work_stack_offset - 1) - 1);

case (1):						/*  ADD  */
	if true_rand = -1
	then do;

/* If the accumulated current dimension does not take part in the expression at all, then we have
   to see what it is.  If there is no accumulated current dimension, then we are herewith beginning
   a new dimension.  Simply stick the left_hand operand into the appropriate dim.  entry, according
   to whether it is constant or not, set true_rand to indicate that the left_hand operand is the
   accumulated current dimension, and continue.  Otherwise simply create the appropriate operator
   node and leave the result in the stack. */

		if sub_stack.dim.temp = 0 & sub_stack.dim.offset = 0
		then do;
			if effectively_constant (work_stack_offset - 3, 1, constant_value)
			then sub_stack.dim.offset = constant_value;
			else sub_stack.dim.temp = stack (work_stack_offset - 3);
			true_rand = 2;
		     end;
		else do;
			op_index = create_operator (2);
			stack (work_stack_offset) = create_temporary (max (rand_data_type (1), rand_data_type (2)));
			call bump_work_stack_offset (+1);
			return;
		     end;
	     end;

/* If the true_operand is a constant, just add its value to sub_stack.dim.offset.*/

	if effectively_constant (work_stack_offset - 4 + true_rand, true_rand, constant_value)
	then do;
		sub_stack.dim.offset = sub_stack.dim.offset + constant_value;
		call bump_work_stack_offset (-3);
	     end;

/* Or, if there is not yet a variable part of the accumulated current dimension, put the true operand
   into dim.temp */

	else if sub_stack.dim.temp = 0
	then do;
		sub_stack.dim.temp = stack (work_stack_offset - 4 + true_rand);
		call bump_work_stack_offset (-3);
	     end;

/* Otherwise create nodes to compute <dim.mult>*<dim.temp> + <true operand>, and place the result
   into dim.temp, resetting dim.mult to 1. */

	else call compress_subscript ();

/* Leave a 0 in the stack to indicate that the result is being held in the accumulated current dimension. */

	call bump_work_stack_offset (+1);
	stack (work_stack_offset - 1) = 0;
	return;

case (2):						/* SUBTRACT */
	if true_rand = -1
	then do;

/* If the accumulated current dimension does not take part in the expression at all, then we have
   to see what it is.  If there is no accumulated current dimension, then we are herewith beginning
   a new dimension.  Simply stick the left_hand operand into the appropriate dim entry, according
   to whether it is constant or not, set true_rand to indicate that the left_hand operand is the
   accumulated current dimension, and continue.  Otherwise, simply create the appropriate operator
   node and leave the result in the stack. */

		if sub_stack.dim.temp = 0 & sub_stack.dim.offset = 0
		then do;
			if effectively_constant (work_stack_offset - 3, 1, constant_value)
			then sub_stack.dim.offset = constant_value;
			else sub_stack.dim.temp = stack (work_stack_offset - 3);
			true_rand = 2;
		     end;
		else do;
			op_index = create_operator (2);
			stack (work_stack_offset) = create_temporary (max (rand_data_type (1), rand_data_type (2)));
			call bump_work_stack_offset (+1);
			return;
		     end;
	     end;

/* If the true_rand is a constant, then we check which operand it is, since - does not commute.  If
   the true operand is the right_hand side, just subtract it from dim.offset.  If the true operand
   is the left_hand side, we must negate the dim.mult entry and set dim.offset to the
      operand - dim.offset */

	if effectively_constant (work_stack_offset - 4 + true_rand, true_rand, constant_value)
	then do;
		if true_rand = 2
		then sub_stack.dim.offset = sub_stack.dim.offset - constant_value;
		else do;
			sub_stack.dim.offset = constant_value - sub_stack.dim.offset;
			if sub_stack.dim.temp ^= 0
			then sub_stack.dim.mult = -sub_stack.dim.mult;
		     end;
		call bump_work_stack_offset (-3);
	     end;

/* If the true operand is not constant, and there is no accumulated variable part, then if the true
   operand is the right_hand side, put it in dim.temp and set the dim.mult to -1.  If the true
   operand is on the left, put it in dim.temp and negate dim.offset */

	else if sub_stack.dim.temp = 0
	then do;
		sub_stack.dim.temp = stack (work_stack_offset - 4 + true_rand);
		if true_rand = 2
		then sub_stack.dim.mult = -1;
		else sub_stack.dim.offset = -sub_stack.dim.offset;
		call bump_work_stack_offset (-3);
	     end;

/* Otherwise create nodes to compute <dim.mult>*<dim.temp> and to produce the subtraction with the
   true operand.  Place the result into dim.temp, and reset dim.mult to 1 */

	else call compress_subscript ();

/* Leave a 0 in the stack to indicate that the result is being held in accumulated current
   dimension. */

	call bump_work_stack_offset (+1);
	stack (work_stack_offset - 1) = 0;
	return;

case (3):						/*  MULT  */
	if true_rand = -1
	then do;

/* If the accumulated current dimension does not take part in the expression at all, then we have
   to see what it is.  If there is no accumulated current dimension, then we are herewith beginning
   a new dimension.  Simply stick the left_hand operand into the appropriate dim entry according to
   whether it is constant or not, set true_rand to indicate that the left_hand operand is the
   accumulated current dimension, and continue.  Otherwise, simply create the appropriate operator
   node and leave the result in the stack. */

		if sub_stack.dim.temp = 0 & sub_stack.dim.offset = 0
		then do;
			if effectively_constant (work_stack_offset - 3, 1, constant_value)
			then sub_stack.dim.offset = constant_value;
			else sub_stack.dim.temp = stack (work_stack_offset - 3);
			true_rand = 2;
		     end;
		else do;
			op_index = create_operator (2);
			stack (work_stack_offset) = create_temporary (max (rand_data_type (1), rand_data_type (2)));
			call bump_work_stack_offset (+1);
			return;
		     end;
	     end;

/* If the true_rand is a constant, then simply multiply dim.offset by it, and also multiply
   dim.mult by it if dim.temp is non_zero.  (Processing is easier if mult is guaranteed to be 1
   when there is no dim.temp part.) */

	if effectively_constant (work_stack_offset - 4 + true_rand, true_rand, constant_value)
	then do;
		sub_stack.dim.offset = sub_stack.dim.offset * constant_value;
		if sub_stack.dim.temp ^= 0
		then sub_stack.dim.mult = sub_stack.dim.mult * constant_value;
		call bump_work_stack_offset (-3);
	     end;

/* Or, if the true_rand is variable and there is no variable part in the current dimension, simply
   put the operand into dim.temp, move the former dim.offset into dim.mult, and zero dim.offset. */

	else if sub_stack.dim.temp = 0
	then do;
		sub_stack.dim.mult = sub_stack.dim.offset;
		sub_stack.dim.offset = 0;
		sub_stack.dim.temp = stack (work_stack_offset - 4 + true_rand);
		call bump_work_stack_offset (-3);
	     end;

/* Otherwise, create nodes to reduce the entire accumulated current dimension to a single temp,
   perform the new multiplication, and place the result into sub_stack.dim.temp, resetting the
   dim.offset to 0 and the dim.mult to 1. */

	else call compress_subscript ();

/* Leave a 0 in the stack to indicate that the result is being held in accumulated current dimension. */

	call bump_work_stack_offset (+1);
	stack (work_stack_offset - 1) = 0;
	return;

case (4):						/* DIVIDE  */

/* Operator nodes are always generated for divisions, because the truncation effect of FORTRAN
   integer division means they've basically gotta be done where the guy wrote them to avoid
   changing the meaning of the code. */

	if true_rand = -1
	then do;

/* If the accumulated current dimension does not take part in the calculation, then we must look to
   see what it is.  If there is no accumulated current dimension, we'll create a divide_op node and
   stick the output temp into dim.temp.  If there is an accumulated current dimension, make the
   node and stick the output temp into the stack. */

		if sub_stack.dim.temp = 0 & sub_stack.dim.offset = 0
		then do;
			sub_stack.dim.temp = subscript_arith (2);
			call bump_work_stack_offset (+1);
			stack (work_stack_offset - 1) = 0;
			return;
		     end;
		else do;
			op_index = create_operator (2);
			stack (work_stack_offset) = create_temporary (max (rand_data_type (1), rand_data_type (2)));
			call bump_work_stack_offset (+1);
			return;
		     end;
	     end;

/* Or, if there is no variable part to the accumulated current dimension, we'll convert the offset
   part into the appropriate operand position in the stack, create the operator, and stick the
   result temp into dim.temp. */

	if sub_stack.dim.temp = 0
	then do;
		stack (work_stack_offset - 1 - true_rand) =
		     create_integer_constant ((sub_stack.dim.offset));
		sub_stack.dim.temp = subscript_arith (2);
		sub_stack.dim.offset = 0;
	     end;

/* Otherwise, create nodes to reduce the entire accumulated current dimension to a single temp,
   perform the division, and place the result into dim.temp, resetting dim.mult to 1 and dim.offset
   to 0. */

	else call compress_subscript ();

/* Leave a 0 in the stack to indicate the the result is being held in accumulated current dimension. */

	call bump_work_stack_offset (+1);
	stack (work_stack_offset - 1) = 0;
	return;
     end process_arith;

compress_concat:
     procedure ();

/* Attempts to combine adjacent concatenation operators into a single
        operator with many operands.  Op_index points to the (binary)
        concatenation operator that was just created. */

dcl	(cur_operator, old_operator)
			pointer;
dcl	(n, k, i)		fixed binary (18);

	cur_operator = addr (q (op_index));

/* If the first operand of the new concatenation operator is a temporary
        that was created by another concatenation operator, then splice the
        operands of the old operator into the beginning of the new one and
        unchain the old operator. */

	if addr (x (cur_operator -> operator.operand (1))) -> node.node_type = temporary_node
	then do;
		old_operator = addr (q (addr (x (cur_operator -> operator.operand (1))) -> temporary.output_by));
		if old_operator -> operator.op_code = cat_op
		then do;
			n, cur_operator -> operator.number = old_operator -> operator.number + 1;
			cur_operator -> operator.operand (n) = cur_operator -> operator.operand (3);
			cur_operator -> operator.operand (n - 1) = cur_operator -> operator.operand (2);
			do i = 1 to n - 2;
			     cur_operator -> operator.operand (i) = old_operator -> operator.operand (i);
			end;
			next_free_quad = next_free_quad + n - 3;
			call unchain_cat_op (old_operator);
		     end;
	     end;

/* If the last operand of the new concatenation operator is a temporary
        that was output by another concatenation operator, splice the operands
        of the old operator onto the end of the new one and unchain the old
        operator.  Note that the current operator is not necessarily a binary
        operator at this point. */

	n = cur_operator -> operator.number;
	if addr (x (cur_operator -> operator.operand (n - 1))) -> node.node_type = temporary_node
	then do;
		old_operator = addr (q (addr (x (cur_operator -> operator.operand (n - 1))) -> temporary.output_by));
		if old_operator -> operator.op_code = cat_op
		then do;
			k = old_operator -> operator.number;
			cur_operator -> operator.number = n + k - 2;
			cur_operator -> operator.operand (n + k - 2) = cur_operator -> operator.operand (n);
			do i = 1 to k - 1;
			     cur_operator -> operator.operand (n + i - 2) = old_operator -> operator.operand (i);
			end;
			next_free_quad = next_free_quad + k - 2;
			call unchain_cat_op (old_operator);
		     end;
	     end;

     end compress_concat;


unchain_cat_op:
     procedure (op_p);

dcl	(op_p, p)		pointer;

/* unchain_cat_op is called by compress_concat with a pointer to a
   concatenation operator node as its argument.  It removes the operator node
   from the quad chain, and releases its output temporary.  It also frees the
   sub_index operator (and its temporary) that was used for the length. */

	p = op_p;
	call unchain (addr (q (addr (x (p -> operator.operand (p -> operator.number))) -> temporary.output_by)));
	call unchain (p);
	return;

     end unchain_cat_op;

unchain:
     procedure (op_ptr);

/* Does actual unchaining and freeing for unchain_cat_op and elsewhere */

dcl	op_ptr		pointer;

	addr (q (op_ptr -> operator.next)) -> operator.back = op_ptr -> operator.back;
	addr (q (op_ptr -> operator.back)) -> operator.next = op_ptr -> operator.next;
	addr (x (op_ptr -> operator.output)) -> temporary.next = next_free_temp;
	next_free_temp = op_ptr -> operator.output;

     end unchain;

process_expo:
     proc (mode);

dcl	(base, j, k, running_base)
			fixed bin (18);
dcl	mode		bit (1) aligned;

/* process_expo is called with the stack in the form (<>) <exp_op> <base> <power> <...>.  If
   <power> is not a positive integer it generates an exp_op node, otherwise it generates a series
   of multiply nodes using Knuth's algorithm.  It returns with the stack looking like (<>) <result> <...>
   The tricky part deals with subscript computations.  If this exp op occurs inside a
   sub_script calculation, and one of the operands is the accumulated current dimension, then the
   accumulated current dimension is reduced to a single temp or constant and placed into the work
   stack; If inside a sub_script evaluation, then the result temp is placed into dim.temp and a 0
   placed into the work stack at the end of this calculation.  */

	call get_data_type (2);
	if mode & (rand_data_type (1) = 0 | rand_data_type (2) = 0)
	then do;
		if rand_data_type (1) = 0
		then true_rand = 2;
		else true_rand = 1;
		if sub_stack.dim.temp = 0
		then do;
			stack (work_stack_offset - 1 - true_rand) =
			     create_integer_constant ((sub_stack.dim.offset));
			sub_stack.dim.offset = 0;
		     end;
		else call compress_subscript ();
		call get_data_type (2);
	     end;

	if rand_data_type (2) = int_mode
	then do;
		r = addr (x (stack (work_stack_offset - 2)));
		if r -> node.node_type = constant_node
		then do;
			unspec (j) = r -> constant.value;
			if j = 0
			then do;
				stack (work_stack_offset - 3) = one;
				call bump_work_stack_offset (-2);
				return;
			     end;

			if j = 1
			then do;
				call bump_work_stack_offset (-2);
				return;
			     end;
			if j > 1
			then do;
				k = index (r -> constant.value, "1"b);
				call bump_work_stack_offset (-2);
				base, running_base = stack (work_stack_offset - 1);
				do j = k + 1 to 36;
				     stack (work_stack_offset) = running_base;
				     stack (work_stack_offset + 1) = mult_op;
				     call bump_work_stack_offset (+2);
				     call process_arith ("0"b);
				     if substr (r -> constant.value, j, 1)
				     then do;
					     stack (work_stack_offset) = base;
					     stack (work_stack_offset + 1) = mult_op;
					     call bump_work_stack_offset (+2);
					     call process_arith ("0"b);
					end;
				     running_base = stack (work_stack_offset - 1);
				end;
				return;
			     end;
		     end;
	     end;
	if rand_data_type (2) ^= int_mode
	then call conversion;

	op_index = create_operator (2);
	stack (work_stack_offset) = create_temporary (max (rand_data_type (1), rand_data_type (2)));

	if mode & sub_stack.dim.temp = 0 & sub_stack.dim.offset = 0
	then do;
		sub_stack.dim.temp = stack (work_stack_offset);
		stack (work_stack_offset) = 0;
	     end;
	call bump_work_stack_offset (+1);
     end process_expo;

get_data_type:
     proc (number);

dcl	i		fixed bin (18),
	n		fixed bin (18),
	number		fixed bin (18);
dcl	r		ptr;

/* get_data_type is called with a stack of the form (<>) <operator> {<operand>} <...> and an
   argument giving the number of operands.  The first (i.e.  leftmost) operand is the one deepest
   in the stack.  get data_type returns the data types of the "number" operands, in the array
   rand_data_type, with the first operand in rand_data_type(1), etc.  In addition, if the number of
   operands is 2, combination_type is set; this is used by the conversion handling routines when
   determining whether an explicit conversion should be generated.  An operand = to 0, representing
   the accumulated current dimension in a subscript calculation, is arbitrarily assigned a
   data_type of 0 */

	do i = 1 to number;
	     n = stack (work_stack_offset - number - 2 + i);
	     if n < 0				/*   count   */
	     then rand_data_type (i) = int_mode;
	     else if n = 0
	     then rand_data_type (i) = 0;
	     else do;
		     r = addr (x (n));
		     rand_data_type (i) = r -> node.data_type;
		end;
	end;
	if number = 2
	then if rand_data_type (2) > cmpx_mode
	     then combination_type = 17;
	     else if rand_data_type (1) > cmpx_mode
	     then combination_type = 18;
	     else combination_type = 4 * (rand_data_type (2) - 1) + rand_data_type (1);
	return;
     end get_data_type;

bump_work_stack_offset:
     proc (increment);

dcl	increment		fixed bin (18);

/* This was subroutinized to allow over and underflow checking. */

	work_stack_offset = work_stack_offset + increment;
	if work_stack_offset < 0
	then call print_message (205);
	else if work_stack_offset > hbound (stack, 1)
	then call print_message (206, char (hbound (stack, 1)));
	return;
     end bump_work_stack_offset;

effectively_constant:
     proc (offset, rand_no, value) returns (bit (1) aligned);

dcl	(offset, rand_no, value)
			fixed bin (18);
dcl	r		ptr;

/* effectively_constant checks to see if a given operand is either an integer constant, or a
   temporary which was generated by the unary negation of an integer constant.  If either case is
   true, it returns the effective positive or negative value in the third argument, and a function
   value of "1"b; otherwise, it returns a function value of "0"b.  in addition, if the operand was
   the result of negating a constant, it unchains the negate_op node from the quad chain and
   releases the temporary.  */

	r = addr (x (stack (offset)));
	if rand_data_type (rand_no) ^= int_mode
	then return ("0"b);
	if rand_node_type (rand_no) = constant_node
	then do;
		unspec (value) = r -> constant.value;
		return ("1"b);
	     end;

	if rand_node_type (rand_no) ^= temporary_node
	then return ("0"b);

	r = addr (q (r -> temporary.output_by));
	if r -> operator.op_code ^= negate_op
	then return ("0"b);
	if addr (x (r -> operator.operand (1))) -> node.node_type ^= constant_node
	then return ("0"b);

	unspec (value) = addr (x (r -> operator.operand (1))) -> constant.value;
	value = -value;
	if addr (x (r -> operator.output)) -> temporary.ref_count = 0
	then do;
		addr (x (r -> operator.output)) -> temporary.next = next_free_temp;
		next_free_temp = r -> operator.output;
		if r -> operator.next = 0
		then do;
			last_op_index, op_index = r -> operator.back;
			last_quad_p = addr (q (last_op_index));
			next_free_quad = last_quad_p -> operator.next;
			last_quad_p -> operator.next = 0;
		     end;
		else do;
			addr (q (r -> operator.next)) -> operator.back = r -> operator.back;
			addr (q (r -> operator.back)) -> operator.next = r -> operator.next;
		     end;
	     end;
	return ("1"b);
     end effectively_constant;

subscript_arith:
     proc (n) returns (fixed bin (18));

dcl	(data_type, n)	fixed bin (18);

/* subscript_arith is used by the subscript processing routines instead of process_arith, to avoid
   recursion, which would be marvelously inconvenient in this case.  It is called with the stack
   containing (<>) <binary op> <operand> <operand> <...>, or (<>) <unary op> <operand> <...>
   It creates an appropriate operator node, with conversion made explicit if appropriate, generates an
   output temp to place into the node, and places the output temp into the stack as its result.
   The stack becomes (<>) <result> <...> */

	call get_data_type (n);
	if n = 2
	then call conversion;
	op_index = create_operator (n);
	if n = 1
	then data_type = rand_data_type (1);
	else data_type = max (rand_data_type (1), rand_data_type (2));
	return (create_temporary (data_type));
     end subscript_arith;

get_node_type:
     proc (number);

dcl	(i, n, number)	fixed bin (18);
dcl	r		ptr;

/* get_node_type is called with a stack of the form (<>) <operator> {<operand>} <...> and an
   argument giving the number of operands.  The first (i.e.  leftmost) operand is the one deepest
   in the stack.  get_node_type returns the node types of the operands in the array rand_node_type.
   An operand of 0, representing the accumulated current dimension, is arbitrarily given a
   node_type of 0.  */

	do i = 1 to number;
	     n = stack (work_stack_offset - number - 2 + i);
	     if n = 0
	     then rand_node_type (i) = 0;
	     else do;
		     r = addr (x (n));
		     rand_node_type (i) = r -> node.node_type;
		end;
	end;
	return;
     end get_node_type;

compress_subscript:
     proc ();

/* compress_subscript is called when an operation must be evaluated which forces some reduction in
   the accumulated current dimension, so that it can take part in the evaluation.  It is normally
   called with the stack containing (<>) <operator> <operand1> <operand2> <...>, where one of the
   two operands is 0, indicating that the accumulated current dimension is to be used.  The return
   stack depends on the value of <operator>.  If operator is +, -, *, or / then the stack is
   cleaned off to (<>) <...>; otherwise, the returned stack is identical to the calling stack
   except that the operand which was 0 is replaced by a temp indicating the result of evaluating
   accumulated current dimension. */

/* If dim.mult is = 1, there's no need to multiply .  Stuff dim.temp into 0 operand position. */

	if sub_stack.dim.mult = 1
	then stack (work_stack_offset - 1 - true_rand) = sub_stack.dim.temp;

/* If dim.mult is -1, use negate rather than mult.  Then stuff negate_op result into 0 operand position. */

	else if sub_stack.dim.mult = -1
	then do;
		stack (work_stack_offset) = sub_stack.dim.temp;
		stack (work_stack_offset + 1) = negate_op;
		call bump_work_stack_offset (+2);
		tkx = work_stack_offset - 3 - true_rand;
		stack (tkx) = subscript_arith (1);
	     end;

/* Otherwise, generate mult_op node for <dim.mult>*<dim.temp>, and stuff the result into 0 operand place. */

	else do;
		stack (work_stack_offset) = sub_stack.dim.temp;
		stack (work_stack_offset + 1) = create_integer_constant ((sub_stack.dim.mult));
		stack (work_stack_offset + 2) = mult_op;
		call bump_work_stack_offset (+3);
		tkx = work_stack_offset - 4 - true_rand;
		stack (tkx) = subscript_arith (2);
	     end;

/* Reset dim.mult. */

	sub_stack.dim.mult = 1;

/* If the operator is not add or subtract, then add in the offset, if any, to what's been
   calculated so far, and stick this new total result temp into the original 0 result place.  Reset
   dim.offset to 0. */

	if stack (work_stack_offset - 1) ^= add_op | stack (work_stack_offset - 1) ^= sub_op
	then do;
		if sub_stack.dim.offset ^= 0
		then do;
			stack (work_stack_offset) = stack (work_stack_offset - 1 - true_rand);
			stack (work_stack_offset + 1) =
			     create_integer_constant ((sub_stack.dim.offset));
			stack (work_stack_offset + 2) = add_op;
			call bump_work_stack_offset (+3);
			tkx = work_stack_offset - 4 - true_rand;
			stack (tkx) = subscript_arith (2);
		     end;
		sub_stack.dim.offset = 0;
	     end;

/* Now, if this is one of the basic 4 ops, generate a node for it, and stuff the result into dim.temp. */

	if stack (work_stack_offset - 1) >= add_op & stack (work_stack_offset - 1) <= div_op
	then sub_stack.dim.temp = subscript_arith (2);
	return;
     end compress_subscript;

initialize_subscript:
     procedure (symbol_ptr);

/* initialize_subscript is called at the beginning of subscript processing to
   initialize the array's dimension information.  It computes the dimension
   sizes if they are constant, and allocates symbols for them if they are not.
   It computes the virtual origin if it is constant, and allocates a possibly
   shared symbol for it if it is not. */

dcl	symbol_ptr	pointer;

dcl	(s, d)		pointer;
dcl	(i, ndims)	fixed binary (3);
dcl	(sum, multiplier)	fixed binary (24);

	s = symbol_ptr;
	d = addr (x (s -> symbol.dimension));
	ndims = d -> dimension.number_of_dims;

	if ^d -> dimension.has_dim_sizes
	then do;
		do i = 1 to ndims - binary (d -> dimension.assumed_size, 1);
		     if string (d -> dimension.v_bound (i)) = "00"b
		     then d -> dimension.size (i) = d -> dimension.upper_bound (i)
			     - d -> dimension.lower_bound (i) + 1;
		     else if ^d -> dimension.v_bound (i).lower
			& d -> dimension.lower_bound (i) = 1
		     then d -> dimension.size (i) = d -> dimension.upper_bound (i);
		     else d -> dimension.size (i) = create_dim_size_var (d, i);
		end;
		d -> dimension.has_dim_sizes = "1"b;
	     end;

	if ^d -> dimension.has_virtual_origin
	then do;
		if s -> symbol.star_extents
		then do;

/* Star extent character arrays may not share virtual origins with any other
   arrays.  Always create a new symbol for the virtual origin. */

			d -> dimension.virtual_origin = create_var ();
			d -> dimension.variable_virtual_origin = "1"b;
		     end;

		else do;

/* Try to compute the virtual origin.  If it turns out to be constant, there is
   no need to create a variable for it.  If it isn't constant, we try to share
   the virtual origin symbol with other arrays that have the same shape. */

			sum = 0;
			multiplier = s -> symbol.element_size;

			do i = 1 to ndims - 1 while (d -> dimension.virtual_origin = 0);
			     if string (d -> dimension.v_bound (i)) = "00"b
			     then do;
				     sum = sum + multiplier * d -> dimension.lower_bound (i);
				     multiplier = multiplier * d -> dimension.size (i);
				end;
			     else do;
				     d -> dimension.virtual_origin = create_virtual_origin_var (s);
				     d -> dimension.variable_virtual_origin = "1"b;
				end;
			end;

			if d -> dimension.virtual_origin = 0
			then if ^d -> dimension.v_bound (ndims).lower
			     then d -> dimension.virtual_origin =
				     sum + multiplier * d -> dimension.lower_bound (ndims);
			     else do;
				     d -> dimension.virtual_origin = create_virtual_origin_var (s);
				     d -> dimension.variable_virtual_origin = "1"b;
				end;
		     end;
		d -> dimension.has_virtual_origin = "1"b;
	     end;

     end initialize_subscript;

process_builtin:
     proc ();

dcl	(bif_index, char_size, data_type, gen_bif_index, i)
			fixed bin (18);
dcl	op_p		pointer;

dcl	char_bif		fixed bin (18) static options (constant) init (65);

/* process_builtin is called to process builtin function references.  When it is called the stack
   contains (<>) {<args>} <count> <function_id> <...>.  It creates an appropriate builtin function
   node with an output temporary, cleans out the stack, adds the temp, and returns with stack
   containing (<>) <output_temp> <...> */

	bif_index = addr (x (stack (eol_stack.work_stack_offset - 1))) -> symbol.char_size;

/* If the builtin name is a generic name, we must determine which actual function to use.	*/

	if fort_data$builtin_name.description (bif_index).generic_name
	then do;
		data_type = 0;

/* for generics, set the desired function data type to the max data type of its args. */

		do i = eol_stack.work_stack_offset + 1 to work_stack_offset - 2;
		     data_type = max (data_type, addr (x (stack (i))) -> node.data_type);
		end;

/* Now choose the appropriate specific func by using data_type as subscript. */

		gen_bif_index = bif_index;
		if data_type < 1 | data_type > 4
		then bif_index = 0;
		else bif_index = fort_data$builtin_name.description (gen_bif_index).generic_func (data_type);

/* If an appropriate specific does not exist, we'll just use the one with the highest data type. */

		do i = 4 to 1 by -1 while (bif_index = 0);
		     bif_index = fort_data$builtin_name.description (gen_bif_index).generic_func (i);
		     data_type = i;
		end;

/* As usual, if any args need conversion to/from integer, we'll make them explicit. */

		do i = eol_stack.work_stack_offset + 1 to work_stack_offset - 2;
		     if addr (x (stack (i))) -> node.data_type ^= data_type
		     then if addr (x (stack (i))) -> node.data_type = int_mode | data_type = int_mode
			then do;
				stack (work_stack_offset) = stack (i);
				stack (work_stack_offset + 1) = convert_to_int_op + data_type - 1;
				call bump_work_stack_offset (+2);
				op_index = create_operator (1);
				stack (i) = create_temporary (data_type);
			     end;
		end;
	     end;

/* now we can create the builtin node and set up the output temp.  process_eol_stack also pops the
   associated eol_stack entry. */

	call process_eol_stack (1, 2);
	stack (work_stack_offset) = create_temporary (fort_data$builtin_name.description (bif_index).result_type);
	call bump_work_stack_offset (+1);

/* If this is the CHAR builtin, we have to set the length field of the output
   temporary, or else the code generator will get confused. */

	if bif_index = char_bif
	then temp_ptr -> temporary.length = 1;

	return;

     end process_builtin;

process_lhs_fld:
     proc ();

/*  Called with the top of the stack (<>) <lhs_fld> <right_hand_value>
    <argument3> <argument2> <argument1> <...>  Increments the reference
    count on the target argument (argument 3) if it is an array_ref.
    Makes the lhs_fld node, and then cleans out the stack, leaving
    (<> <...> */

dcl	target		fixed bin (18);

	if stack (work_stack_offset - 3) > last_assigned_op
	then if addr (x (stack (work_stack_offset - 3))) -> node.node_type = array_ref_node
	     then addr (x (stack (work_stack_offset - 3))) -> array_ref.ref_count =
		     addr (x (stack (work_stack_offset - 3))) -> array_ref.ref_count + 1;

/* Make the lhs_fld node; set the output to the third argument. */

	target = stack (work_stack_offset - 3);
	stack (work_stack_offset - 3) = stack (work_stack_offset - 2);
	stack (work_stack_offset - 2) = stack (work_stack_offset - 1);
	call bump_work_stack_offset (-1);
	op_index = create_operator (3);
	last_quad_p -> operator.output = target;
	return;
     end process_lhs_fld;

push_eol_stack:
     proc ();

	call bump_work_stack_offset (-1);
	eol_stack_p = addr (w (first_free_object));
	first_free_object = first_free_object + size (eol_stack);
	if first_free_object > operand_max_len
	then call print_message (202, "eol_stack");
	eol_stack.last = eol_offset;
	eol_offset = first_free_object - size (eol_stack);
	eol_stack.op = stack (work_stack_offset);
	eol_stack.work_stack_offset = work_stack_offset - 1;
	suspend_subscript = (eol_stack.op ^= subscript_op);
	return;
     end push_eol_stack;

process_eol_stack:
     proc (units_per_item, extra_units);

dcl	(units_per_item, extra_units)
			fixed bin (18);

	stack (work_stack_offset - 1) = eol_stack.op;
	op_index = create_operator (units_per_item * (stack (eol_stack.work_stack_offset) + bias) + extra_units);
	call pop_eol_stack ();
	return;
     end process_eol_stack;

pop_eol_stack:
     proc ();

	eol_offset = eol_stack.last;
	unspec (eol_stack) = "0"b;
	eol_stack_p = addr (w (eol_offset));
	call new_free_object ();
	if eol_offset = 0
	then suspend_subscript = "0"b;
	else suspend_subscript = (eol_stack.op ^= subscript_op);
	return;
     end pop_eol_stack;

/* The hold stack is used when processing operators, such as logical jumps, which cannot be
   completely processed until the next statement node has been found.  push_hold_stack adds an
   entry to the hold_stack list, and pop_hold_stack deletes one.  */

push_hold_stack:
     proc ();

	hold_stack_p = addr (w (first_free_object));
	first_free_object = first_free_object + size (hold_stack);
	if first_free_object > operand_max_len
	then call print_message (202, "hold_stack");
	hold_stack.last = hold_offset;
	hold_offset = first_free_object - size (hold_stack);
	return;
     end push_hold_stack;

pop_hold_stack:
     proc ();

	hold_offset = hold_stack.last;
	unspec (hold_stack) = "0"b;
	hold_stack_p = addr (w (hold_offset));
	call new_free_object ();
	return;
     end pop_hold_stack;

/* The sub_stack is used to contain special information needed for processing sub_script operators.
   push_sub_stack adds an entry to the sub_stack list, pop_sub_stack removes one.  */

push_sub_stack:
     proc ();

	sub_stack_p = addr (w (first_free_object));
	first_free_object = first_free_object + size (sub_stack);
	if first_free_object > operand_max_len
	then call print_message (202, "sub_stack");
	sub_stack.last = sub_offset;
	sub_offset = first_free_object - size (sub_stack);
	sub_stack.nested = subscript_processing;
	return;
     end push_sub_stack;

pop_sub_stack:
     proc ();
	subscript_processing = sub_stack.nested;
	sub_offset = sub_stack.last;
	unspec (sub_stack) = "0"b;
	sub_stack_p = addr (w (sub_offset));
	call new_free_object ();
	return;
     end pop_sub_stack;

/* The exit_stack is used when processing a semantic construct which is expected to be terminated
   by an exit_op.  push_exit_stack is called when the basic operator is found, to create an
   exit_stack entry.  When the corresponding exit_op has been found and the processing completed,
   pop_exit_stack is called to pop the entry.  */

push_exit_stack:
     proc ();

	exit_stack_p = addr (w (first_free_object));
	first_free_object = first_free_object + size (exit_stack);
	if first_free_object > operand_max_len
	then call print_message (202, "exit_stack");
	exit_stack.last = exit_offset;
	exit_offset = first_free_object - size (exit_stack);
	return;
     end push_exit_stack;

pop_exit_stack:
     proc ();

	exit_offset = exit_stack.last;
	unspec (exit_stack) = "0"b;
	exit_stack_p = addr (w (exit_offset));
	call new_free_object ();
	return;
     end pop_exit_stack;

/* The sf_stack is used when processing a statement function invocation, to keep track of the
   various arguments and other such information.  The stack is needed to handle nested definitions
   and invocations.  push_sf_stack creates and initializes the sf_stack entry, when the sf_ref node
   is found.  The count and sf id are remembered and taken from the work stack.  pop_sf_stack is
   called to clear an entry from the sf_stack list.  */

push_sf_stack:
     proc ();

	sf_stack_p = addr (w (first_free_object));
	sf_num_args = stack (work_stack_offset - 1) + bias;
	first_free_object = first_free_object + size (sf_stack);
	if first_free_object > operand_max_len
	then call print_message (202, "sf_stack");
	sf_stack.last = sf_offset;
	sf_offset = first_free_object - size (sf_stack);
	sf_stack.sf = stack (work_stack_offset - 2);
	sf_stack.def_chain = addr (x (sf_stack.sf));
	sf_stack.current_arg = 1;
	sf_stack.num_args = sf_num_args;
	sf_stack.arg_info (sf_stack.current_arg).chain_start = last_op_index;
	sf_stack.cur_sf_param = sf_stack.def_chain -> symbol.next_member;
	call bump_work_stack_offset (-2);
	return;
     end push_sf_stack;

pop_sf_stack:
     proc ();

	sf_offset = sf_stack.last;
	sf_num_args = sf_stack.num_args;
	unspec (sf_stack) = "0"b;
	sf_stack_p = addr (w (sf_offset));
	call new_free_object ();
	return;
     end pop_sf_stack;

/* the virtual origin list is used as an optimizing feature.  
   there are three routines associated with it:
	1. an add_link routine
	2. a free chain routine- called after each subprog is processed
	3. a routine to scan the list to determine if another link need be
	inserted or if the virtual origin can occur. */

get_virtual_origin_link:
     proc;

/* like the push-pop subrs, this adds a link to the chain, the head of which 
    is the last link created */

	virtual_origin_base, virtual_origin_list_ptr = addr (w (first_free_object));
	first_free_object = first_free_object + size (virtual_origin_list);
	if first_free_object > operand_max_len
	then call print_message (202, "virtual_origin_list");
	virtual_origin_list.last = virtual_origin_offset;
	virtual_origin_offset = first_free_object - size (virtual_origin_list);
     end get_virtual_origin_link;

free_virtual_origin_list:
     proc;

/* unlike the other pop-push routines, the virtual origin list grows during 
    the processing of one subprogram.  Hence we don't pop when finished with
    an item, but free the entire list at the end of the subprog. */

	do while (virtual_origin_offset ^= 0);
	     virtual_origin_offset = virtual_origin_list.last;
	     unspec (virtual_origin_list) = "0"b;
	     virtual_origin_list_ptr = addr (w (virtual_origin_offset));
	     call new_free_object ();
	end /* loop */;
	virtual_origin_base = virtual_origin_list_ptr;
	return;
     end free_virtual_origin_list;

/* The block_if_stack is used to remember important details about block IF
   statements.  Entries are pushed on the block_if_stack when a block_if_op
   is encountered in the polish; entries are popped (after the corresponding
   ENDIF statement has been reached) by process_hold_stack_entry. */

push_block_if_stack:
     procedure ();

	block_if_stack_p = addr (w (first_free_object));
	first_free_object = first_free_object + size (block_if_stack);
	if first_free_object > operand_max_len
	then call print_message (202, "block_if_stack");
	block_if_stack.last = block_if_offset;
	block_if_stack.n_clauses = block_if_clause_count;
	block_if_offset = first_free_object - size (block_if_stack);
	return;

     end push_block_if_stack;

pop_block_if_stack:
     procedure ();

	block_if_offset = block_if_stack.last;
	unspec (block_if_stack) = "0"b;
	block_if_stack_p = addr (w (block_if_offset));
	call new_free_object ();
	return;

     end pop_block_if_stack;

/* The dim_size_list is used in the sharing of dimension size variables.
   It is similar to the virtual_origin_list in that new entries are allocated
   during the processing of a subprogram, and all entries are deleted at the
   end of each subprogram. */

get_dim_size_link:
     procedure ();

	dim_size_list_ptr = addr (w (first_free_object));
	first_free_object = first_free_object + size (dim_size_list);
	if first_free_object > operand_max_len
	then call print_message (202, "dim_size_list");
	dim_size_list.last = dim_size_offset;
	dim_size_offset = first_free_object - size (dim_size_list);

     end get_dim_size_link;


free_dim_size_list:
     procedure ();

	do while (dim_size_offset ^= 0);
	     dim_size_offset = dim_size_list.last;
	     unspec (dim_size_list) = "0"b;
	     dim_size_list_ptr = addr (w (dim_size_offset));
	     call new_free_object ();
	end;

     end free_dim_size_list;

create_virtual_origin_var:
     proc (symbol_ptr) returns (fixed binary (18));

/* procedure to allow sharing of variables for arrays with identical virtual 
    origins which have:
	1. the same element size in the same units
	2. the same number of dimensions
	3. the same lower bounds in all dimensions
	4. the same upper bounds in all dimensions but the last. */

declare	symbol_ptr	pointer /* ptr to the symbol for which a v_o is needed */;

declare	elem_size		fixed bin (17);
declare	elem_units	fixed bin (17);
declare	dim_node		pointer;
declare	num_dims		fixed bin (17);
declare	vo_sharable	bit (1);
declare	this_array	pointer;
declare	this_dim_node	pointer;
declare	this_vo_var	fixed bin (18);

	elem_size = symbol_ptr -> symbol.element_size;
	elem_units = symbol_ptr -> symbol.units;
	dim_node = addr (x (symbol_ptr -> symbol.dimension));
	num_dims = dim_node -> dimension.number_of_dims;
	virtual_origin_list_ptr = virtual_origin_base;

/* scan thru the list of virtual origins, which have already been assigned
    and are potentially sharable.  If it matches present symbol in elem_size and 
     elem_units then explore the dim node. */

	do while (virtual_origin_list_ptr ^= addr (w (0)));
	     if elem_size = virtual_origin_list.element_size
		& num_dims = virtual_origin_list.numb_of_dims
		& elem_units = virtual_origin_list.units
	     then do;				/* an examination of the dim_node */
		     this_array = virtual_origin_list.symbol_node;
		     this_dim_node = addr (x (this_array -> symbol.dimension));
		     vo_sharable =
			(dim_node -> dimension.lower_bound (num_dims)
			= this_dim_node -> dimension.lower_bound (num_dims))
			& (dim_node -> dimension.v_bound (num_dims).lower
			= this_dim_node -> dimension.v_bound (num_dims).lower);
		     do i = 1 to num_dims - 1 while (vo_sharable);
			if string (dim_node -> dimension.v_bound (i))
			     ^= string (this_dim_node -> dimension.v_bound (i))
			     | dim_node -> dimension.lower_bound (i) ^= this_dim_node -> dimension.lower_bound (i)
			     | dim_node -> dimension.upper_bound (i) ^= this_dim_node -> dimension.upper_bound (i)
			then vo_sharable = "0"b;
		     end;

		     if vo_sharable
		     then do;
			     virtual_origin_list_ptr = virtual_origin_base;
			     return (this_dim_node -> dimension.virtual_origin);
			end;
		end /*further calculation */;
	     virtual_origin_list_ptr = addr (w (virtual_origin_list.last));
	end /* walk thru list of previously assigned vo's */;

/* At this point, this array can not share a vo with any other.
   So, add its characteristics to the list, create a new variable,
   and then return. */

	this_vo_var = create_var ();
	call get_virtual_origin_link ();
	virtual_origin_list.element_size = elem_size;
	virtual_origin_list.symbol_node = symbol_ptr;
	virtual_origin_list.numb_of_dims = num_dims;
	virtual_origin_list.units = elem_units;
	virtual_origin_list_ptr = virtual_origin_base;
	return (this_vo_var);
     end create_virtual_origin_var;

create_dim_size_var:
     procedure (dim_p, dim_no) returns (fixed binary (24));

/* This procedure attempts to share variables that are created for dimension
   sizes.  The dim_size_list is scanned for a variable which could represent
   the size of the dimension described by dim_p and dim_no.  If such a variable
   is found, it is returned.  Otherwise, a new variable is created, added to
   the dim_size_list, and returned. */

dcl	(dim_p, d, p)	pointer;
dcl	(dim_no, i)	fixed binary (3);

	d = dim_p;
	i = dim_no;

	do p = dim_size_list_ptr repeat (addr (w (p -> dim_size_list.last)))
	     while (p ^= addr (w (0)));

	     if string (d -> dimension.v_bound (i)) = string (p -> dim_size_list.var)
	     then if d -> dimension.lower_bound (i) = p -> dim_size_list.lower_bound
		then if d -> dimension.upper_bound (i) = p -> dim_size_list.upper_bound
		     then return (p -> dim_size_list.size);

	end;

	call get_dim_size_link ();
	string (dim_size_list.var) = string (d -> dimension.v_bound (i));
	dim_size_list.lower_bound = d -> dimension.lower_bound (i);
	dim_size_list.upper_bound = d -> dimension.upper_bound (i);
	dim_size_list.size = create_var ();

	return (dim_size_list.size);

     end create_dim_size_var;

new_free_object:
     proc ();

/* new_free_object is called by the pop_???_stack goodies, since they all make their linked lists
   in the same segment.  It is a quick and dirty way of making sure that the stack area is kept at
   a minimal size.  */

	first_free_object =
	     max (sf_offset, exit_offset, eol_offset, hold_offset, sub_offset, virtual_origin_offset, block_if_offset,
	     dim_size_offset);
	if first_free_object = 0
	then first_free_object = 1;
	else if first_free_object = sf_offset
	then first_free_object = sf_offset + currentsize (sf_stack);
	else if first_free_object = exit_offset
	then first_free_object = exit_offset + currentsize (exit_stack);
	else if first_free_object = eol_offset
	then first_free_object = eol_offset + currentsize (eol_stack);
	else if first_free_object = hold_offset
	then first_free_object = hold_offset + currentsize (hold_stack);
	else if first_free_object = sub_offset
	then first_free_object = sub_offset + currentsize (sub_stack);
	else if first_free_object = virtual_origin_offset
	then first_free_object = virtual_origin_offset + currentsize (virtual_origin_list);
	else if first_free_object = block_if_offset
	then first_free_object = block_if_offset + currentsize (block_if_stack);
	else if first_free_object = dim_size_offset
	then first_free_object = dim_size_offset + currentsize (dim_size_list);

	return;
     end new_free_object;

conversion:
     proc ();

/* conversion is called with a stack of the form (<>) <some operator> <arg2> <arg1> <...> It checks
   to see if one, but not both, of the args is an integer, and if so generates an explicit
   conversion node to convert it to the same data type as the other argument, and replaces it in
   the stack with the output temp of the convert node.  The stack is returned in the same form as
   it was received.  */

dcl	arg_no		fixed bin (18);

	if combination_type >= 17
	then return;
	if rand_data_type (1) = int_mode
	then if rand_data_type (2) = int_mode
	     then return;
	     else arg_no = 1;
	else if rand_data_type (2) = int_mode
	then arg_no = 2;
	else return;

	stack (work_stack_offset) = stack (work_stack_offset - 4 + arg_no);
	stack (work_stack_offset + 1) = convert_to_int_op - 1 + rand_data_type (3 - arg_no);
	call bump_work_stack_offset (+2);
	op_index = create_operator (1);
	stack (work_stack_offset - 4 + arg_no) = create_temporary (rand_data_type (3 - arg_no));
	return;
     end conversion;

process_sf:
     proc ();

/* process_sf is called when we hit the eol_op terminating the polish entries for a
   statement_function invocation.  At this point the arguments for this invocation have all been
   processed and are held in the sf_stack entry, along with information about where in the quad
   chain the quads needed to evaluate any arguments which required calculation or conversion were
   put.  process_sf performs certain diddles so that the actual expansion of the statement function
   can be handled by the normal operator processing programs. */

/* First check to see if the proper number of args were supplied.  If not, we'll print an error
   message and simply replace the whole sf evaluation with an uninitialized temp to allow continued
   processing for further error checking. */

	if sf_stack.num_args ^= sf_stack.def_chain -> symbol.char_size
	then do;
		if sf_stack.num_args < sf_stack.def_chain -> symbol.char_size
		then call print_message (307, sf_stack.sf);
		else if sf_stack.num_args > sf_stack.def_chain -> symbol.char_size
		then call print_message (308, sf_stack.sf);
		call pop_eol_stack ();
		stack (work_stack_offset) = last_quad_p -> operator.output;
		stack (work_stack_offset - 1) = create_temporary ((sf_stack.def_chain -> symbol.data_type));
		last_quad_p -> operator.output = stack (work_stack_offset);
		call pop_sf_stack ();
		return;
	     end;

/* Otherwise, if everything seems ok, we'll push an exit_stack entry, since sf definitions are
   terminated by an exit_op, toss the eol_stack entry, and force expansion of the sf code by
   remembering the current location in the polish stack (polish_offset) in the sf_stack, and
   resetting the polish pointer to refer to the first polish entry of the statement function
   definition.  When the exit_op is seen, polish_offset will be restored from the sf_stack, and the
   sf_result will be in the work stack. */

	else do;
		call push_exit_stack ();
		exit_stack.op = sf_op;
		exit_stack.count = sf_stack.num_args;
		sf_stack.polish_offset = polish_offset;
		call pop_eol_stack ();
		call bump_work_stack_offset (-1);
		polish_offset = sf_stack.def_chain -> symbol.initial - 1;
	     end;
	return;
     end process_sf;

rechain_arg:
     proc (sf_ptr, sf_entry);

dcl	(sf_entry, start, stop)
			fixed bin (18);
dcl	(start_p, sf_ptr, stop_p)
			ptr;

/* rechain_arg is called if a substitution has to be made for a statement_function dummy variable,
   and sf_stack.chain_start and chain_end for the associated value are non-zero.  This indicates
   that some quads had to be genrated to evaluate the variable, and that the variable has not yet
   been used.  It was decided to be desirable not to evaluate such arguments until immediately
   before they are used, so rechain_arg unchains the argument evaluation from the place in the
   chain where it was first generated, and rechains it at the current top of the chain.  It then
   resets chain_start and end to inhibit this action if the arg is used again.  A check is made
   first to make sure that the argument is not already the last thing on the quad chain.  */

	start = sf_ptr -> sf_stack.arg_info (sf_entry).chain_start;
	stop = sf_ptr -> sf_stack.arg_info (sf_entry).chain_end;
	if stop ^= last_op_index
	then do;
		stop_p = addr (q (stop));
		start_p = addr (q (start));
		addr (q (start_p -> operator.back)) -> operator.next = stop_p -> operator.next;
		if stop_p -> operator.next ^= 0
		then addr (q (stop_p -> operator.next)) -> operator.back = start_p -> operator.back;
		addr (q (last_op_index)) -> operator.next = start;
		start_p -> operator.back = last_op_index;
		stop_p -> operator.next = 0;
		last_op_index, op_index = stop;
		last_quad_p = addr (q (stop));
	     end;
	sf_ptr -> sf_stack.arg_info (sf_entry).chain_start, sf_ptr -> sf_stack.arg_info (sf_entry).chain_end = 0;
	return;
     end rechain_arg;

process_1_subscript:
     proc ();

dcl	constant_value	fixed bin (18);
dcl	big_offset	bit (1) aligned;

/* process_1_subscript is called during subscript processing, when an item op is hit, signifying that
   a subscript has now been completely evaluated.  The top of the stack looks like
   (<>) <item_op> <subscript_value> <array_var> <...>
   process_1_subscript performs the necessary actions to incorporate the effect of the current
   subscript into the total accumulated subscript value.  If this is not the last subscript
   (dimension) the stack will be cleared off and returned as (<>) <array_var> <...>, and various
   initializations will be performed so the next dimension can be evaluated.  If this is the last
   dimension, process_1_subscript will create the opt_subscript_node and the array_ref temp, and
   will return the stack as (<>) <array_ref_node> <...> (For a discussion of the manner in which
   the subscript values are accumulated, see the comments to the process_arith subroutine.  */

/* If the <subscript_value> is 0, it means that the actual value is the accumulated current
   dimension, and we're ok; otherwise, move it into the appropriate part of the accumulated current
   dimension, so we have a standard form for further processing.  */

	if stack (work_stack_offset - 2) ^= 0
	then do;
		call get_data_type (1);
		call get_node_type (1);
		if effectively_constant (work_stack_offset - 2, 1, constant_value)
		then sub_stack.dim.offset = constant_value;
		else sub_stack.dim.temp = stack (work_stack_offset - 2);
		stack (work_stack_offset - 2) = 0;
	     end;
	call bump_work_stack_offset (-2);

/* Now the subscript is in the accumulated current dimension of sub_stack, in the form
   dim.mult*dim.temp + dim.offset.  dim.mult and dim.offset are known to be integer data_types.  If
   dim.temp is not an integer, we will call compress_subscript to force the calculation now, and
   convert the result to an integer.  After this the subscript will be in the same form, but all 3
   parts will be known to be integers.  */

	if sub_stack.dim.temp ^= 0
	then if addr (x (sub_stack.dim.temp)) -> node.data_type ^= int_mode
	     then do;
		     true_rand = -1;
		     call compress_subscript ();
		     stack (work_stack_offset + 1) = convert_to_int_op;
		     call bump_work_stack_offset (+2);
		     op_index = create_operator (1);
		     sub_stack.dim.temp = create_temporary ((int_mode));
		end;

/* Now we want to multiply the current dimensions subscript which is represented as shown above
   (known to be integer) by the effective length of one element in this dimension (i.e the number
   of words in storage which would be represented by an increase of 1 in this dimension) which is
   represented by the expression element.var*element.constant both parts of which are known to be
   integers.  This section is a collection of special cases designed to allow as much of the
   computation as possible to be done at the time of compilation.

   The result will be placed back into the dim.???  entries, leaving an expression in the same
   form, but which now represents a number of words of storage rather than a subscript.  Finally
   element.??  will be updated for the next dimension calculation.  */

	if sub_stack.element.var ^= 0
	then do;

/* if there is an element.var, but no dim.temp, then we simply set dim.mult equal to
   dim.offset*element.constant, put element.var into dim.temp, and set dim.offset to 0		*/

		if sub_stack.dim.temp = 0
		then do;
			sub_stack.dim.mult = sub_stack.dim.offset * sub_stack.element.constant;
			sub_stack.dim.temp = sub_stack.element.var;
			sub_stack.dim.offset = 0;
		     end;

/* a little hairier if there is an element.var and a dim.temp, but no dim.offset.  Then we must
   multiply dim.mult by element.constant, and create a mult_op node to multipy dim.temp by
   element.var, placing the result temp into dim.temp */

		else if sub_stack.dim.offset = 0
		then do;
			sub_stack.dim.mult = sub_stack.dim.mult * sub_stack.element.constant;
			stack (work_stack_offset) = sub_stack.dim.temp;
			stack (work_stack_offset + 1) = sub_stack.element.var;
			stack (work_stack_offset + 2) = mult_op;
			call bump_work_stack_offset (+3);
			call process_arith ("0"b);
			call bump_work_stack_offset (-1);
			sub_stack.dim.temp = stack (work_stack_offset);
		     end;

/* worst case...  there is an element.var, a dim.temp, and a dim.offset.  in that case we must
   fully evaluate the dim calculation to multiply it by element.var.

   First we generate a mult_op node to calculate dim.temp*dim.mult...unless dim.mult is 1, in which
   case this step is skipped, or -1, in which case a negate_op of dim.temp is generated instead.
   Then an add_op node to add in dim.offset is created.  Finally a mult_op node is generated to
   multiply this result by element.var The result of this operation is placed into dim.temp, and
   element.constant is placed into dim.mult.  dim.offset is zeroed.  */

		else do;
			stack (work_stack_offset) = sub_stack.dim.temp;
			call bump_work_stack_offset (+1);
			if sub_stack.dim.mult = -1
			then do;
				stack (work_stack_offset) = negate_op;
				call bump_work_stack_offset (+1);
				op_index = create_operator (1);
				stack (work_stack_offset) = create_temporary ((int_mode));
				call bump_work_stack_offset (+1);
			     end;
			else if sub_stack.dim.mult ^= 1
			then do;
				stack (work_stack_offset) =
				     create_integer_constant ((sub_stack.dim.mult));
				stack (work_stack_offset + 1) = mult_op;
				call bump_work_stack_offset (+2);
				call process_arith ("0"b);
			     end;
			stack (work_stack_offset) =
			     create_integer_constant ((sub_stack.dim.offset));
			stack (work_stack_offset + 1) = add_op;
			call bump_work_stack_offset (+2);
			call process_arith ("0"b);
			stack (work_stack_offset) = sub_stack.element.var;
			stack (work_stack_offset + 1) = mult_op;
			call bump_work_stack_offset (+2);
			call process_arith ("0"b);
			call bump_work_stack_offset (-1);
			sub_stack.dim.temp = stack (work_stack_offset);
			sub_stack.dim.mult = sub_stack.element.constant;
			sub_stack.dim.offset = 0;
		     end;

/* Time to update element entry.  If this is the last dimension, we'll skip this part.  Otherwise,
   we've got to look at dimension.dim associated with this dimension of this symbol.  (In case
   you've lost track, this is still part of the block done only if there was an element.var) */

		if sub_stack.dimension ^= sub_stack.n_dimensions
		then do;

/* if this dimension is a constant, just multiply element.constant by it.  */

			if string (sub_stack.dim_node -> dimension.v_bound (sub_stack.dimension)) = "00"b
			then sub_stack.element.constant =
				sub_stack.element.constant
				* sub_stack.dim_node -> dimension.size (sub_stack.dimension);

/* This dim not constant, gotta generate a mult_op node to multiply it times element.var, and stuff
   the result temp back into element.var */

			else do;
				stack (work_stack_offset) = sub_stack.element.var;
				stack (work_stack_offset + 1) =
				     sub_stack.dim_node -> dimension.size (sub_stack.dimension);
				stack (work_stack_offset + 2) = mult_op;
				call bump_work_stack_offset (+3);
				call process_arith ("0"b);
				call bump_work_stack_offset (-1);
				sub_stack.element.var = stack (work_stack_offset);
			     end;
		     end;
	     end;

	else do;

/* If we got here, there's no element.var...  They should all be so easy...  Just multiply dim.mult
   and dim.offset by element.constant.  */

		sub_stack.dim.mult = sub_stack.dim.mult * sub_stack.element.constant;
		sub_stack.dim.offset = sub_stack.dim.offset * sub_stack.element.constant;

/* Like above, if this is not the last dimension, we gotta update element.???  (remember, there is
   no element.var here).  If the current dimension.dim is a constant, just multiply
   element.constant by it; if it's variable, stuff it in element.var */

		if sub_stack.dimension ^= sub_stack.n_dimensions
		then do;
			if string (sub_stack.dim_node -> dimension.v_bound (sub_stack.dimension)) = "00"b
			then sub_stack.element.constant =
				sub_stack.element.constant
				* sub_stack.dim_node -> dimension.size (sub_stack.dimension);
			else sub_stack.element.var = sub_stack.dim_node -> dimension.size (sub_stack.dimension);
		     end;
	     end;

/* Now we have to add the effect of the current dimension (dim.mult*dim.temp + dim.offset,
   remember) to the offset from the array effective origin accumulated so far from the previously
   processed subscripts.  Again, it's a bunch of special cases to minimize run_time calculation. */

/* First, the simple part.  Add dim.offset into cum.constant, giving a new cum.constant */

	sub_stack.cum.constant = sub_stack.cum.constant + sub_stack.dim.offset;
	if sub_stack.dim.temp ^= 0
	then do;

/* There is also a dim.temp, if we got this far.  If dim.mult is -1, there are two possibilities.
   If there is not yet a cum.temp entry, we'll generate a negate_op of dim.temp, and stuff the
   output temp into cum.temp.  If there is already a cum.temp, we'll generate a subtract_op of
   cum.temp and dim.temp, and stuff the output into cum.temp.  */

		if sub_stack.dim.mult = -1
		then do;
			if sub_stack.cum.temp = 0
			then do;
				stack (work_stack_offset) = sub_stack.dim.temp;
				stack (work_stack_offset + 1) = negate_op;
				call bump_work_stack_offset (+2);
				op_index = create_operator (1);
				sub_stack.cum.temp = create_temporary ((int_mode));
			     end;
			else do;
				stack (work_stack_offset) = sub_stack.cum.temp;
				stack (work_stack_offset + 1) = sub_stack.dim.temp;
				stack (work_stack_offset + 2) = sub_op;
				call bump_work_stack_offset (+3);
				call process_arith ("0"b);
				call bump_work_stack_offset (-1);
				sub_stack.cum.temp = stack (work_stack_offset);
			     end;
		     end;

/* There's a dim.temp, and dim.mult was not -1.  We'll first generate a mult_op node with dim.mult
   and dim.temp (unless dim.mult is 1).  Then if cum_temp is nonzero, we'll generate an add_op node
   to add it in.  Finally we'll take the result, whatever it is, and stuff it back into cum.temp */

		else do;
			stack (work_stack_offset) = sub_stack.dim.temp;
			call bump_work_stack_offset (+1);
			if sub_stack.dim.mult ^= 1
			then do;
				stack (work_stack_offset) =
				     create_integer_constant ((sub_stack.dim.mult));
				stack (work_stack_offset + 1) = mult_op;
				call bump_work_stack_offset (+2);
				call process_arith ("0"b);
			     end;
			if sub_stack.cum.temp ^= 0
			then do;
				stack (work_stack_offset) = sub_stack.cum.temp;
				stack (work_stack_offset + 1) = add_op;
				call bump_work_stack_offset (+2);
				call process_arith ("0"b);
			     end;
			call bump_work_stack_offset (-1);
			sub_stack.cum.temp = stack (work_stack_offset);
		     end;
	     end;

/* Now we can reset dim.???  to compute the next dimension */

	sub_stack.dim.mult = 1;
	sub_stack.dim.temp = 0;
	sub_stack.dim.offset = 0;
	sub_stack.dimension = sub_stack.dimension + 1;
	if sub_stack.dimension <= sub_stack.n_dimensions
	then return;

/* That was the final dimension:  Make the opt_subscript_op node, with the
   array_ref_node as its output.  */


	if sub_stack.symbol_node -> symbol.VLA
	then do;

/*  The 'create_opt_subscript' routine requires the nodes that contain the   */
/*  constant and variable offsets of the desired element to be entered into  */
/*  the work stack.  For VLA's, the constant offset is always zero and the   */
/*  variable offset is really a packed pointer to the desired array element. */
/*  Since we originally initialized 'cum.temp' to the address of the start   */
/*  of the array minus its virtual origin, 'cum.temp' is now the address of  */
/*  the desired array element, provided that none of the subscripts of the   */
/*  element were constant.  If there were some constant subscripts, their    */
/*  effect was accumulated in 'cum.constant' and we must generate a quad to  */
/*  add it to 'cum.temp' to get the address of the desired element.  If we   */
/*  are not dealing with 256K VLA's, the addressor contains the "logical"    */
/*  address of the element and we must generate a quad to convert it to a    */
/*  physical address (i.e. a packed pointer).                                */

		stack (work_stack_offset) = zero;
		stack (work_stack_offset + 1) = sub_stack.cum.temp;
		call bump_work_stack_offset (+2);

		if sub_stack.cum.constant ^= 0
		then do;				/*  Add 'cum.constant' to the addressor.  */
			stack (work_stack_offset) = create_integer_constant ((sub_stack.cum.constant));
			stack (work_stack_offset + 1) = add_op;
			call bump_work_stack_offset (+2);
			call process_arith ("0"b);
			cum.constant = 0;
		     end;

		if ^VLA_is_256K
		then do				/*  Convert the addressor to a packed pointer.  */
			stack (work_stack_offset) = form_VLA_packed_ptr_op;
			call bump_work_stack_offset (+1);
			op_index = create_operator (1);
			stack (work_stack_offset) = create_temporary ((int_mode));
			call bump_work_stack_offset (+1);
		     end;

		big_offset = "1"b;			/*  The addressor is too big for an X register.  */
	     end;
	else do;

/* If the virtual origin of the array is a constant, just add it to cum.constant.  Move
   cum.constant and cum.temp into the work stack.  */

		if ^sub_stack.dim_node -> dimension.variable_virtual_origin
		then sub_stack.cum.constant = sub_stack.cum.constant - sub_stack.dim_node -> dimension.virtual_origin;
		stack (work_stack_offset) = create_integer_constant ((sub_stack.cum.constant));
		stack (work_stack_offset + 1) = sub_stack.cum.temp;
		call bump_work_stack_offset (+2);

/* If the virtual origin is not a constant, generate an appropriate node to subtract it from
   cum.temp This may be a negate_op if there was no cum.temp.  */

		if sub_stack.dim_node -> dimension.variable_virtual_origin
		then do;
			if stack (work_stack_offset - 1) = 0
			then do;
				stack (work_stack_offset - 1) = sub_stack.dim_node -> dimension.virtual_origin;
				stack (work_stack_offset) = negate_op;
				call bump_work_stack_offset (+1);
				op_index = create_operator (1);
				stack (work_stack_offset) = create_temporary ((int_mode));
				call bump_work_stack_offset (+1);
			     end;
			else do;
				stack (work_stack_offset) = sub_stack.dim_node -> dimension.virtual_origin;
				stack (work_stack_offset + 1) = sub_op;
				call bump_work_stack_offset (+2);
				call process_arith ("0"b);
			     end;
		     end;

/* If the variable offset might not fit into an index register, set the
   big_offset bit, which prevents a sub_index operator from being generated
   and causes the offset to be loaded into the A or Q.  We must have
   0 <= variable offset <= 262143 for an index register to be used.  Since we
   know 0 <= constant offset + variable offset <= array_size - 1, we can derive
   these two conditions for index register use:
   constant offset <= 0  AND  array_size - constant offset <= 262144.
   If either of these is not met, an index register may not be used. */

		big_offset = "0"b;
		if sub_stack.symbol_node -> symbol.units = char_units
		then if sub_stack.cum.temp ^= 0
		     then if sub_stack.symbol_node -> symbol.variable_extents
			     | sub_stack.symbol_node -> symbol.star_extents
			     | sub_stack.cum.constant > 0
			     | sub_stack.dim_node -> dimension.array_size - sub_stack.cum.constant > 262144
			then big_offset = "1"b;

/* Now if the variable part about to be used in the opt_subscript_op node is a
   temporary or array_ref (and it is not a big_offset) we've gotta run it
   through a sub_index_op node.  We must also set the output temp's
   used_as_subscript bit.  */

		if (stack (work_stack_offset - 1) ^= 0) & (^big_offset)
		then do;
			if addr (x (stack (work_stack_offset - 1))) -> node.node_type ^= symbol_node
			then do;
				stack (work_stack_offset) = sub_index_op;
				call bump_work_stack_offset (+1);
				call get_data_type (1);
				op_index = create_operator (1);
				stack (work_stack_offset) = create_temporary (rand_data_type (1));
				call bump_work_stack_offset (+1);
				temp_ptr -> temporary.bits.used_as_subscript = "1"b;
			     end;
		     end;
	     end;

/* At last we can create the opt_subscript_op node and its associated array_ref node */

	stack (work_stack_offset) = opt_subscript_op;
	call bump_work_stack_offset (+1);
	call create_opt_subscript ("0"b);
	array_ptr -> array_ref.large_offset = big_offset;
     end process_1_subscript;

process_substr:
     procedure ();

/* process_substr is called when a substr_op is hit and does all required work.
    The top of the stack is: (<>)<substr_op><upper_bound><lower_bound><parent>...
    The parent is either a symbol (i.e. substr'ing a scalar) or an array ref (i.e.the parent is an array ref).
    An opt_subscript node is placed in the quads with 4 operands: (1) symbol, (2) constant-offset,
    (3)variable-offset, (4) length.  If the parent is an array-ref, then we must merge
    the offset info with that of the substr (this is like subscript processing). */

declare	(parent_ptr, sympx, bound_ptr)
			pointer;
declare	(
	big_offset,
	bound_constant	(2),
	parent_is_array
	)		bit (1);
declare	(
	bound_index	(2),
	constant_part,
	parent_constant_part,
	parent_variable_part,
	true_parent_variable_part,
	substr_length,
	variable_part
	)		fixed binary (18);

declare	(
	bound_value	(2),
	constant_value,
	parent_constant_value
	)		fixed binary (35);

declare	int_image		fixed binary (35) based;

/* first examine the parent for any array-ref-node info */

	parent_ptr = addr (x (stack (work_stack_offset - 4)));
	if parent_ptr -> node.node_type = array_ref_node
	then do;
		parent_is_array = "1"b;
		sympx = addr (x (parent_ptr -> array_ref.parent));
		big_offset = parent_ptr -> array_ref.large_offset;
	     end;
	else do;
		parent_is_array = "0"b;
		sympx = parent_ptr;
		big_offset = "0"b;
	     end;

	if sympx -> symbol.data_type ^= char_mode
	then call print_message (159, stack (work_stack_offset - 4));

/* now examine the bounds - if constant and integer then bound is
    constant, else  it is variable and may need conversion to integer
    in this code bound_xxx (1)  refers to the lower bound and  bound_xxx(2)
    to the upper bound.   */

	call get_data_type (2);

	do i = 1 to 2;
	     bound_ptr = addr (x (stack (work_stack_offset - 4 + i)));
	     if rand_data_type (i) ^= int_mode
	     then do;

/* we have to convert to integer */

		     bound_constant (i) = "0"b;
		     stack (work_stack_offset) = stack (work_stack_offset - 4 + i);
		     stack (work_stack_offset + 1) = convert_to_int_op;
		     call bump_work_stack_offset (+2);
		     op_index = create_operator (1);
		     bound_index (i) = create_temporary ((int_mode));
		end;
	     else do;

/* data type is integer - if constant, get its value */

		     bound_constant (i) = (bound_ptr -> node.operand_type = constant_type);
		     bound_index (i) = stack (work_stack_offset - 4 + i);
		     if bound_constant (i)
		     then bound_value (i) = addr (bound_ptr -> constant.value) -> int_image;
		end;

	end /* do loop */;

/* next compute length and offset of the substr,
   remembering that length = upper_bound - lower_bound + 1, however computed */

	if bound_constant (1)
	then do;

/* lower bound is constant, so offset is also */


		constant_value = bound_value (1) - 1;
		variable_part = 0;

		if bound_constant (2)

/* if both are constant then length is constant */

		then substr_length = create_integer_constant (bound_value (2) - bound_value (1) + 1);
		else substr_length = do_arith (sub_op, create_integer_constant ((constant_value)), bound_index (2));
	     end;

	else do;

/* lowerbound is variable, so both length and offset are */

		constant_value = -1;
		variable_part = bound_index (1);

/* if the upper_bound is constant, fold "1" into its value and subtract the
   lower bound from that, else two arithmetic operations are required */

		if bound_constant (2)
		then substr_length =
			do_arith (sub_op, bound_index (1), create_integer_constant (bound_value (2) + 1));
		else substr_length = do_arith (add_op, do_arith (sub_op, bound_index (1), bound_index (2)), one);
	     end;

/* if parent is an array, merge its offset info with that of the substr,
    otherwise, merely set that for the substr */

	if parent_is_array
	then do;
		parent_constant_part = addr (q (parent_ptr -> array_ref.output_by)) -> operator.operand (2);
		parent_constant_value = addr (addr (x (parent_constant_part)) -> constant.value) -> int_image;
		true_parent_variable_part = addr (q (parent_ptr -> array_ref.output_by)) -> operator.operand (3);

		constant_part = create_integer_constant (parent_constant_value + constant_value);

		if true_parent_variable_part > 0
		then do;
			parent_variable_part = strip_sub_index (true_parent_variable_part);
			if variable_part = 0
			then variable_part = parent_variable_part;
			else variable_part = do_arith (add_op, parent_variable_part, variable_part);
		     end;

/* Make sure the variable offset still fits in an index register. */

		if ^sympx -> symbol.variable_extents & ^sympx -> symbol.star_extents
		then if variable_part ^= 0
		     then big_offset = constant_value + parent_constant_value > 0
			     | addr (x (sympx -> symbol.dimension)) -> dimension.array_size
			     - (constant_value + parent_constant_value) > 262144;

	     end;

	else do;

/*  parent is a symbol */

		constant_part = create_integer_constant ((constant_value));

	     end;

/*  if the offset is capable of being held in an index register,
    then run it thru a sub_index node & set output temp's used as subs bit */

	if ^big_offset & variable_part ^= 0
	then if addr (x (variable_part)) -> node.node_type ^= symbol_node
	     then do;
		     stack (work_stack_offset) = variable_part;
		     stack (work_stack_offset + 1) = sub_index_op;
		     call bump_work_stack_offset (+2);
		     call get_data_type (1);
		     op_index = create_operator (1);
		     variable_part = create_temporary ((int_mode));
		     temp_ptr -> temporary.bits.used_as_subscript = "1"b;
		end;

/* clean up the stack, pop on the opt_subscript_op and args, create the opt_subscript node in the quads */

	call bump_work_stack_offset (-4);
	stack (work_stack_offset) = fixed (rel (sympx), 18);
	stack (work_stack_offset + 1) = constant_part;
	stack (work_stack_offset + 2) = variable_part;
	stack (work_stack_offset + 3) = substr_length;
	stack (work_stack_offset + 4) = opt_subscript_op;
	call bump_work_stack_offset (+5);
	call create_opt_subscript ("1"b);
	array_ptr -> array_ref.large_offset = big_offset;

/* if the parent was an array with a variable part,
   unchain the old opt_subscript_node and free the sub_index operator and its temporary */

	if parent_is_array
	then do;
		if true_parent_variable_part ^= parent_variable_part & true_parent_variable_part ^= 0
		then call unchain (addr (q (addr (x (true_parent_variable_part)) -> temporary.output_by)));

		call unchain_opt_subscript (addr (q (parent_ptr -> array_ref.output_by)));
	     end;


	return;

unchain_opt_subscript:
     procedure (op_ptr);

/* Does the actual unchaining of opt_subscript_nodes and freeing of 
    array_refs */

dcl	op_ptr		pointer;

	addr (q (op_ptr -> operator.next)) -> operator.back = op_ptr -> operator.back;
	addr (q (op_ptr -> operator.back)) -> operator.next = op_ptr -> operator.next;
	addr (x (op_ptr -> operator.output)) -> array_ref.next = next_free_array_ref;
	next_free_array_ref = op_ptr -> operator.output;

     end unchain_opt_subscript;

     end process_substr;

do_arith:
     procedure (operator, operand1, operand2) returns (fixed binary (18));

/* called with a operator and the two operands -does the quad generation 
    and returns the temporary left on top of the stack by process_arith,
    however the stack itself is left unchanged by this call */

declare	(operator, operand1, operand2)
			fixed binary (18);

	stack (work_stack_offset) = operand2;
	stack (work_stack_offset + 1) = operand1;
	stack (work_stack_offset + 2) = operator;
	call bump_work_stack_offset (+3);
	call process_arith ("0"b);
	call bump_work_stack_offset (-1);
	return (stack (work_stack_offset));

     end do_arith;

create_opt_subscript:
     procedure (doing_substr);

declare	doing_substr	bit (1);
declare	num_operands	fixed binary (18);
declare	array_parent_p	pointer;
declare	char_len		fixed binary (18);

/* creates the opt_substr node and associated array ref node for a
    subscripted or substred variable  - assumes the stack looks like:
    (<>) <opt_subscript_op> [<length>] <variable_part> <constant_part> <parent>,
    the length operand only if doing_substr.  
    the stack is left as (<>) <array_ref_node> ...    */

	if doing_substr
	then num_operands = 4;
	else num_operands = 3;

	array_parent_p = addr (x (stack (work_stack_offset - num_operands - 1)));

	rand_data_type (1) = array_parent_p -> symbol.data_type;
	op_index = create_operator (num_operands);
	stack (work_stack_offset) = create_node (array_ref_node, size (array_ref));
	last_quad_p -> operator.output = stack (work_stack_offset);

	array_ptr = addr (x (stack (work_stack_offset)));
	array_ptr -> array_ref.output_by = op_index;
	array_ptr -> array_ref.operand_type = array_ref_type;
	array_ptr -> array_ref.ref_count = 0;
	array_ptr -> array_ref.data_type = rand_data_type (1);
	array_ptr -> array_ref.parent = last_quad_p -> operator.operand (1);

	if array_ptr -> array_ref.data_type = char_mode
	then do;
		char_len = get_char_size (array_parent_p);
		if char_len < 0
		then array_ptr -> array_ref.length = char_len + bias;
		else do;
			array_ptr -> array_ref.length = char_len;
			array_ptr -> array_ref.variable_length = "1"b;
		     end;
	     end;

	call bump_work_stack_offset (+1);

	return;

     end create_opt_subscript;

get_char_size:
     procedure (node_p) returns (fixed binary (18));

/* Returns the character length of the operand pointed to by
	   node_p.  Returns a count if the length is known to be constant,
	   otherwise returns an operand index. */

dcl	(node_p, p, o)	pointer;

	p = node_p;

	if p -> node.node_type = char_constant_node
	then return (p -> char_constant.length - bias);

	if p -> node.node_type = symbol_node
	then do;
		if p -> symbol.v_length ^= 0
		then return (p -> symbol.v_length);
		else return (p -> symbol.char_size + 1 - bias);
	     end;

	if p -> node.node_type = array_ref_node
	then do;
		o = addr (q (p -> array_ref.output_by));
		if o -> operator.op_code = opt_subscript_op
		     & o -> operator.number = 4
		then return (strip_sub_index (o -> operator.operand (4)));
		else if p -> array_ref.variable_length
		then return (p -> array_ref.length);
		else return (p -> array_ref.length - bias);
	     end;

	if p -> node.node_type = temporary_node
	then do;
		o = addr (q (p -> temporary.output_by));
		if o -> operator.op_code = cat_op
		then return (strip_sub_index (o -> operator.operand (o -> operator.number)));
		else if p -> temporary.variable_length
		then return (p -> temporary.length);
		else return (p -> temporary.length - bias);
	     end;

	return (0);

     end get_char_size;


strip_sub_index:
     procedure (operand) returns (fixed binary (18));

/* If the operand is the output of a sub_index operator, return
	   the input of the operator.  Otherwise, just return the operand. */

dcl	(operand, op)	fixed binary (18);
dcl	o		pointer;

	op = operand;

	if addr (x (op)) -> node.node_type = temporary_node
	then do;
		o = addr (q (addr (x (op)) -> temporary.output_by));
		if o -> operator.op_code = sub_index_op
		then op = o -> operator.operand (1);
	     end;

	return (op);

     end strip_sub_index;


is_local:
     procedure (operand) returns (bit (1) aligned);

/* is_local is a predicate which returns true if the operand is
	   a subroutine or function that occurs in this compilation. */

dcl	(operand, sym)	fixed binary (18);
dcl	(p, s)		pointer;

	p = addr (x (operand));

	if (^p -> symbol.external)
	then return ("0"b);

/* Search list of entry symbols for one with the same name. */

	do sym = first_entry_name repeat (s -> symbol.next_symbol) while (sym > 0);
	     s = addr (x (sym));
	     if s -> symbol.name = p -> symbol.name
	     then return ("1"b);
	end;

	return ("0"b);

     end is_local;


is_star_extent:
     procedure (operand) returns (bit (1) aligned);

/* is_star_extent is a predicate that returns true if the operand
	   is a symbol of star extent, or a substring or array reference
	   whose parent is of star extent. */

dcl	operand		fixed binary (18);
dcl	p		pointer;

	p = addr (x (operand));

	if p -> node.node_type = array_ref_node
	then p = addr (x (p -> array_ref.parent));

	if p -> node.node_type = symbol_node
	then return (p -> symbol.star_extents);
	else return ("0"b);

     end is_star_extent;

process_hold_stack_entry:
     proc ();

dcl	(i, j)		fixed bin (18);

/* The hold stack is used to remember various things that need to be done to a statement after the
   next statement node has been processed.  */

	if opst -> opt_statement.put_in_map | hold_stack.op_code = block_if_op
	then do while (hold_offset ^= 0);

/* If the statement must have a label, but doesn't, make it one.  */

		if hold_stack.op_code ^= jump_true_op
		then do;
			if opst -> opt_statement.label = 0
			then opst -> opt_statement.label = create_label (last_op_index);
			i = opst -> opt_statement.label;
			addr (x (i)) -> label.referenced_executable = "1"b;
		     end;

/* If the last statement was an if statement whose conditionally executed part was not a goto, we
   need to tell it where to jump to if the test failed.  */

		if hold_stack.op_code = jump_false_op
		then hold_stack.ptr -> operator.operand (2) = i;

/* Now is where we optimize any variety of if statement by separating the tests in compound tests.	*/

		if hold_stack.op_code = jump_false_op | hold_stack.op_code = jump_true_op
		then call optimize_if ((hold_stack.ptr));

/* If last statement was an arithmetic if, there may be unspecified labels to fill in.  */

		else if hold_stack.op_code = jump_arithmetic_op
		then do j = 2 to 4;
			if hold_stack.ptr -> operator.operand (j) < 0
			then hold_stack.ptr -> operator.operand (j) = i;
		     end;

/* If we are at the end of a block IF statement, the jump operators at the
   ends of the clauses must be filled in. */

		else if hold_stack.op_code = block_if_op
		then do;
			do j = 1 to block_if_stack.n_jumps;
			     addr (q (block_if_stack.jump (j))) -> operator.operand (1) = i;
			end;
			call pop_block_if_stack ();
		     end;

/* Last possibility is that last statement was a do statement, and this is the first statement of
   the do group.  In that case, we must remember its label.  */

		else exit_stack.do_label = i;
		call pop_hold_stack ();
	     end;
	return;
     end process_hold_stack_entry;

create_label:
     proc (i) returns (fixed bin (18));

dcl	(i, j)		fixed bin (18);

/* create_label creates a label and attaches it to the opt_statement node whose offset in the quads
   is contained in i.  It returns the offset in x (the symbol area) of the label entry created.  */

	j = create_node (label_node, size (label));
	addr (x (j)) -> label.statement = i;
	addr (x (j)) -> label.operand_type = rel_constant;
	addr (x (j)) -> label.executable, addr (x (j)) -> label.referenced, addr (x (j)) -> label.allocate,
	     addr (x (j)) -> label.set = "1"b;
	if subp_ptr -> subprogram.last_label = 0
	then subp_ptr -> subprogram.first_label = j;
	else addr (x (subp_ptr -> subprogram.last_label)) -> label.next_label = j;
	subp_ptr -> subprogram.last_label = j;
	return (j);
     end create_label;

search_label:
     proc (n);

dcl	n		fixed bin (18);

/* search_label checks to determine if a reference to a label is a backwards reference, and if so
   sets the referenced_backwards bit in the statement to which the label belongs.  The argument is
   the offset in the symbol list of the label entry to be checked.  */

	if addr (x (n)) -> label.statement ^= 0
	then if addr (q (addr (x (n)) -> label.statement)) -> opt_statement.processed_by_converter
	     then addr (q (addr (x (n)) -> label.statement)) -> opt_statement.referenced_backwards = "1"b;
	return;
     end search_label;

create_opt_statement:
     proc () returns (ptr);

dcl	i		fixed bin (18);
dcl	opst		ptr;

/* create_opt_statement is called to create and initialize an opt_statement node.  It returns a
   pointer to the node created.  Most of the initialization data is taken directly from the
   statement node in the polish.  */

	i = next_free_quad;
	next_free_quad = next_free_quad + size (opt_statement);
	if next_free_quad > quad_max_len
	then call print_message (407, "quadruple region", char (quad_max_len));
	opst = addr (q (i));
	unspec (opst -> opt_statement) = "0"b;
	if subp_ptr -> subprogram.last_polish = cur_statement
	then subp_ptr -> subprogram.last_quad = i;
	opst -> opt_statement.back = rel (last_opt_statement);
	if rel (last_opt_statement)
	then last_opt_statement -> opt_statement.next = rel (opst);
	if last_op_index ^= 0
	then addr (q (last_op_index)) -> operator.next = i;
	else subp_ptr -> subprogram.first_quad = i;

	opst -> opt_statement.prev_operator = last_op_index;
	opst -> opt_statement.op_code = stat_op;
	opst -> opt_statement.source_id = stm_ptr -> statement.source_id;
	opst -> opt_statement.length = stm_ptr -> statement.length;
	opst -> opt_statement.put_in_map = stm_ptr -> statement.put_in_map;
	opst -> opt_statement.put_in_profile = stm_ptr -> statement.put_in_profile;
	opst -> opt_statement.start = stm_ptr -> statement.start;
	opst -> opt_statement.location = stm_ptr -> statement.location;
	opst -> opt_statement.flow_unit, opst -> opt_statement.operator_list = null;

	last_op_index = i;
	last_opt_statement = opst;
	return (opst);
     end create_opt_statement;

create_operator:
     proc (n) returns (fixed bin (18));

dcl	i		fixed bin (18),
	j		fixed bin (18),
	n		fixed bin (18);

/* create_operator is called with the stack containing (<>) <operator> <arg_n> ... <arg_1> <...>
   The number of args in the stack is passed as the argument n.  create_operator creates and inits
   an appropriate size node, stuffs the operator and operands into the node from the stack,
   increments the ref_counts for any of the operator args which are array_refs or temps, Cleans the
   operator and its args from the stack, and returns the offset in the quads of the created node.
   The stack is left as (<>) <...> upon return.  */

	i = next_free_quad;
	n_operands = n;
	if n_operands > max_num_of_rands
	then call print_message (204, char (max_num_of_rands));
	next_free_quad = next_free_quad + size (operator);
	if next_free_quad > quad_max_len
	then call print_message (407, "quadruple region", char (quad_max_len));

	last_quad_p = addr (q (i));
	unspec (last_quad_p -> operator) = "0"b;
	last_quad_p -> operator.back = last_op_index;
	if last_op_index ^= 0
	then addr (q (last_op_index)) -> operator.next = i;
	if opst -> opt_statement.first_operator = 0
	then opst -> opt_statement.first_operator = i;
	last_quad_p -> operator.op_code = stack (work_stack_offset - 1);
	last_quad_p -> operator.number = n_operands;
	last_quad_p -> operator.primary = null;

	do j = 1 to n_operands;
	     last_quad_p -> operator.operand (j) = stack (work_stack_offset - n_operands - 2 + j);
	     if j > 1 | last_quad_p -> operator.op_code ^= opt_subscript_op
	     then last_quad_p -> operator.operand (j) = effective_operand (last_quad_p -> operator.operand (j));
	     if last_quad_p -> operator.operand (j) > last_assigned_op
	     then if addr (x (last_quad_p -> operator.operand (j))) -> node.node_type = temporary_node
		     | addr (x (last_quad_p -> operator.operand (j))) -> node.node_type = array_ref_node
		then addr (x (last_quad_p -> operator.operand (j))) -> temporary.ref_count =
			addr (x (last_quad_p -> operator.operand (j))) -> temporary.ref_count + 1;
	end;

	call bump_work_stack_offset (-n_operands - 1);
	last_op_index = i;
	return (i);
     end create_operator;

create_temporary:
     proc (data_type) returns (fixed bin (18));

dcl	data_type		fixed bin (18);

/* create_temporary is called specifically to create an output temp for an already created operator
   node.  It is called with the data_type to be used for the temp.  It creates a temporary node,
   places it into the output entry of the last operator node created, and returns the offset of the
   created temporary in the x (symbol) stack.  */

	temp_index = create_node (temporary_node, size (temporary));
	temp_ptr = addr (x (temp_index));
	last_quad_p -> operator.output = temp_index;
	temp_ptr -> temporary.output_by = op_index;
	temp_ptr -> temporary.operand_type = temp_type;
	temp_ptr -> temporary.ref_count = 0;
	temp_ptr -> temporary.data_type = data_type;
	temp_ptr -> temporary.addressing_bits.not_in_storage = "1"b;
	return (temp_index);
     end create_temporary;

create_var:
     proc () returns (fixed bin (18));

dcl	var		fixed bin (18);
dcl	p		ptr;

/* create_var is called when it is necessary to produce a new compiler-generated symbol.
   It creates an unnamed integer symbol entry in the symbol table, and returns the offset
   of the created entry.  */

	allocate_symbol_name = 0;
	var = create_node (symbol_node, size (symbol));
	p = addr (x (var));
	p -> symbol.data_type = int_mode;
	p -> symbol.element_size = data_type_size (int_mode);
	p -> symbol.operand_type = variable_type;
	p -> symbol.allocate, p -> symbol.referenced, p -> symbol.set, p -> symbol.by_compiler, p -> symbol.integer,
	     p -> symbol.automatic = "1"b;

/* connect the node to the symbol chain */

	addr (x (subp_ptr -> subprogram.last_symbol)) -> symbol.next_symbol = var;
	subp_ptr -> subprogram.last_symbol = var;
	return (var);
     end create_var;

create_integer_constant:
     procedure (value) returns (fixed binary (18));

dcl	value		fixed binary (19) aligned;
dcl	bit_value		bit (72) aligned;

	bit_value = unspec (value);
	return (create_constant (int_mode, bit_value));

     end create_integer_constant;

match_index_type:
     proc ();

dcl	i		fixed bin (18);
dcl	(i_ptr, c_ptr)	ptr;

/* match_index_type is called when processing do loops, with the stack containing (<>) <do_op>
   <incr> <upper> <lower> <index_var> <...> It checks the data type of incr, upper, and lower
   against the data type of index_var, the nominal control variable.  If the data types do not
   match, it will generate an explicit conversion node to convert the errant value's data type to
   match the data_type of index_var.  The stack is in identical form upon return, except that incr,
   lower, and upper all have the same data type as index_var.  */

	c_ptr = addr (x (stack (work_stack_offset - 5)));
	do i = 2 to 4;
	     i_ptr = addr (x (stack (work_stack_offset - i)));
	     if i_ptr -> node.data_type ^= c_ptr -> node.data_type
	     then do;
		     stack (work_stack_offset) = stack (work_stack_offset - i);
		     stack (work_stack_offset + 1) = convert_to_int_op + c_ptr -> node.data_type - 1;
		     call bump_work_stack_offset (+2);
		     op_index = create_operator (1);
		     stack (work_stack_offset - i) = create_temporary ((c_ptr -> node.data_type));
		end;
	end;
	return;
     end match_index_type;

optimize_if:
     proc (if_node_p) recursive;

dcl	(if_node_p, log_op_p)
			ptr;
dcl	(inverted_if, next, next_label)
			fixed bin (18);

/* optimize_if is called from the top level program to break up if statements involving logical
   operators into a series of if_nodes each of which uses a single logical value (logical variable
   or expression involving relational operators.  This may serve to eliminate unneeded computation,
   since the if statement will take effect as soon as it is known that enough of the logical
   expression has been that any further tests would have no effect.  The basic transformations used
   are:

   jump_true(target,or(a,b)) -> jump_true(target,a), jump_true(target,b)

   jump_true(target,and(a,b)) -> jump_false(next,a), jump_true(target,b)

   jump_true(target,not(a)) -> jump_false(target,a)

   jump_false(target,and(a,b)) -> jump_false(target,a), jump_false(target,b)

   jump_false(target,or(a,b)) -> jump_true(next,a), jump_false(target,b)

   jump_false(target,not(a)) -> jump_true(target,a)

   optimize_if recurses, and will unweave any arbitrary logical expression.  */

	if if_node_p -> operator.op_code = jump_false_op
	then inverted_if = jump_true_op;
	else inverted_if = jump_false_op;

/* If the test_expression is not a temp, it was a variable.  Can't do nuttin.  */

	if addr (x (if_node_p -> operator.operand (1))) -> node.node_type ^= temporary_node
	then return;

/* Otherwise get the operator used to produce the temporary.  */

	log_op_p = addr (q (addr (x (if_node_p -> operator.operand (1))) -> temporary.output_by));

/* If the op was .not., just invert the jump sense.  */

	if log_op_p -> operator.op_code = not_op
	then do;
		if_node_p -> operator.op_code = inverted_if;
		if_node_p -> operator.operand (1) = log_op_p -> operator.operand (1);
	     end;

/* If node is a jump true on an .or., or jump false on an .and., we just split it into 2 nodes with
   the same sense jump, One based on each side of the logical operator.  The left hand side will be
   put into a new jump node created by create_new_if, which will also call optimize_if to optimize
   that branch.  The right_hand side will replace the original test_expression in the original
   jump.  */

	else if (if_node_p -> operator.op_code = jump_true_op & log_op_p -> operator.op_code = or_op)
	     | (if_node_p -> operator.op_code = jump_false_op & log_op_p -> operator.op_code = and_op)
	then do;
		call create_new_if (if_node_p, (if_node_p -> operator.op_code), (if_node_p -> operator.operand (2)),
		     (log_op_p -> operator.operand (1)));
		if_node_p -> operator.operand (1) = log_op_p -> operator.operand (2);
	     end;

/* If node is a jump true on an .and., or jump false on an .or., do the same as in last case,
   except that the new jump created for the lhs is inverted in sense from the original jump.  */

	else if (if_node_p -> operator.op_code = jump_true_op & log_op_p -> operator.op_code = and_op)
	     | (if_node_p -> operator.op_code = jump_false_op & log_op_p -> operator.op_code = or_op)
	then do;

/* Find the next executable statement, and put a label on it if necessary. */

		do next = if_node_p -> operator.next repeat (fixed (addr (q (next)) -> opt_statement.next, 18))
		     while (^addr (q (next)) -> opt_statement.put_in_map);
		end;

		if addr (q (next)) -> opt_statement.label = 0
		then addr (q (next)) -> opt_statement.label = create_label (next);
		next_label = addr (q (next)) -> opt_statement.label;
		addr (x (next_label)) -> label.referenced_executable = "1"b;
		call create_new_if (if_node_p, (inverted_if), next_label, (log_op_p -> operator.operand (1)));
		if_node_p -> operator.operand (1) = log_op_p -> operator.operand (2);
	     end;

/* If we get here, node has already been reduced as far as possible.  Just return.  */

	else return;

/* Call unchain_op to throw out the no longer needed logical operator node, and optimize_if to
   optimize the new chain created from the right_hand side of the original logical operator.  */

	call unchain_op (log_op_p);
	call optimize_if ((if_node_p));
	return;

create_label:
     proc (i) returns (fixed bin (18));

dcl	(i, j)		fixed bin (18);

/* create_label creates a label and attaches it to the opt_statement node whose offset in the quads
   is contained in i.  It returns the offset in x (the symbol area) of the label entry created.
   This second copy of create label is included for the use of the if optimizing subroutines, which
   are recursive, so that the copy used by the remainder of the converter can remain a quick
   procedure.  */

	j = create_node (label_node, size (label));
	addr (x (j)) -> label.statement = i;
	addr (x (j)) -> label.operand_type = rel_constant;
	addr (x (j)) -> label.executable, addr (x (j)) -> label.referenced, addr (x (j)) -> label.allocate,
	     addr (x (j)) -> label.set = "1"b;
	if subp_ptr -> subprogram.last_label = 0
	then subp_ptr -> subprogram.first_label = j;
	else addr (x (subp_ptr -> subprogram.last_label)) -> label.next_label = j;
	subp_ptr -> subprogram.last_label = j;
	return (j);
     end create_label;

/* This copy of create_node is used only by the if optimizing subprograms.  Giving them a separate
   copy prevents create_node from becoming non_quick when it is used everywhere else in the
   converter.  */

%include fort_create_node;
unchain_op:
     proc (op_p);

dcl	op_p		ptr;

/* unchain_op is called by the if_optimizer with a pointer to a logical operator node as its
   argument.  It removes the operator node from the quad chain, and releases its output temporary. */

	addr (q (op_p -> operator.next)) -> operator.back = op_p -> operator.back;
	addr (q (op_p -> operator.back)) -> operator.next = op_p -> operator.next;
	addr (x (op_p -> operator.output)) -> temporary.next = next_free_temp;
	next_free_temp = op_p -> operator.output;
	return;
     end unchain_op;

     end optimize_if;

create_new_if:
     proc (parent_if_p, use_jump, jump_target, expression);

dcl	(b_p, f_p, parent_if_p, ti_p, ts_p)
			ptr;
dcl	(back, expression, forward, jump_target, last_st, next_st, parent_if, ti, ts, use_jump)
			fixed bin (18);

/* create_new_if is called by optimize_if to create a new operator node for the jump being created
   from the left_hand_side of a logical expression.  It is called with a pointer to the parent if
   node, the jump type to be used, the jump target to be used, and the offset in the symbols of the
   logical variable or temporary to be tested.  It creates both the operator node, and a statement
   node.  The statement node is needed so this jump will have a proper "next" when create_new_if
   calls optimize_if for this new jump node.  A label will be generated later, only if the
   statement node is actually used as a jump target.  */

	n_operands = 2;
	ti = next_free_quad;
	ti_p = addr (q (ti));
	ts = next_free_quad + size (operator);
	ts_p = addr (q (ts));
	next_free_quad = ts + size (opt_statement);
	if next_free_quad > quad_max_len
	then call print_message (407, "quadruple_region", char (quad_max_len));

	unspec (ts_p -> opt_statement) = "0"b;
	unspec (ti_p -> operator) = "0"b;
	next_st = parent_if_p -> operator.next;
	last_st = fixed (addr (q (next_st)) -> opt_statement.back, 18);
	parent_if = addr (q (next_st)) -> opt_statement.prev_operator;

/*    rechain statement chain     */

	addr (q (last_st)) -> opt_statement.next = bit (fixed (ts, 18), 18);
	ts_p -> opt_statement.back = bit (fixed (last_st, 18), 18);
	addr (q (next_st)) -> opt_statement.back = bit (fixed (ts, 18), 18);
	ts_p -> opt_statement.next = bit (fixed (next_st, 18), 18);

/*     rechain operator chain     */

	ts_p -> operator.back = ti;
	ti_p -> operator.next = ts;
	b_p = addr (x (expression));
	if b_p -> node.node_type ^= temporary_node & b_p -> node.node_type ^= array_ref_node
	then back = last_st;
	else back = b_p -> temporary.output_by;
	b_p = addr (q (back));
	forward = b_p -> operator.next;
	f_p = addr (q (forward));
	b_p -> operator.next = ti;
	ti_p -> operator.back = back;
	f_p -> operator.back = ts;
	ts_p -> operator.next = forward;

/*     fill in nodes bit by bit     */

	ts_p -> opt_statement.op_code = stat_op;
	ts_p -> opt_statement.source_id = addr (q (last_st)) -> opt_statement.source_id;
	ts_p -> opt_statement.length = addr (q (last_st)) -> opt_statement.length;
	ts_p -> opt_statement.start = addr (q (last_st)) -> opt_statement.start;
	ts_p -> opt_statement.location = stm_ptr -> opt_statement.location;
	ts_p -> opt_statement.processed_by_converter = "1"b;
	ts_p -> opt_statement.put_in_map = "1"b;
	ts_p -> opt_statement.flow_unit, ts_p -> opt_statement.operator_list = null;

	ti_p -> operator.op_code = use_jump;
	ti_p -> operator.number = 2;
	ti_p -> operator.primary = null;
	ti_p -> operator.operand (2) = jump_target;
	ti_p -> operator.operand (1) = expression;
	call optimize_if ((ti_p));
	return;
     end create_new_if;

optimize_vector:
     proc ();

dcl	(do_position, eol_position, n_dims_used, inner_do_position, i, j, n_dims, low, high, low_value, high_value,
	vector_length, vector_length_temp)
			fixed bin (18);
dcl	(low_p, high_p, r, dim_p, symb_p)
			ptr;
dcl	(optimized_something, low_is_variable, high_is_variable, high_bounds_differ, low_bounds_differ,
	must_keep_remaining_loops)
			bit (1) aligned;


/* optimize_vector is called when a do_op is hit on the stack.  At this point the stack contains
   (<>) {<do_op or counter> <incr> <lower> <upper> <index_var>} <...>
   (In the best cases there will be more than one level of do_op nesting) optimize_vector is called
   only for implied do's in i/o ops, and by the time it is called the do_op initialization stuff is
   already in the quads.  optimize_vector attempts to convert the implied do's into xmit_vectors,
   removing as many of the nested implied do's as possible.

   NOTE: This is the one section of the converter which may actually modify the polish input.  */

/* Remember where we are */

	inner_do_position, do_position = polish_offset;

/* CHECK--transmitted item must be subscripted.  This test will also toss us out if we have not yet
   hit the most deeply nested do.  */

	if p (do_position + 3) ^= subscript_op
	then go to NO_OPT_VECTOR;

/* Get number of dimensions, and figure out where the eol should be.  */

	n_dims = p (do_position + 2) + bias;
	eol_position = do_position + 4 + n_dims * 2;

/* CHECK--subscripts must not contain expressions (quick & dirty, but effective method).  */

	if p (eol_position) ^= eol_op
	then go to NO_OPT_VECTOR;

	symb_p = addr (x (p (inner_do_position + 1)));
	dim_p = addr (x (symb_p -> symbol.dimension));

	optimized_something = "0"b;

/* initial vector length is just the element size.  final vector length will be
   vector_length*vector_length_temp.  The constant and variable parts are kept separate to enable
   maximum compile time evaluation.  */

	if symb_p -> symbol.v_length = 0
	then do;
		vector_length = symb_p -> symbol.element_size;
		vector_length_temp = 0;
	     end;
	else do;
		vector_length = 1;
		vector_length_temp = symb_p -> symbol.v_length;
	     end;

	n_dims_used = 0;

/*  Check for validity at each contained level */

	must_keep_remaining_loops = "0"b;
	do i = 1 by 1 while (^must_keep_remaining_loops);

/* if work_stack_offset < 5 there are no more do_op entries in the stack.  We're done.  */

	     if work_stack_offset < 5
	     then go to NO_MORE_DIMS;

/* if the next thing down in the stack is not a do_op we're done.  */

	     if stack (work_stack_offset - 1) ^= do_op
	     then go to NO_MORE_DIMS;

/* CHECK--the subscript must be the same variable as the do index.  */

	     if p (inner_do_position + 2 + i * 2) ^= stack (work_stack_offset - 5)
	     then go to NO_MORE_DIMS;

/* CHECK--the increment must be a constant integer 1--at this point we know that this also means
   the index_var and upper and lower bounds are integer, since match_index_type was called before
   we were.  */

	     if stack (work_stack_offset - 2) ^= one
	     then go to NO_MORE_DIMS;

/* CHECK--the array item must be the only item in the list at this level.  */

	     if p (eol_position + 1 + i) ^= exit_op | exit_stack.xmit_at_this_level ^= 0
	     then go to NO_MORE_DIMS;

/* CHECK--this subscript must not be aliasable with any of the remaining subscripts */

	     do j = i + 1 to n_dims;
		if aliasable (p (inner_do_position + 2 + i * 2), p (inner_do_position + 2 + j * 2))
		then go to NO_MORE_DIMS;
	     end;

/* CHECK--contained do's must cover complete dimension--if that's true of this dimension, we'll
   keep going in this loop.  If not true of this dimension, we'll branch to ONE_MORE_DIM to see if
   this partial dimension can be taken out.  */

	     low = stack (work_stack_offset - 4);
	     high = stack (work_stack_offset - 3);
	     low_p = addr (x (low));
	     high_p = addr (x (high));

/* If we got this far, we're gonna take this level of implied do out.  */

	     optimized_something = "1"b;

/* If upper is not a constant, then it was output by an assign generated to make a frozen_for_do
   temp.  In that case we can pitch the assign_op node and the associated temp, and set high to be
   the original value before that assign was generated.  If the new high is a temp or array_ref,
   the assign would have caused its ref_count to be bumped, so we gotta decrement it.  */

	     if high_p -> node.node_type ^= constant_node
	     then do;
		     r = addr (q (high_p -> temporary.output_by));
		     if r -> operator.next ^= 0
		     then addr (q (r -> operator.next)) -> operator.back = r -> operator.back;
		     else do;
			     last_quad_p = addr (q (r -> operator.back));
			     last_op_index, op_index = r -> operator.back;
			     next_free_quad = last_quad_p -> operator.next;
			end;
		     addr (q (r -> operator.back)) -> operator.next = r -> operator.next;
		     high_p -> temporary.next = next_free_temp;
		     next_free_temp = high;
		     stack (work_stack_offset - 3), high = r -> operator.operand (1);
		     high_p = addr (x (high));
		     if high_p -> node.node_type = temporary_node | high_p -> node.node_type = array_ref_node
		     then high_p -> temporary.ref_count = high_p -> temporary.ref_count - 1;
		end;

/* Take out this level of implied do-loop.  The variables to watch are low_p
   and high_p, pointers to the symbol nodes for the lower and upper bounds,
   respectively, and low_value and high_value, which contain the bound values
   themselves if the corresponding bounds are constant.  The variables
   low_is_variable and high_is_variable serve as flags to indicate whether the
   bounds are constant or variable.  The tricky part is that we want to
   minimize run_time code -- the length used from this dim will be
   (high-low)+1, but we will compute it as either (high+1)-low or high-(low-1)
   if high or low is constant.  Have to take care not to do both (high+1) and
   (low-1) if both are constant.

   If the low or high bound of the implied do-loop is not the same as the
   corresponding array bound, this implied loop either does not or might not
   cover the entire dimension and we must set 'must_keep_remaining_loops'.  */

	     low_bounds_differ = "0"b;
	     if low_p -> node.node_type ^= constant_node
	     then do;
		     low_is_variable = "1"b;
		     low_value = 0;
		     if low ^= dim_p -> dimension.lower_bound (i)
		     then low_bounds_differ = "1"b;
		end;
	     else do;
		     low_is_variable = "0"b;
		     unspec (low_value) = low_p -> constant.value;
		     if dim_p -> dimension.v_bound (i).lower | dim_p -> dimension.lower_bound (i) ^= low_value
		     then do;
			     low_bounds_differ = "1"b;
			     if ^valid_subscript (dim_p, i, low_value)
			     then call print_message (422, low, stack (work_stack_offset - 5));
			end;
		end;

	     high_bounds_differ = "0"b;
	     if high_p -> node.node_type ^= constant_node
	     then do;
		     high_is_variable = "1"b;
		     high_value = 0;
		     if high ^= dim_p -> dimension.upper_bound (i)
		     then high_bounds_differ = "1"b;
		end;
	     else do;
		     high_is_variable = "0"b;
		     unspec (high_value) = high_p -> constant.value;
		     if dim_p -> dimension.v_bound (i).upper | dim_p -> dimension.upper_bound (i) ^= high_value
		     then do;
			     high_bounds_differ = "1"b;
			     if ^valid_subscript (dim_p, i, high_value)
			     then call print_message (422, high, stack (work_stack_offset - 5));
			end;
		end;

	     if low_bounds_differ | high_bounds_differ
	     then must_keep_remaining_loops = "1"b;

/* If both bounds are constants, we'll just do the calculation of vector length here.  */

	     if ^low_is_variable & ^high_is_variable
	     then vector_length = vector_length * (high_value - low_value + 1);

/* otherwise, move the high node into the stack.  If high_value is constant, add one before
   creating the constant node.  Then, move the low node into the stack.  If low_value is constant
   we'll subtract one before creating the constant node, unless high was also constant (shouldn't
   happen, but better to test).  generate a sub_op node to take the difference.  If both high and
   low were non-constant values, have to generate an explicit add of one.  Finally, if there is
   already a vector length temp part, generate a mult node to multiply it in.  Take the result and
   stuff it into vector_length_temp, bump the count of dimensions removed, set the appropriate
   array_ref subscript in the polish to the lower bound for later origin calculation, and call
   unthread_do to pop the exit_stack, take the do entry off the work stack, and throw out any quads
   that were generated in the do initialization for this do.  */

	     else do;
		     if ^high_is_variable
		     then do;
			     high_value = high_value + 1;
			     stack (work_stack_offset) = create_integer_constant ((high_value));
			end;
		     else stack (work_stack_offset) = high;
		     if low_is_variable | low_value ^= 1
		     then do;
			     if low_is_variable
			     then stack (work_stack_offset + 1) = low;
			     else do;
				     if high_is_variable
				     then low_value = low_value - 1;
				     stack (work_stack_offset + 1) = create_integer_constant ((low_value));
				     if high_is_variable
				     then low_value = low_value + 1;
				end;
			     stack (work_stack_offset + 2) = sub_op;
			     call bump_work_stack_offset (+3);
			     call process_arith ("0"b);
			     call bump_work_stack_offset (-1);
			end;

		     if low_is_variable & high_is_variable
		     then do;
			     stack (work_stack_offset + 1) = one;
			     stack (work_stack_offset + 2) = add_op;
			     call bump_work_stack_offset (+3);
			     call process_arith ("0"b);
			     call bump_work_stack_offset (-1);
			end;

		     if vector_length_temp ^= 0
		     then do;
			     stack (work_stack_offset + 1) = vector_length_temp;
			     stack (work_stack_offset + 2) = mult_op;
			     call bump_work_stack_offset (+3);
			     call process_arith ("0"b);
			     call bump_work_stack_offset (-1);
			end;
		     vector_length_temp = stack (work_stack_offset);
		end;
	     n_dims_used = n_dims_used + 1;
	     p (inner_do_position + 2 + n_dims_used * 2) = low;
	     call unthread_do;
	end;

/* If we haven't accomplished anything really, just go away. */

NO_MORE_DIMS:
	if ^optimized_something
	then go to NO_OPT_VECTOR;

/* Now we reduce vector_length*vector_length_temp to a single temporary node which goes back into
   vector_length_temp.  Take care not to generate any unneeded ops, though.  */

	if vector_length ^= 1
	then do;
		stack (work_stack_offset) = create_integer_constant ((vector_length));
		if vector_length_temp ^= 0
		then do;
			stack (work_stack_offset + 1) = vector_length_temp;
			stack (work_stack_offset + 2) = mult_op;
			call bump_work_stack_offset (+3);
			call process_arith ("0"b);
			call bump_work_stack_offset (-1);
		     end;
		vector_length_temp = stack (work_stack_offset);
	     end;

/* Back polish_offset up a bit for safety.  Otherwise we might overwrite something we haven't
   processed yet.  5 is a safe number, since we've eliminated at least 1 do op, which used at least
   5 polish entries.  */

	polish_offset = polish_offset - 5;

/* Finally we create a proper polish xmit_vector_op entry.  If we took out all the dimensions
   and if the last loop we took out started at the first element of that dimension, we can discard
   the array ref stuff and just use the array; otherwise move the array ref stuff, which has
   been changed from it's original form to now represent the origin for the xmit_vector, towards
   the beginning of the polish stack.  Put in the length temp and an xmit_vector_op following it.
   Finally, an increment_polish to skip over an appropriate number of eliminated exit_ops.  On
   return, we'll go back and run across this new stuff and just pretend the parse put it there.  */

	if n_dims_used = dim_p -> dimension.number_of_dims & ^low_bounds_differ
	then j = 1;
	else j = n_dims * 2 + 4;
	do i = 1 to j;
	     p (polish_offset + i) = p (inner_do_position + i);
	end;
	p (polish_offset + i) = vector_length_temp;
	i = i + 1;
	p (polish_offset + i) = xmit_vector_op;
	i = i + 1;
	if exit_offset ^= 0
	then if exit_stack.op = do_op
	     then exit_stack.xmit_at_this_level = exit_stack.xmit_at_this_level + 1;
	p (polish_offset + i) = increment_polish_op;
	p (polish_offset + i + 1) = eol_position + n_dims_used - polish_offset - i;

NO_OPT_VECTOR:
	return;

unthread_do:
     proc ();

dcl	st		fixed bin (18);
dcl	(a, o)		ptr;

/* unthread_do is called by optimize_vector to remove no longer needed do initialization code.
   If exit_stack.ptr is nonnull, it points to an assign_op followed by an opt_statement node,
   both of which will be freed.  If exit_stack.zero_trip_branch is nonzero, there are three
   items between the assign_op and the opt_statement: a comparison of some sort, a
   jump_false operator, and an opt_statement node.  These will also be freed.
   Whether or not there are any operators to be freed, unthread_do pops the exit stack and
   replaces one level of DO on the work stack by an assignment to the loop index of the final
   loop value plus one. */

	if exit_stack.ptr ^= null ()
	then do;

/* unthread the assign_op */

		a = exit_stack.ptr;
		call unthread (a);
		o = addr (x (a -> operator.operand (1)));
		if o -> node.node_type = temporary_node | o -> node.node_type = array_ref_node
		then o -> temporary.ref_count = o -> temporary.ref_count - 1;

		a = addr (q (a -> operator.next));

		if exit_stack.zero_trip_branch ^= 0
		then do;

/* unthread the comparison operator */

			call unthread (a);
			addr (x (a -> operator.output)) -> temporary.next = next_free_temp;
			next_free_temp = a -> operator.output;

			a = addr (q (a -> operator.next));

/* unthread the jump_false operator */

			call unthread (a);

			a = addr (q (a -> operator.next));

/* unthread the inner opt_statement node */

			call unthread (a);
			st = fixed (a -> opt_statement.back, 18);
			addr (q (st)) -> opt_statement.next = a -> opt_statement.next;
			st = fixed (a -> opt_statement.next, 18);
			addr (q (st)) -> opt_statement.back = a -> opt_statement.back;

			a = addr (q (a -> opt_statement.first_operator));

		     end;

/* unthread the final opt_statement node */

		st = fixed (a -> opt_statement.back, 18);
		addr (q (st)) -> opt_statement.next = a -> opt_statement.next;
		opst, last_opt_statement = addr (q (st));
		addr (x (a -> opt_statement.label)) -> label.statement = 0;
		if a -> opt_statement.first_operator = 0
		then do;
			last_op_index, op_index = a -> opt_statement.prev_operator;
			last_quad_p = addr (q (op_index));
			next_free_quad = last_quad_p -> operator.next;
			last_quad_p -> operator.next = 0;
		     end;
		else do;
			addr (q (a -> opt_statement.prev_operator)) -> operator.next =
			     a -> opt_statement.first_operator;
			addr (q (a -> opt_statement.first_operator)) -> operator.back =
			     a -> opt_statement.prev_operator;
		     end;
	     end;

	call pop_exit_stack ();

/* The stack is now (<>) <dp_op> <incr> <upper> <lower> <index var> <...>.
   Change it to (<>) <add_op> <upper> <one> <index var> <...> and process
   the add, leaving (<>) <sum> <index var> <...>.  Change that to (<>)
   <assign_op> <sum> <index var> <...>.  Process the assignment, leaving
   (<>) <...> and return. */

	call bump_work_stack_offset (-1);		/* Discard <do_op>. */
	stack (work_stack_offset - 1) = add_op;		/* Replace <incr> with <add_op>. */
	stack (work_stack_offset - 3) = one;		/* Replace <lower> with <one>. */
	call process_arith ("0"b);			/* Replace <add_op> <upper> <one> by its <sum>. */
	stack (work_stack_offset) = assign_op;
	call bump_work_stack_offset (+1);
	call process_assign;
	return;

unthread:
     procedure (op);

dcl	op		pointer;

/* unthread is called by unthread_do to remove a single operator from the quad chain.
   It is assumed that the operator is not at the end of the chain. */

	addr (q (op -> operator.next)) -> operator.back = op -> operator.back;
	addr (q (op -> operator.back)) -> operator.next = op -> operator.next;
	return;

     end unthread;

     end unthread_do;

aliasable:
     proc (offset1, offset2) returns (bit (1) aligned);

dcl	offset1		fixed bin (18),
	offset2		fixed bin (18);
dcl	p1		ptr,
	p2		ptr;

/* aliasable is called with the symbol table offsets of two variables or temps.  it returns "1"b if
   the two may be aliases of the same storage, "0"b otherwise.  */

	if offset1 = offset2
	then return ("1"b);
	p1 = addr (x (offset1));
	p2 = addr (x (offset2));
	if p2 -> node.node_type ^= symbol_node
	then return ("0"b);
	if ^p1 -> symbol.equivalenced & ^p1 -> symbol.parameter
	then return ("0"b);
	if ^p2 -> symbol.equivalenced & ^p2 -> symbol.parameter
	then return ("0"b);
	return ("1"b);
     end aliasable;

valid_subscript:
     procedure (dim_p, dim_no, value) returns (bit (1) aligned);

/* valid_subscript checks value to see if it is a valid subscript value for
   dimension dim_no of the array described by the dimension node pointed to
   by dim_p.  If the value is known to fall outside the legal range, "0"b is
   returned.  In all other cases, "1"b is returned. */

dcl	dim_p		pointer;
dcl	(dim_no, i)	fixed binary (18);
dcl	value		fixed binary (18);

	i = dim_no;

	if ^dim_p -> dimension.v_bound (i).lower
	then if value < dim_p -> dimension.lower_bound (i)
	     then return ("0"b);

	if ^dim_p -> dimension.v_bound (i).upper
	then if value > dim_p -> dimension.upper_bound (i)
	     then return ("0"b);

	return ("1"b);

     end valid_subscript;

     end optimize_vector;

effective_operand:
     proc (opnd) returns (fixed bin (18));

/*  Function to replace an operand by its effective value.  */

dcl	opnd		fixed bin (18);		/* incoming operand */

dcl	op		fixed bin (18);		/* outgoing operand */
dcl	p		ptr;			/* pointer to symbol */

	op = opnd;
	if op > 0
	then do;
		p = addr (x (op));
		if p -> node.node_type = label_node
		then if p -> label.format
		     then do;
			     op = p -> label.format_var;
			     p = addr (x (op));
			end;
		if p -> node.node_type = symbol_node
		then if p -> symbol.named_constant
		     then op = p -> symbol.initial;
	     end;
	return (op);
     end effective_operand;

     end fort_converter;
