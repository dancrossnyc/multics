/****^  ***********************************************************
        *                                                         *
        * Copyright, (C) BULL HN Information Systems Inc., 1989   *
        *                                                         *
        * Copyright, (C) Honeywell Information Systems Inc., 1982 *
        *                                                         *
        * Copyright (c) 1972 by Massachusetts Institute of        *
        * Technology and Honeywell Information Systems, Inc.      *
        *                                                         *
        *********************************************************** */




/****^  HISTORY COMMENTS:
  1) change(89-04-17,JRGray), approve(89-04-17,MCR8078), audit(89-04-18,Huen),
     install(89-06-09,MR12.3-1055):
     Modified to allow for archive component source programs.
  2) change(89-07-10,RWaters), approve(89-07-10,MCR8118), audit(89-07-19,Vu),
     install(89-07-31,MR12.3-1066):
     Removed the obsolete parameter source_line from the call to error_().
  3) change(89-08-01,RWaters), approve(89-08-01,MCR8069), audit(89-09-07,Vu),
     install(89-09-19,MR12.3-1068):
     Fix bug 1748.
  4) change(89-10-03,Vu), approve(89-10-03,MCR8139), audit(89-10-04,Blackmore),
     install(89-10-09,MR12.3-1086):
     Allow the use of named constants as replication factors.
  5) change(91-01-18,Blackmore), approve(91-01-18,MCR8234),
     audit(91-12-05,Huen), install(92-04-24,MR12.5-1011):
     Change entry pts. and dcl of 'constant_token' entry to allow passing a ptr
     to the current block, for the constant reference resolution fix.
                                                   END HISTORY COMMENTS */


/* lex is the lexical analysis program for the Multics PL/I compiler.  Its primary responsibilities are:
	1. Break the source program into tokens.
	2. Process %include statements.
	3. Generate a line-numbered source listing.
	4. Diagnose errors in lexical syntax of programs.

   lex also performs several other chores during its operation that eliminate a few of the
   vagaries of the PL/I language, thus making the job of subsequent phases simpler.  They are:
	1. Apply string repetition factors.
	2. Apply bit-string radix factors.
	3. Determine the type of numeric constants.
	4. Notice equal signs at level 0 of parenthesis.
	5. Notice colons at level 0 of parenthesis.

   The original version of lex was written by J.D.Mills, 26 March 1968.
   Totally rewritten to use EIS in April, 1977 by P. Green.
   Modified 770713 by PG to put back in checks for errors 157 and 158.
   Modified 771020 by PG to fix 1677 (compiler faults if no status permission to main source program),
	and 1668 (lex can fault if a stmt has > 3000 tokens)
   Modified 780607 by PG to fix 1738 (print one more character of source line for errors 157 and 158)
   Modified 780804 by PG to fix 1759 (not supplying substitutable argument for errors 109 and 110).
   Modified 790730 by PG to use rank builtin, to create enter_token facility, reducing number of calls
	to create_token, and to implement %page and %skip.
   Modified 7 October 1980 by M. N. Davidoff to fix 1989 (uninitialized variable can cause lex to fault
	on null statements) and to implement 1914 (call com_err_ with find_include_file_ code).
   Modified 25 April 1983 by R Gray to allow archive component source files
   Modified 7 Feb 1989 by RW deleted obsolete parameter to error_
   Modified 1 Jan 1989 by RW print new message disallowing pathnames in
     the %include macro
*/
/* format: style3,^indattr,ifthendo,ifthen,^indnoniterdo,indproc,^elsestmt,dclind9 */
lex:
     procedure (cblock);

/* parameter */

declare	cblock pointer parameter;			/* pointer to current block */

/* automatic */

declare	action_index fixed bin,			/* index of action to execute */
	bitcount fixed bin (24),			/* bitcount of include segment */
	char_value fixed bin (9),			/* numeric value of current character */
	code fixed bin (35),			/* standard status code */
	current_char char (1) aligned,		/* character that stopped the scan, char we are checking */
	depthx fixed bin,				/* do-loop temporary */
	decimal_value bit (9) aligned,		/* flag meaning constant is decimal, not binary */
	dx fixed bin,				/* temporary used in radix expansion */
	error_number fixed bin (15),			/* temp to hold error number for call to lex_error */
	error_token ptr,				/* temp to hold token ptr for call to lex_error */
	first_bit fixed bin,			/* temporary used in radix expansion */
	float_value bit (9) aligned,			/* flag meaning constant is float, not fixed */
	imaginary_value bit (9) aligned,		/* flag meaning constant is imaginary, not real */
	include_file_length fixed bin (21),		/* length, in chars, of new include file */
	include_file_name char (32) varying,		/* name of include file */
	include_file_ptr ptr,			/* ptr to base of include file */
	integral_value bit (9) aligned,		/* flag meaning constant is integral, not fractional */
	k fixed bin,				/* index into t_table */
	line_length fixed bin (21),			/* number of chars to be printed in listing */
	listing_on bit (1) aligned,			/* flag meaning to generate a source listing */
	max_in_chars fixed bin,			/* max string length before radix expansion */
	n fixed bin (21),				/* temp used when allocating a source node */
	new_file_number fixed bin (8),		/* number of new source file */
	new_file_token_ptr ptr,			/* ptr to token node for new include file name */
	page_macro bit (1) aligned,			/* "1"b iff macro was %page, not %skip */
	parenthesis_level fixed bin (21),		/* nesting depth of parenthesis in current statement */
	percent_sign_seen bit (1) aligned,		/* a %-sign was seen during scan...ck for %include later */
	protected bit (18) aligned,			/* "1"b iff current (constant) token is protected from default */
	radix fixed bin,				/* radix of bit string begin expanded */
	rep_factor fixed bin,			/* string replication factor */
	saved_token_index fixed bin,			/* token_index at time % was seen */
	scan_index fixed bin (21),			/* index (relative to source_index) of forward scan */
	string_max fixed bin (21),			/* temporary used in rep_factor checking */
	string_token_start fixed bin (21),		/* if token_start = 0, string_token_start holds offset
						   of first char of token in source seg */
	strx fixed bin,				/* temporary used in radix expansion */
	temp_token_string char (256) varying,		/* copy of token used by replication and radix code */
	token_index fixed bin,			/* index of current token being created */
	token_length fixed bin (21),			/* length of token in characters */
	token_ptr ptr unal,				/* ptr to current delimiter token */
	token_start fixed bin (21),			/* index of first character of current token */
	token_string char (256) varying,		/* current token in some hairy cases */
	token_string_ptr ptr,			/* ptr to token string, wherever it is */
	token_type bit (9) aligned;			/* type of current token */

/* based */

declare	source_string char (source_length) based (source_ptr),
						/* overlay of current source segment */
	token_overlay char (token_length) based (token_string_ptr);
						/* overlay of current token */

/* builtins */

declare	(addr, addrel, binary, bit, char, copy, divide, hbound, index, lbound, length, ltrim, null, rank, rtrim, search,
	string, substr, verify) builtin;

/* entries */

declare	com_err_ entry options (variable);
declare   constant_token entry (ptr, ptr, bit(9) aligned, bit(9) aligned) returns (bit(9));
declare	date_time_ entry (fixed bin (71), char (*));
declare	find_include_file_$initiate_count entry (char (*), ptr, char (*), fixed bin (24), ptr, fixed bin (35));
declare	hcs_$terminate_noname entry (ptr, fixed bin (35));

/* external static */

declare	error_table_$noentry fixed bin (35) external static;
declare	(
	pl1_stat_$cur_statement ptr,			/* ptr to tree for current statement...cleared by lex */
	pl1_stat_$level_0_colon bit (1) aligned,	/* "1"b iff colon seen at level 0 of parens */
	pl1_stat_$level_0_equal bit (1) aligned,	/* "1"b iff equal sign seen at level 0 of parens */
	pl1_stat_$line_count fixed bin,		/* grand total of number of source lines processed */
	pl1_stat_$listing_on bit (1) aligned,		/* "1"b iff line-numbered source listing being created */
	pl1_stat_$seg_name char (32) varying,		/* name of main source program, w/o .pl1 suffix */
	pl1_stat_$st_length fixed bin (21),		/* length of current statement */
	pl1_stat_$st_start fixed bin (21)		/* 0-origin char offset of begining of current statement;
						   value -1 means it has never been set */
	) external static;

/* internal static */

declare	(
	file_token_ptr ptr,				/* ptr to token node for current file name */
	lexing_after_end_stmt bit (1) aligned,		/* "1"b iff main procedure has been lexed and we are
						   just scanning comments and white space */
	line_begins_in_comment bit (1) aligned,		/* "1"b iff source line begins inside a comment */
	line_number fixed bin (14),			/* line number of current line in source segment */
	line_start fixed bin (21),			/* offset of first char to be printed in listing */
	source_depth fixed bin,			/* 0-origin nesting depth of include files */
	source_index fixed bin (21),			/* index into current source segment */
	source_length fixed bin (21),			/* length (in characters) of current source segment */
	source_ptr ptr,				/* pointer to base of current source segment */
	statement_number fixed bin (5),		/* number of statement on current line */
	suppress_line_numbers bit (1) aligned		/* next listing line should not have source numbers */
	) internal static;

declare	(and_token_ptr, arrow_token_ptr, assignment_token_ptr, asterisk_token_ptr, cat_token_ptr, colon_token_ptr,
	comma_token_ptr, expon_token_ptr, ge_token_ptr, gt_token_ptr, le_token_ptr, left_parn_token_ptr, lt_token_ptr,
	minus_token_ptr, ne_token_ptr, ngt_token_ptr, nlt_token_ptr, not_token_ptr, or_token_ptr, percent_token_ptr,
	period_token_ptr, plus_token_ptr, right_parn_token_ptr, semi_colon_token_ptr, slash_token_ptr) ptr
	     unaligned internal static;		/* ptrs to like-named tokens */

declare	1 file_stack (0:32) aligned internal static,	/* Pushdown stack used to process nested include files */
	  2 source_ptr ptr,				/* ptr to base of source segment */
	  2 file_token_ptr ptr,			/* ptr to token node for file name */
	  2 source_index fixed bin (21),		/* index (in chars) of lexical scan */
	  2 source_length fixed bin (21),		/* length (in chars) of source segment */
	  2 line_number fixed bin (14),		/* line number in source segment */
	  2 file_number fixed bin (8);		/* file number of source segment */

declare	action_table (0:128) fixed bin internal static initial (/* what action label to take given ASCII char */ (9) 9,
						/* 000-010	ctl chars */
	     1,					/* 011		tab	*/
	     8,					/* 012		newline	*/
	     (2) 1,				/* 013-014	vt, np	*/
	     (19) 9,				/* 015-037	ctl chars	*/
	     1,					/* 040		sp	*/
	     9,					/* 041		!	*/
	     2,					/* 042		"	*/
	     9,					/* 043		#	*/
	     9,					/* 044		$	*/
	     4,					/* 045		%	*/
	     17,					/* 046		&	*/
	     9,					/* 047		'	*/
	     18,					/* 050		(	*/
	     19,					/* 051		)	*/
	     10,					/* 052		*	*/
	     20,					/* 053		+	*/
	     21,					/* 054		,	*/
	     11,					/* 055		-	*/
	     7,					/* 056		.	*/
	     5,					/* 057		/	*/
	     (10) 6,				/* 060-071	0 - 9	*/
	     22,					/* 072		:	*/
	     16,					/* 073		;	*/
	     12,					/* 074		<	*/
	     23,					/* 075		=	*/
	     13,					/* 076		>	*/
	     (2) 9,				/* 077-100	? @	*/
	     (26) 3,				/* 101-132	A - Z	*/
	     (3) 9,				/* 133-135	[ \ ]	*/
	     14,					/* 136		^	*/
	     (2) 9,				/* 137-140	_ `	*/
	     (26) 3,				/* 141-172	a - z	*/
	     9,					/* 173		{	*/
	     15,					/* 174		|	*/
	     (3) 9,				/* 175-177	{ ~ PAD	*/
	     9);					/* >177		non-ASCII	*/

declare	command char (3) internal static options (constant) initial ("pl1");
declare	(
	asterisk_or_newline char (2) initial ("*
"),
	double_quote char (1) initial (""""),
	double_quote_or_newline char (2) initial ("""
"),
	HT_VT_NP_SP char (4) initial ("	 "),
	identifier_characters char (64) initial ("$0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ_abcdefghijklmnopqrstuvwxyz"),
	newline char (1) initial ("
"),
	newpage char (1) initial ("")
	) internal static;

/* include files */

%include language_utility;
%include nodes;
%include pl1_tree_areas;
%include radix_factor_constants;
%include source_list;
%include system;
%include token;
%include token_list;
%include token_types;

/* program */

/* Main entry to lex.  Convert the next source statement into tokens and return. */

	token_index = 0;
	protected = ""b;
	listing_on = pl1_stat_$listing_on;
	parenthesis_level = 0;
	pl1_stat_$level_0_colon = "0"b;
	pl1_stat_$level_0_equal = "0"b;
	percent_sign_seen = "0"b;

action (1):					/* SCAN WHITE SPACE */
	scan_index = verify (substr (source_string, source_index), HT_VT_NP_SP);

	if scan_index = 0 then
	     go to end_of_source_reached_but_no_pending_token;

	source_index = source_index + scan_index;
	current_char = substr (source_string, source_index - 1, 1);
	char_value = rank (current_char);

	if char_value >= hbound (action_table, 1) then
	     action_index = action_table (hbound (action_table, 1));
	else
	     action_index = action_table (char_value);

	go to action (action_index);

action (2):					/* SCAN STRING. current_char = double_quote */
	if source_index > source_length then do;
	     call lex_error (362, file_token_ptr);	/* eof in string */
	     go to end_of_source_reached_but_no_pending_token;
	end;

	token_start = source_index;			/* skip over double_quote */
	string_token_start = source_index - 1;		/* save offset of double_quote for make_token */
	token_length = 0;
	token_type = char_string;			/* tentative */

rescan:
	scan_index = search (substr (source_string, source_index), double_quote_or_newline);

	if scan_index = 0 then do;
	     call lex_error (362, file_token_ptr);	/* eof in string */

	     if token_start = 0 /* filling copy of token */ then
		token_string = token_string || substr (source_string, source_index);
	     else
		token_length = source_length - token_start + 1;

	     go to end_of_source_reached;
	end;

	if substr (source_string, source_index + scan_index - 1, 1) = newline then do;
	     if token_start = 0 then
		token_string = token_string || substr (source_string, source_index, scan_index);
	     else
		token_length = token_length + scan_index;

	     source_index = source_index + scan_index;
	     call print_line;
	     go to rescan;
	end;

/* Found a matching quote. Ignore it. */

	if token_start = 0 then
	     token_string = token_string || substr (source_string, source_index, scan_index - 1);
	else
	     token_length = token_length + scan_index - 1;

	source_index = source_index + scan_index;

	if source_index > source_length /* not an error */ then
	     go to end_of_source_reached;

	if substr (source_string, source_index, 1) = double_quote then do;
	     if token_start > 0 then do;		/* begin using copy, if we haven't already */
		token_string = substr (source_string, token_start, token_length);
		token_start = 0;
	     end;

	     token_string = token_string || double_quote;
	     source_index = source_index + 1;
	     go to rescan;
	end;
	else if substr (source_string, source_index, 1) = "b" then do;
	     token_type = bit_string;
	     source_index = source_index + 1;

	     if source_index <= source_length then do;
		radix = index ("1234", substr (source_string, source_index, 1));

		if radix > 0 then
		     source_index = source_index + 1;
		else
		     radix = 1;
	     end;
	     else
		radix = 1;

	     if token_start > 0 then do;
		temp_token_string = substr (source_string, token_start, token_length);
		token_start = 0;
	     end;
	     else
		temp_token_string = token_string;

/* We will now expand temp_token_string according to the specified
		        radix factor, and put the result into token_string */

	     if radix = 4 then
		if search (temp_token_string, capital_hex) ^= 0 then
		     dx = 5;
		else
		     dx = 4;
	     else
		dx = radix;

	     if verify (temp_token_string, digits (dx)) ^= 0 then do;
						/* non-binary digit in bit string */
		error_token = create_token (temp_token_string || "b", bit_string);
		call lex_error (152, error_token);
		token_type = char_string;
		token_string = temp_token_string;
	     end;
	     else if radix > 1 then do;
		max_in_chars = divide (max_bit_string_constant, radix, 21, 0);
		token_string = "";

		if length (temp_token_string) > max_in_chars then do;
						/* radix factor makes bit string too long */
		     temp_token_string = substr (temp_token_string, 1, max_in_chars);
		     error_token =
			create_token ("""" || temp_token_string || """b" || substr ("1234", radix, 1),
			no_token /* fake type - suppress quoting */);
		     call lex_error (154, error_token); /* radix factor makes bit string too long */
		end;

		do strx = 1 to length (temp_token_string);
		     first_bit = radix * (index (digits (dx), substr (temp_token_string, strx, 1)) - 1) + 1;
		     token_string = token_string || substr (expand_bit_chars (radix), first_bit, radix);
		end;
	     end;
	     else
		token_string = temp_token_string;
	end;

	if token_index >= 3 /* is there room for a replication factor? */ then
	     if token_list (token_index - 2) -> token.type = left_parn
		& token_list (token_index) -> token.type = right_parn then do;
		token_index = token_index - 3;	/* wipe out rep factor and parens */

                    if constant_token (cblock, token_list (token_index + 2), "777"b3, dec_integer) ^= dec_integer then
		     call lex_error (110, token_list (token_index + 2));
						/* rep factor is not a decimal integer */
		else do;
		     rep_factor = token_to_binary (token_list (token_index + 2));

		     if token_start > 0 then do;
			temp_token_string = substr (source_string, token_start, token_length);
			token_start = 0;
		     end;
		     else
			temp_token_string = token_string;

		     if token_type = bit_string then
			string_max = max_bit_string_constant;
		     else
			string_max = max_char_string_constant;

		     if length (temp_token_string) * rep_factor > string_max then do;
			error_token = create_token (temp_token_string || "b", bit_string);
			call lex_error (109, error_token);
						/* replicated string too long */
			rep_factor = divide (string_max, length (temp_token_string), 21, 0);
		     end;

		     token_string = "";
		     do strx = 1 to rep_factor;
			token_string = token_string || temp_token_string;
		     end;
		end;
	     end;

	if token_type = bit_string then do;
	     if length (token_string) > max_bit_string_constant then do;
						/* bit string too long */
		token_string = substr (token_string, 1, max_bit_string_constant);
		error_token = create_token (token_string || "b", bit_string);
		call lex_error (100, error_token);
	     end;

	     token_string = token_string || "b";
	end;
	else if token_start > 0 then
	     if token_length > max_char_string_constant then do;
		token_length = max_char_string_constant;
		error_token = create_token (substr (source_string, token_start, token_length), char_string);
		call lex_error (100, error_token);	/* char string too long */
	     end;
	     else
		;
	else if length (token_string) > max_char_string_constant then do;
						/* char string too long */
	     token_string = substr (token_string, 1, max_char_string_constant);
	     call lex_error (100, create_token ((token_string), char_string));
	end;

	if source_index > source_length then
	     go to end_of_source_reached;

	call make_token;
	go to check_syntax_after_constant;

action (3):					/* SCAN IDENTIFIERS */
	token_type = identifier;
	token_start = source_index - 1;

	scan_index = verify (substr (source_string, source_index), identifier_characters);

	if scan_index = 0 then do;
	     source_index = source_length + 1;
	     go to end_of_source_reached;
	end;

	source_index = source_index + scan_index - 1;
	call make_token;

/* Now make sure the syntax after the identifier is correct. */

	current_char = substr (source_string, source_index, 1);
	char_value = rank (current_char);
	source_index = source_index + 1;

	if char_value >= hbound (action_table, 1) then
	     action_index = action_table (hbound (action_table, 1));
	else
	     action_index = action_table (char_value);

	if action_index = 2 /* double quote */ then do;
	     error_token = token_list (token_index);

	     if error_token -> token.string ^= "p" & error_token -> token.string ^= "pic"
		& error_token -> token.string ^= "picture" then
		call lex_error (158, error_token);	/* double quote after identifier */
	end;

	go to action (action_index);

/* SINGLE CHARACTER TOKENS */

action (4):					/* % */
	token_start = source_index - 1;
	if percent_sign_seen then
	     call lex_error (125, null);		/* %sign while parsing macro */

	percent_sign_seen = "1"b;
	saved_token_index = token_index;
	call print_line_before_include;
	call enter_token (percent_token_ptr);
	go to action (1);

action (17):					/* & */
	token_start = source_index - 1;
	call enter_token (and_token_ptr);
	go to action (1);

action (18):					/* ( */
	token_start = source_index - 1;
	parenthesis_level = parenthesis_level + 1;
	call enter_token (left_parn_token_ptr);
	go to action (1);

action (19):					/* ) */
	token_start = source_index - 1;
	parenthesis_level = parenthesis_level - 1;
	call enter_token (right_parn_token_ptr);
	go to action (1);

action (20):					/* + */
	token_start = source_index - 1;
	call enter_token (plus_token_ptr);
	go to action (1);

action (21):					/* , */
	token_start = source_index - 1;
	call enter_token (comma_token_ptr);
	go to action (1);

action (22):					/* : */
	token_start = source_index - 1;
	if parenthesis_level = 0 then
	     pl1_stat_$level_0_colon = "1"b;

	call enter_token (colon_token_ptr);
	go to action (1);

action (23):					/* = */
	token_start = source_index - 1;
	if parenthesis_level = 0 then
	     pl1_stat_$level_0_equal = "1"b;

	call enter_token (assignment_token_ptr);
	go to action (1);

action (5):					/* SEPARATE / AND /* */
	token_start = source_index - 1;		/* tentative */
	token_type = slash;

	if source_index > source_length then
	     go to end_of_source_reached;

	if substr (source_string, source_index, 1) ^= "*" then do;
	     call enter_token (slash_token_ptr);
	     go to action (1);
	end;

/* Now lexing a comment */

	source_index = source_index + 1;

rescan_comment:
	scan_index = search (substr (source_string, source_index), asterisk_or_newline);
	if scan_index = 0 then do;
	     call lex_error (360, file_token_ptr);	/* eof in comment */
	     go to end_of_source_reached_but_no_pending_token;
	end;

	source_index = source_index + scan_index;

	if substr (source_string, source_index - 1, 1) = newline then do;
	     call print_line;
	     line_begins_in_comment = "1"b;
	     go to rescan_comment;
	end;

/* at this point substr (source_string, source_index - 1, 1) is an asterisk */

	if substr (source_string, source_index, 1) = "/" then do;
	     source_index = source_index + 1;
	     go to action (1);
	end;

	go to rescan_comment;

action (6):					/* SCAN NUMBERS AND ISUBS. current char = <digit> */
	token_start = source_index - 1;
	token_type = fixed_bin;			/* set initial token_type & flags  */
	decimal_value = is_decimal_constant;		/* .. */
	imaginary_value = "0"b;			/* .. */
	float_value = "0"b;				/* .. */
	integral_value = is_integral_constant;		/* .. */

	if source_index > source_length then
	     go to end_of_source_reached;

	call scan_past_digits;

	if substr (source_string, source_index, 1) = "." then do;
	     integral_value = "0"b;

scan_fraction:
	     source_index = source_index + 1;

	     if source_index > source_length then
		go to end_of_source_reached;

	     call scan_past_digits;
	end;
	else if source_index + 2 <= source_length then
	     if substr (source_string, source_index, 3) = "sub" then do;
		source_index = source_index + 3;
		token_type = isub;
		call make_token;
		go to action (1);
	     end;

	token_length = source_index - token_start;	/* remember length of mantissa for later error check */

	if (substr (source_string, source_index, 1) = "e") | (substr (source_string, source_index, 1) = "f") then do;
	     if substr (source_string, source_index, 1) = "e" then
		float_value = is_float_constant;

	     integral_value = "0"b;
	     source_index = source_index + 1;

	     if source_index > source_length then do;
		call missing_exponent;
		go to end_of_source_reached;
	     end;

	     if (substr (source_string, source_index, 1) = "+") | (substr (source_string, source_index, 1) = "-")
	     then do;
		source_index = source_index + 1;

		if source_index > source_length then do;
		     call missing_exponent;
		     go to end_of_source_reached;
		end;
	     end;

	     call scan_past_digits;
	end;

	if substr (source_string, source_index, 1) = "b" /* binary constant */ then do;
	     decimal_value = "0"b;
	     scan_index = source_index;		/* remember position of "b" */
	     source_index = source_index + 1;
	end;

	if source_index <= source_length then
	     if substr (source_string, source_index, 1) = "p" /* default suppression indicator */ then do;
		source_index = source_index + 1;
		protected = "1"b;
	     end;

	if source_index <= source_length then
	     if substr (source_string, source_index, 1) = "i" /* imaginary constant */ then do;
		imaginary_value = is_imaginary_constant;
		source_index = source_index + 1;
	     end;

	if decimal_value = ""b /* is this a binary constant ? */ then
	     if verify (substr (source_string, token_start, token_length), ".01") > 0 then do;
		error_token =
		     create_token (substr (source_string, token_start, source_index - token_start), i_float_dec);
						/* don't care about real token_type...guess safely */
		call lex_error (153, error_token);	/* non-binary digit in apparent binary constant */

/* Fix up the constant...restore the decimal attribute, and eliminate the "b" from
		        the token_string */

		decimal_value = is_decimal_constant;
		token_string = substr (source_string, token_start, scan_index - token_start);

		if imaginary_value ^= ""b then
		     token_string = token_string || "i";

		string_token_start = token_start;	/* save for make_token */
		token_start = 0;
	     end;

/* If the constant is protected (and wasn't copied by the error recovery
	   code above), then we have to copy it now in order to avoid getting
	   the "p" into the token. */

	if (protected ^= ""b) & token_start > 0 then do;
	     if imaginary_value ^= ""b then
		token_length = source_index - token_start - 2;
	     else
		token_length = source_index - token_start - 1;

	     token_string = substr (source_string, token_start, token_length);
	     token_start = 0;

	     if imaginary_value ^= ""b then
		token_string = token_string || "i";
	end;

	if source_index > source_length then
	     go to end_of_source_reached;

	call make_token;

/* Now make sure the syntax after the constant is correct. */

check_syntax_after_constant:
	current_char = substr (source_string, source_index, 1);
	char_value = rank (current_char);
	source_index = source_index + 1;

	if char_value >= hbound (action_table, 1) then
	     action_index = action_table (hbound (action_table, 1));
	else
	     action_index = action_table (char_value);

	if action_index = 3 | action_index = 6 | action_index = 2 /* alphabetics, numbers, double quote */ then
	     call lex_error (157, token_list (token_index));
						/* text after string */

	go to action (action_index);

action (7):					/* SEPARATE . AND NUMBERS. current_char = "." */
	token_start = source_index - 1;
	token_type = period;			/* assume for now */

	if source_index > source_length then
	     go to end_of_source_reached;

	current_char = substr (source_string, source_index, 1);
						/* grab next character */
	char_value = rank (current_char);

	if char_value <= hbound (action_table, 1) then
	     if action_table (char_value) = 6 /* next char is a <digit> */ then do;
		token_type = fixed_bin;		/* set initial token_type & flags */
		decimal_value = is_decimal_constant;	/* .. */
		imaginary_value = "0"b;		/* .. */
		float_value = "0"b;			/* .. */
		integral_value = "0"b;		/* .. */
		go to scan_fraction;
	     end;

	call enter_token (period_token_ptr);
	go to action (1);

action (8):					/* SCAN NEWLINE */
	call print_line;
	go to action (1);

action (9):					/* MISC ERRORS */
	if char_value < 32 | char_value >= 128 then do;
	     error_number = 159;			/* control chars & non-ASCII not allowed */
	     error_token = create_token (char (bit (char_value, 9)) || "b", bit_string);
	end;
	else if (current_char = "_") | (current_char = "$") then do;
	     error_number = 151;			/* $ and _ may not start identifier */
	     error_token = null;
	end;
	else do;
	     error_number = 363;			/* printing char ^a not allowed */
	     error_token = create_token ((current_char), char_string);
	end;

	call lex_error (error_number, error_token);
	go to action (1);

action (10):					/* SEPARATE * AND ** */
	token_start = source_index - 1;
	token_type = asterisk;
	token_ptr = asterisk_token_ptr;

	if source_index > source_length then
	     go to end_of_source_reached;

	if substr (source_string, source_index, 1) = "*" then do;
	     source_index = source_index + 1;
	     token_ptr = expon_token_ptr;
	end;

	call enter_token (token_ptr);
	go to action (1);

action (11):					/* SEPARATE - AND -> */
	token_start = source_index - 1;
	token_type = minus;
	token_ptr = minus_token_ptr;

	if source_index > source_length then
	     go to end_of_source_reached;

	if substr (source_string, source_index, 1) = ">" then do;
	     source_index = source_index + 1;
	     token_ptr = arrow_token_ptr;
	end;

	call enter_token (token_ptr);
	go to action (1);

action (12):					/* SEPARATE < AND <= */
	token_start = source_index - 1;
	token_type = lt;
	token_ptr = lt_token_ptr;

	if source_index > source_length then
	     go to end_of_source_reached;

	if substr (source_string, source_index, 1) = "=" then do;
	     source_index = source_index + 1;
	     token_ptr = le_token_ptr;
	end;

	call enter_token (token_ptr);
	go to action (1);

action (13):					/* SEPARATE > AND >= */
	token_start = source_index - 1;
	token_type = gt;
	token_ptr = gt_token_ptr;

	if source_index > source_length then
	     go to end_of_source_reached;

	if substr (source_string, source_index, 1) = "=" then do;
	     source_index = source_index + 1;
	     token_ptr = ge_token_ptr;
	end;

	call enter_token (token_ptr);
	go to action (1);

action (14):					/* SEPARATE ^ AND ^= AND ^< AND ^> */
	token_start = source_index - 1;
	token_type = not;
	token_ptr = not_token_ptr;

	if source_index > source_length then
	     go to end_of_source_reached;

	if substr (source_string, source_index, 1) = "=" then do;
	     source_index = source_index + 1;
	     token_ptr = ne_token_ptr;
	end;
	else if substr (source_string, source_index, 1) = "<" then do;
	     source_index = source_index + 1;
	     token_ptr = nlt_token_ptr;
	end;
	else if substr (source_string, source_index, 1) = ">" then do;
	     source_index = source_index + 1;
	     token_ptr = ngt_token_ptr;
	end;

	call enter_token (token_ptr);
	go to action (1);

action (15):					/* SEPARATE | AND || */
	token_start = source_index - 1;
	token_type = or;
	token_ptr = or_token_ptr;

	if source_index > source_length then
	     go to end_of_source_reached;

	if substr (source_string, source_index, 1) = "|" then do;
	     source_index = source_index + 1;
	     token_ptr = cat_token_ptr;
	end;

	call enter_token (token_ptr);
	go to action (1);

action (16):					/* SCAN SEMICOLON.  current_char = ";" */
	token_start = source_index - 1;

	if percent_sign_seen then do;
	     percent_sign_seen = "0"b;
	     listing_on = pl1_stat_$listing_on;
	     line_start = source_index;
	     k = saved_token_index + 1;

	     if token_list (token_index) -> token.type = percent /* %; */ then do;
		token_index = saved_token_index;
		go to action (1);			/* ignore it */
	     end;

	     k = k + 1;

	     if t_table.string = "page" | t_table.string = "skip" then do;
		if t_table.string = "page" then
		     page_macro = "1"b;
		else
		     page_macro = "0"b;

		if k = token_index /* no argument */ then
		     n = 1;
		else do;
		     k = k + 1;			/* step over keyword */

		     if token_index - k + 1 < 3 /* must be at least 3 more tokens */ then
			go to error_376;		/* a good programming lang wouldn't need this goto */

		     if t_table.type ^= left_parn | token_list (k + 1) -> token.type ^= dec_integer
			| token_list (k + 2) -> token.type ^= right_parn then do;
error_376:
			call lex_error (376, null);	/* syntax error in %page macro */
			k = token_index;		/* suppress possible error 375, below */
			n = 1;
		     end;
		     else do;
			n = token_to_binary (token_list (k + 1));
			k = k + 2;
		     end;
		end;

		if listing_on then
		     if page_macro then
			call pl1_print$non_varying (copy (newpage, n), 0);
		     else
			call pl1_print$non_varying (copy (newline, n), 0);

		if k ^= token_index then
		     call lex_error (375, null);	/* excess arguments ignored */

		token_index = saved_token_index;
		go to action (1);
	     end;

	     if t_table.string ^= "include" then do;
		token_index = saved_token_index;
		call lex_error (103, null);		/* not include or page */
		go to action (1);
	     end;

	     k = k + 1;

	     if (t_table.type = identifier) | (t_table.type = char_string) then
		include_file_name = t_table.string;
	     else do;
		token_index = saved_token_index;
		call lex_error (104, null);		/* filename not identifier or string */
		go to action (1);
	     end;

	     if k ^= token_index then do;
		token_index = saved_token_index;
		call lex_error (441, null);		/* no semicolon */
		go to action (1);
	     end;

	     token_index = saved_token_index;

	     if length (include_file_name) >= 24 then do;
		call lex_error (106, token_list (k));	/* filename too long */
		go to action (1);
	     end;

	     include_file_name = include_file_name || ".incl.pl1";
	     new_file_token_ptr = create_token ((include_file_name), identifier);

	     call find_include_file_$initiate_count (command, source_ptr, (include_file_name), bitcount,
		include_file_ptr, code);

	     if include_file_ptr = null () then do;
		if index (include_file_name, ">") ^= 0 | index (include_file_name, "<") ^= 0 then
		     call lex_error (392, new_file_token_ptr);
						/* ">" and "<" not accepted in include macro */
		else
		     call lex_error (107, new_file_token_ptr);
						/* include file not found */

	     end;
	     else if code ^= 0 then
		call com_err_ (code, command, "^a", include_file_name);

	     if pl1_stat_$last_source = source_list_length then do;
		call hcs_$terminate_noname (include_file_ptr, code);
		call lex_error (129, new_file_token_ptr);
						/* too many include files */
		go to action (1);
	     end;

	     if source_depth > hbound (file_stack, 1) then do;
		call hcs_$terminate_noname (include_file_ptr, code);
		call lex_error (112, new_file_token_ptr);
						/* nested too deep */
		go to action (1);
	     end;

	     file_stack (source_depth).source_ptr = source_ptr;
	     file_stack (source_depth).file_token_ptr = file_token_ptr;
	     file_stack (source_depth).source_index = source_index;
	     file_stack (source_depth).source_length = source_length;
	     file_stack (source_depth).line_number = line_number;
	     file_stack (source_depth).file_number = pl1_stat_$source_seg;

	     do depthx = lbound (file_stack, 1) to source_depth;
		if file_stack (depthx).source_ptr = include_file_ptr then do;
		     call hcs_$terminate_noname (include_file_ptr, code);
		     call lex_error (108, new_file_token_ptr);
						/* infinite recursion */
		     go to action (1);
		end;
	     end;

/* At this point it is OK to enter the include file */

	     source_depth = source_depth + 1;
	     include_file_length = divide (bitcount + 8, 9, 24, 0);
	     new_file_number =
		create_source (include_file_ptr, include_file_length, new_file_token_ptr, pl1_stat_$source_seg,
		line_number);

	     call enter_source_segment (include_file_ptr, include_file_length, new_file_token_ptr, new_file_number);
	     go to action (1);
	end;

	call emit_semicolon;

	if lexing_after_end_stmt then
	     call lex_error (99, null);		/* text after end of program */

	return;

/* Control transfers here whenever the lex reaches the end of the current source segment. */

end_of_source_reached:
	call make_token;

end_of_source_reached_but_no_pending_token:
	if percent_sign_seen then do;
	     call lex_error (71, null);		/* eof in macro */
	     percent_sign_seen = "0"b;		/* ignore %include */
	     token_index = saved_token_index;
	end;

	call print_line_at_eof;

	pl1_stat_$line_count = pl1_stat_$line_count + line_number;

	if source_depth = 0 /* we are now in the outermost file */ then do;
	     if lexing_after_end_stmt then do;
		if token_index > 0 /* any tokens generated? */ then
		     call lex_error (99, null);	/* text after eof */

		return;
	     end;

	     if token_index > 0 then do;
		call lex_error (361, null);		/* last stmt has no semicolon */
		call emit_semicolon;
		return;
	     end;

	     call lex_error (101, null);		/* not enough end stmts */

	     if token_index < token_list_length then
		token_index = token_index + 1;
	     token_list (token_index) = create_token ("end", identifier);
						/* generate "end" */
	     call emit_semicolon;			/* generate ";" */
	     pl1_stat_$st_length = 0;			/* no source for this phony stmt */
	     return;
	end;

	source_depth = source_depth - 1;		/* we were in incl file...pop out */
	call enter_source_segment (file_stack (source_depth).source_ptr, file_stack (source_depth).source_length,
	     file_stack (source_depth).file_token_ptr, file_stack (source_depth).file_number);

	source_index = file_stack (source_depth).source_index;
	line_start = source_index;
	line_number = file_stack (source_depth).line_number;
	go to action (1);

/* Entry to initialize all of the static variables used by the lex and create_token.
   This entry must be called before the first call to lex itself. */

initialize_lex:
     entry (bv_source_ptr, bv_source_length);

/* parameters */

declare	(
	bv_source_ptr ptr,
	bv_source_length fixed bin (21)
	) parameter;

/* program */

/* Initialize create_token, first */

	call create_token$init_hash_table;

/* Initialize static variables */

	statement_number = 1;

	suppress_line_numbers = "0"b;
	line_begins_in_comment = "0"b;
	lexing_after_end_stmt = "0"b;

/* Get static pointers to all the delimiter tokens */

	plus_token_ptr = create_token ("+", plus);
	minus_token_ptr = create_token ("-", minus);
	asterisk_token_ptr = create_token ("*", asterisk);
	slash_token_ptr = create_token ("/", slash);
	expon_token_ptr = create_token ("**", expon);
	not_token_ptr = create_token ("^", not);
	and_token_ptr = create_token ("&", and);
	or_token_ptr = create_token ("|", or);
	cat_token_ptr = create_token ("||", cat);
	ne_token_ptr = create_token ("^=", ne);
	lt_token_ptr = create_token ("<", lt);
	gt_token_ptr = create_token (">", gt);
	le_token_ptr = create_token ("<=", le);
	ge_token_ptr = create_token (">=", ge);
	ngt_token_ptr = create_token ("^>", ngt);
	nlt_token_ptr = create_token ("^<", nlt);
	assignment_token_ptr = create_token ("=", assignment);
	colon_token_ptr = create_token (":", colon);
	semi_colon_token_ptr = create_token (";", semi_colon);
	comma_token_ptr = create_token (",", comma);
	period_token_ptr = create_token (".", period);
	arrow_token_ptr = create_token ("->", arrow);
	left_parn_token_ptr = create_token ("(", left_parn);
	right_parn_token_ptr = create_token (")", right_parn);
	percent_token_ptr = create_token ("%", percent);

	source_depth = 0;
	pl1_stat_$source_seg = -1;
	pl1_stat_$last_source = -1;
	pl1_stat_$line_count = 0;

	new_file_token_ptr = create_token (pl1_stat_$seg_name || ".pl1", identifier);

/* Create a source node for the main file */

	new_file_number = create_source (bv_source_ptr, bv_source_length, new_file_token_ptr, 0, 0);

/* Enter the main source segment */

	call enter_source_segment (bv_source_ptr, bv_source_length, new_file_token_ptr, new_file_number);
	return;

/* Entry to terminate source segments. */

terminate_source:
     entry;

	do pl1_stat_$last_source = pl1_stat_$last_source to 0 by -1;
	     m = pl1_stat_$last_source;
	     call hcs_$terminate_noname ((source.seg_ptr), code);
	end;
	return;

/* Entry to write the last line and check for text after the end statement. */

write_last_line:
     entry (cblock);

declare	1 source_info aligned,
	  2 line_id char (9) unal,
	  2 sp1 char (2) unal,
	  2 file_id char (3) unal,
	  2 sp2 char (4) unal,
	  2 dtm char (16) unal,
	  2 sp3 char (2) unal,
	  2 include_name char (32) unal,
	  2 sp4 char (2) unal,
	  2 pathname char (168) unal;

declare	line_id char (9) varying aligned;
declare	five_digits picture "zzzzz";
declare	three_digits picture "zz9";

/* internal static */

declare	header char (93) varying aligned int static options (constant) init ("	SOURCE FILES USED IN THIS COMPILATION.

LINE      NUMBER  DATE MODIFIED     NAME			PATHNAME");

/* program */

	lexing_after_end_stmt = "1"b;
	call lex (cblock);                                /* see if anything there besides white space & comments */

	listing_on = pl1_stat_$listing_on;

	if ^listing_on then
	     return;

	call pl1_print$varying_nl (header);

	do m = 0 to pl1_stat_$last_source;
	     string (source_info) = "";

	     if source.file_number = ""b then
		line_id = "";
	     else do;
		three_digits = binary (source.file_number, 8);
						/* known to take three digits at most */
		line_id = ltrim (three_digits) || "-";
	     end;

	     five_digits = binary (source.line_number, 14);
						/* known to take five digits at most */
	     source_info.line_id = line_id || ltrim (five_digits);

	     three_digits = m;			/* known to take three digits at most */
	     source_info.file_id = three_digits;

	     call date_time_ (source.dtm, source_info.dtm);
	     source_info.include_name = source.name -> token.string;
	     source_info.pathname = source.pathname;
	     n = length (string (source_info)) - length (source_info.pathname) + source.pathlen;
	     call pl1_print$non_varying_nl (string (source_info), (n));
	end;
	return;

/* Internal procedures */

/* Internal procedure to create a source node for the main file and each include file */
/* Modified by Gray to allow archive component source */

create_source:
     procedure (bv_source_ptr, bv_source_length, bv_file_token_ptr, bv_file_number, bv_line_number)
	returns (fixed bin (8));

/* parameters */

declare	(
	bv_source_ptr ptr,				/* ptr to base of source segment */
	bv_source_length fixed bin (21),		/* length in chars of source segment */
	bv_file_token_ptr ptr,			/* ptr to token node of file name */
	bv_file_number fixed bin (8),			/* number of file that contains %include stmt */
	bv_line_number fixed bin (14)			/* number of line that contains %include stmt */
	) parameter;

/* automatic */

declare	cname char (32),				/* archive component name */
	dname char (256),				/* directory name of source segment */
	dtm fixed bin (71),				/* date-time modified of source segment */
	ename char (32),				/* real entry name of source segment */
	include_path char (256) varying,		/* temporary */
	uid bit (36) aligned;			/* file system unique id of segment */

/* entries */

declare	translator_info_$component_get_source_info
	     entry (ptr, char (*), char (*), char (*), fixed bin (71), bit (36) aligned, fixed bin (35));

/* external static */

declare	pl1_stat_$node_uses (18) fixed bin external static;
						/* number of nodes allocated, indexed by type */

/* program */

	call translator_info_$component_get_source_info (bv_source_ptr, dname, ename, cname, dtm, uid, code);
	if code ^= 0 then do;
	     call lex_error (344, bv_file_token_ptr);
	     include_path = "UNKNOWN DIRECTORY NAME" || bv_file_token_ptr -> token.string;
						/* give 'em something. */
	     uid = ""b;
	     dtm = 0;
	end;
	else if cname = "" then
	     include_path = rtrim (dname, "> ") || ">" || rtrim (ename);
	else
	     include_path = rtrim (dname, "> ") || ">" || before (ename || " ", ".archive ") || "::" || rtrim (cname);

	n = length (include_path);

	pl1_stat_$node_uses (14) = pl1_stat_$node_uses (14) + 1;

	m, pl1_stat_$last_source = pl1_stat_$last_source + 1;
	allocate source in (tree_area) set (source_list (m));
	source.node_type = source_node;
	source.seg_ptr = bv_source_ptr;
	source.name = bv_file_token_ptr;
	source.source_length = bv_source_length;
	source.pathname = include_path;
	source.file_number = bit (bv_file_number, 8);
	source.line_number = bit (bv_line_number, 14);
	source.uid = uid;
	source.dtm = dtm;
	return (m);

     end create_source;

/* Procedure to centralize the processing performed when the semicolon is reached. */

emit_semicolon:
     procedure;

	if token_index = token_list_length then
	     call lex_error (105, null);		/* too many tokens */
	else
	     token_index = token_index + 1;

	token_list (token_index) = semi_colon_token_ptr;

	if token_index = 1 /* we have just lexed a null statement */ then do;
	     pl1_stat_$statement_id.file_number = bit (pl1_stat_$source_seg, 8);
	     pl1_stat_$statement_id.line_number = bit (line_number, 14);
	     pl1_stat_$statement_id.statement_number = bit (statement_number, 5);
	     pl1_stat_$st_start = token_start - 1;
	end;

	statement_number = statement_number + 1;

	if statement_number >= 1f5b /* check range of statement number */ then do;
	     call lex_error (111, null);		/* too many statements */
	     statement_number = 1;
	end;

	if pl1_stat_$st_start ^= -1 /* if st_start has been set, set st_length */ then
	     pl1_stat_$st_length = (source_index - 1) - pl1_stat_$st_start;
	pl1_stat_$cur_statement = null;
	return;

     end emit_semicolon;

/* Internal procedure to set some global variables each time a new source segment is entered */

enter_source_segment:
     procedure (bv_source_ptr, bv_source_length, bv_file_token_ptr, bv_file_number);

/* parameters */

declare	(
	bv_source_ptr ptr,				/* ptr to base of source segment */
	bv_source_length fixed bin (21),		/* length in chars of source segment */
	bv_file_token_ptr ptr,			/* ptr to token node of file name */
	bv_file_number fixed bin (8)			/* number of new source file */
	) parameter;

/* program */

	source_ptr = bv_source_ptr;
	source_length = bv_source_length;
	source_index = 1;
	file_token_ptr = bv_file_token_ptr;
	pl1_stat_$source_seg = bv_file_number;
	line_number = 1;
	line_start = 1;
	pl1_stat_$st_start = -1;
	pl1_stat_$st_length = 0;
	return;

     end enter_source_segment;

/* Internal procedure to centralize error reporting by the lex. */

lex_error:
     procedure (bv_error_number, bv_token_ptr);

/* parameters */

declare	(
	bv_error_number fixed bin (15),
	bv_token_ptr ptr
	) parameter;

/* automatic */

declare	statement_length fixed bin (21);		/* length (in chars) of current statement */

/* program */

	pl1_stat_$statement_id.file_number = bit (pl1_stat_$source_seg, 8);
	pl1_stat_$statement_id.line_number = bit (line_number, 14);
	pl1_stat_$statement_id.statement_number = bit (statement_number, 5);

	if pl1_stat_$st_start = -1 /* if st_start hasn't been set, do it now */ then do;
	     pl1_stat_$st_start = line_start - 1;	/* print one source line... */

	     if source_index > source_length /* if beyond eof, cancel stmt */ then
		statement_length = 0;
	     else
		statement_length = (source_index - 1) - pl1_stat_$st_start;
	end;
	else
	     statement_length = (source_index - 1) - pl1_stat_$st_start;

	call error_ (bv_error_number, pl1_stat_$statement_id, bv_token_ptr, pl1_stat_$source_seg, (pl1_stat_$st_start),
	     (statement_length));
	return;

     end lex_error;

/* This procedure is called to enter a pointer to a token into the token
   list. */

enter_token:
     procedure (P_token_ptr);

/* parameters */

declare	P_token_ptr ptr unal parameter;

/* program */

	if token_index < token_list_length then
	     token_index = token_index + 1;

	token_list (token_index) = P_token_ptr;

	if token_index = 1 /* Now emitting first token of a stmt... */ then do;
	     pl1_stat_$statement_id.file_number = bit (pl1_stat_$source_seg, 8);
	     pl1_stat_$statement_id.line_number = bit (line_number, 14);
	     pl1_stat_$statement_id.statement_number = bit (statement_number, 5);

	     if token_start = 0 then
		pl1_stat_$st_start = string_token_start - 1;
						/* char_strings & bit_strings */
	     else
		pl1_stat_$st_start = token_start - 1;	/* everything else */
	end;

	return;

     end enter_token;

/* This procedure is called to make a token. */
/* Convention:
	token_type is set to the correct type, OR is set to fixed_bin, in which case
		the variables imaginary_value, float_value, decimal_value, and integral_value are all set.
	token_start is either set to the index of the first character of the token,
		OR is zero and token_string contains the token.  If token_start is nonzero and token_type is char_string,
		token_length is also set, otherwise it isn't.
	source_index is set to the index of the first character after the token. */

make_token:
     procedure;

/* automatic */

declare	token_ptr ptr unal;

/* program */

	if token_type = fixed_bin then
	     token_type = token_type | imaginary_value | float_value | decimal_value | integral_value;

	if token_start > 0 then do;
	     token_string_ptr = addr (substr (source_string, token_start, 1));
						/* UGH */

	     if token_type ^= char_string /* token_length is OK for char_strings */ then
		token_length = source_index - token_start;

	     if token_length > max_identifier_length then do;
		token_length = max_identifier_length;
		call lex_error (100, create_token (token_overlay, (token_type)));
	     end;
	end;
	else do;
	     token_string_ptr = addrel (addr (token_string), 1);
						/* UGH */
	     token_length = length (token_string);
	end;

	token_ptr = create_token$protected (token_overlay, (token_type), protected);
						/* we pass token_type by value to get sta's, not stba's. */

	protected = ""b;

	call enter_token (token_ptr);
	return;

/* Internal procedure (quick block) version of create_token */

%include create_token;
     end create_token;

     end make_token;

/* Internal procedure to centralize error recovery from eof in numeric tokens */

missing_exponent:
     procedure;

	token_string = substr (source_string, token_start, source_index - token_start);
	token_string = token_string || "0";		/* provide an exponent */
	token_start = 0;
	call lex_error (155, create_token ((token_string), char_string));
						/* missing exponent */
	return;

     end missing_exponent;

/* This procedure handles everything that needs to be done when a newline is seen */
/* Convention: source_index must be set to the index of the character after the newline. */

print_line:
     procedure;

	line_length = source_index - line_start;

	if listing_on then
	     call pl1_print$for_lex (source_ptr, line_number, line_start, line_length, (suppress_line_numbers),
		(line_begins_in_comment));

	line_start = source_index;
	line_number = line_number + 1;

	if line_number >= 1f14b /* check range of line number */ then
	     if ^lexing_after_end_stmt /* doesn't matter if past program portion of segment */ then do;
		call lex_error (46, null);		/* too many source lines */
		line_number = 1;			/* no use counting higher...node fields aren't big enough */
	     end;

	statement_number = 1;
	suppress_line_numbers = "0"b;
	line_begins_in_comment = "0"b;
	return;

     end print_line;

/* procedure to flush listing buffer of everything on last line of a segment.  There are two special cases
   to worry about: (1) the last line is empty, and (2) the last line doesn't end in a newline. */

print_line_at_eof:
     procedure;

	line_length = source_index - line_start;

	if line_length = 0 then
	     return;				/* nothing on last line. */

	if listing_on then
	     call pl1_print$for_lex (source_ptr, line_number, line_start, line_length, (suppress_line_numbers),
		(line_begins_in_comment));

	line_begins_in_comment = "0"b;

	if substr (source_string, source_index - 1, 1) = newline then do;
	     suppress_line_numbers = "0"b;
	     statement_number = 1;
	end;
	else
	     suppress_line_numbers = "1"b;

	return;

     end print_line_at_eof;

/* procedure to flush listing buffer of everything on the line before the percent sign. */

print_line_before_include:
     procedure;

	line_length = source_index - line_start - 1;	/* do not print percent sign */

	if line_length > 0 then do;			/* if ll=0, percent sign is in column 1...nothing to print */
	     if listing_on then
		call pl1_print$for_lex (source_ptr, line_number, line_start, line_length, (suppress_line_numbers),
		     (line_begins_in_comment));

	     suppress_line_numbers = "1"b;		/* we are no longer at the left margin */
	     line_begins_in_comment = "0"b;
	end;

	listing_on = "0"b;				/* in case %include is > 1 line long */
	return;

     end print_line_before_include;

/* Internal procedure to scan sequences of <digits>.  */
/* Convention: source_index is on character after digit upon entry, and is on
   stopping break upon exit. */

scan_past_digits:
     procedure;

	scan_index = verify (substr (source_string, source_index), "0123456789");

	if scan_index = 0 then do;			/* eof reached */
	     source_index = source_length + 1;		/* set to pseudo-char after eof */
	     go to end_of_source_reached;
	end;
	else
	     source_index = source_index + scan_index - 1;
	return;

     end scan_past_digits;

     end lex;
