" ***********************************************************
" *                                                         *
" * Copyright, (C) Honeywell Bull Inc., 1987                *
" *                                                         *
" * Copyright, (C) Honeywell Information Systems Inc., 1982 *
" *                                                         *
" * Copyright (c) 1972 by Massachusetts Institute of        *
" * Technology and Honeywell Information Systems, Inc.      *
" *                                                         *
" ***********************************************************

" HISTORY COMMENTS:
"  1) change(87-06-22,Fawcett), approve(87-06-23,MCR7734),
"     audit(87-07-14,Farley), install(87-07-17,MR12.1-1043):
"     Change the checking for the "mylock" on the ptl for after the first stac
"     instructions indicates that the lock was in fact locked.
"                                                      END HISTORY COMMENTS


" " " " " " " "" " " " " " " " " " " " " " " " " " " " " " " " " " " "
"
"	page_fault
"
"	This is the major procedure of Multics page control. For details, see
"	the Storage System PLM, Order Number AN61.
"
"	Coded 1/70 by S.Webber
" Last Modified (Date and Reason):
"	Modified by S.Webber 07/01/71 to add page multilevel
"	Modified by S.Webber 07/01/72 for followon
"	Modified by S.Webber 10/01/73 to merge with privileged code
"	Modified by B. Greenberg 06/10/74 for IOBM and put all cam/lock_ptl in page.
"	Modified by B. Greenberg 11/12/74 for overlap-lookahead core control.
"	Modified by B. Greenberg 02/05/75 for new storage system.
"	Modified by S. Webber 02/05/76 for new reconfiguration
"	Modified by B. Greenberg 03/08/76 for waiting on PTL
"	Modified by B. Greenberg 05/13/76 for pdme's with uid/pageno
"	Modified by B. Greenberg 12/76 for core_queue_man delay queue.
"	Modified by B. Greenberg 3/31/77 for disk_emergency and new page_error.
"	Modified by B. Greenberg 5/03/77 for page$pcleanup, aste.damaged.
"	Modified by RE Mullen 5/13/77 for concurrent scheduler
"	Modified by B. Greenberg 8/77 for pc_recover_sst, misc. cleanups.
"	Modified by B. Greenberg 9/20/77 for disk offline waiting.
"	Modified by B. Greenberg 3/15/78 for large sst, ptw.phm1
"	Modified by B. Greenberg 5/1/78 for parity errors.
"	Modified by D. Spector 2/20/79 for 18-bit unsigned quota
"	Modified by B. Greenberg 2/79 for variable write_limit
"	Modified by B. Greenberg 2/79 for 8-cpu port expander
"	Modified by J. A. Bush 3/80 to store fault time in machine conditions
"	Modified by B. Greenberg 6/23/80 for loop & unlock meters
"	Modified by J. A. Bush 8/80 for the DPS8/70M CPU
"	Modified by E.N. Kittlitz (per WOS) to not update PF count on gtus segments.
"	Modified by E.N. Kittlitz 11/17/80 for new dtu/dtm calculation.
"	Modified by J. Bongiovanni 1/81 for fault_counters
"         Modified by M. Pierret 11/80 to use page pinning algorithm
"	Modified by J. Bongiovanni 2/81 to remove cam/cache code
"	Modified by W. Olin Sibert, 2/26/81, for ADP conversion, phase one
"	Modified by C. Hornig, January 1982, to only CAM if segment accessible.
"	Modified by J. Bongiovanni, January 1982, to remove PML code, add
"	    extended page fault trace type
"	Modified by J. Bongiovanni, February 1982, for stocks
"	Modified by E. N. Kittlitz, 6/21/82, summer solstice sacrifice of core map.
"	Modified by J. Bongiovanni, July 1982, scs$trouble_processid, scavenger
"	Modified by J. Bongiovanni, October 1982, synchronized segment support,
"	     don't decrement quota through zero
"	Modified by E. N. Kittlitz (Massachusetts agent for W.O. Sibert) to pin those pages again.
"	Modified by Keith Loepere, October 1983, for paged unpaged dseg and
"	     for bug fix to find_core loop.
"	Modified by R. Coppola 10/13/83 to meter DF1 on per-cpu basis and
"	added code to meter cache errors when mc_trace'ing
"         Modified by BIM 83-12-03 for pgt_ IPS signal.
"	Modified by TO 84-10-17 to remove write_limit and disk_run'ing.
"	Modified by Keith Loepere, December 1984, for covert channel 
"	     detection and a little cleanup.
"	Modified by Keith Loepere, January 1985, for updated covert
"	     channel detection.
"	Modified by Keith Loepere, January 1985, for fix to aste.records race.
"	Modified by Tom Oke, February 1985, to remove a missed write_limit
"	     and disk run.
"
"	The following entries exist within this procedure (given by entry name to "page"):
"
"	done	used by the paging DIMs to signal the completion
"		of an I/O request.
"
"	enter_data places an entry into the per-process trace table
"
"	fault     transferred to upon page faults from the fault vector
"
"	lock_ptl  used to lock the page table lock
"
"	pccleanup	used to get a page out of core
"
"	pread	used to read a page into core
"
"	pwrite	used to write a page out of core
"	
"	reset_working_set is obsolete and does nothing
"
"	trace_marker places a user marker entry into the per-process
"		trace table
"
"	unlock_ptl used to unlock the page table lock
"				
"
" " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " "

"
" 
"
" The very beginning
"
	name	page_fault


	entry	wait_return,pmut_unlock_ptl
	entry	ptl_wait_return

	segdef	check_accessible		" See whether anyone can access segment
	segdef	cleanup_page		" Evict one page from memory
	segdef	cme_offsets		" Core map ITS pointers, 1 per cme word
	segdef	cme_0,cme_bp,cme_fp		" ITS to word 0 of cme
	segdef	cme_1,cme_devadd,cme_flags	" ITS to word 1 of cme
	segdef	cme_2,cme_astep,cme_ptwp	" ITS to word 2 of cme
	segdef	cme_3,cme_pin_counter,cme_synch_page_entryp	" ITS to word 3 of cme

	segdef	delete_mm_frame		" Clear out and deconfigure main memory frame
	segdef	disk_offline_event		" Wait event for disk offline
	segdef	disk_offlinep		" Check whether disk is offline
	segdef	done			" Post completion of I/O
	segdef	done_			" Post completion with PTL locked
	segdef	enter_data		" Enter per-process trace data
	segdef	fault			" Page Fault entry
	segdef	find_core_		" Find a frame of core
	segdef	init_savex		" Init x7 save stack
	segdef	init_savex_bb		" Init x7 save stack, set bb -> sst
	segdef	lock_ptl			" Lock PTL
	segdef	lock_ptl_ext		" Lock PTL from outside ALm PC
	segdef	lock_ptl_no_lp		" Lock PTL, don't save lp
	segdef	my_lp			" lp for bound_page_control
	segdef	notify_return		" Side-door return from pxss$notify_page
	segdef	page_fault_error		" Call to page_error - fatal
	segdef	pcleanup			" Entry to get a page out of core
	segdef	pf_prs			" Pointer to saved prs on page fault
	segdef	pf_scuinfo		" Pointer to SCU data on page fault
	segdef	pre_page_info		" Obsolete
	segdef	pread			" Entry to read a page
	segdef	pwrite			" Entry to write a page
	segdef	read_page_abs		" Same as read_page, but OOPV not allowed
	segdef	reset_working_set		" Obsolete
	segdef	savex			" Save x7 in save stack for recursive use
	segdef	set_up_abs_seg		" Setup abs_seg_1
	segdef	thread_in			" Thread CME as MRU
	segdef	thread_lru_ext		" Thread CME as LRU, ouside of ALM PC
	segdef	thread_out		" Thread CME out of used list
	segdef	thread_to_lru		" Thread CME as LRU
	segdef	trace_marker		" Add user marker to per-process trace
	segdef	trace_restart_fault		" Add restart_fault to per-process trace
	segdef	trace_scheduling		" Add reschedule to per-process trace
	segdef	trace_signaller		" Add signaller to per-process trace
	segdef	unlock_ptl		" Unlock PTL
	segdef	unlock_ptl_ext		" Unlock PTL, outside of ALM PC
	segdef	unsavex			" Pop save stack, tra 0,x7
	segdef	unsavex_1			" Pop save stack, tra 1,x7
	segdef	unsavex_2			" Pop save stack, tra 2,x7
	segdef	write_page		" Write page out if necessary
"

	include	page_regs
" " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " "
"
"	Temporary storage, INCLUDE files, and constants
"
" " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " "


	link	prds_link,prds$
	link	abs_seg1_link,abs_seg1$

	include	stack_frame
	include	stack_header
	include	trace_types
	include	sys_trouble_codes
	include	mode_reg
	include	pxss_page_stack
	include	page_error_types
	include	page_info
	include	apte
	include	sst
	include	tc_meters
	include	wcte
	include	sdw
	include	ptw
	include	add_type
	include	aste
	include	cmp
	include	mc
	include	null_addresses
	include	static_handlers
	include	device_error
	include	mctseg
	include	fault_vector
	include	unpaged_page_tables
"
"	check for wild transfers to bound_page_control|0

	tsx5	page_fault_error	"ERROR - TRA TO PAGE|0"
	tsx5	page_fault_error	"ERROR - TRA TO PAGE|1"
"
"
"	The following code (located at bound_page_control|2) is used for
"	hardware debugging to make it easy to restart the last page
"	fault via restoring the machine conditions and doing an RCU.
"
	epplp	my_lp,*		restore page's linkage
	eppap	pds$page_fault_data
	tra	restart_fault

	dec	0	" (bpc|5) -- address_mask used to be here

"	This location (bound_page_control|6) is left unused so that
"	obsolete patches of run limit (write_limit) will not crash system.
obsolete_wlim:
	dec	0

	even
pf_prs:	its	-1,1
pf_scuinfo:
	its	-1,1
my_lp:
	its	-1,1

cme_offsets:			" set up by initialize_faults.
cme_0:
cme_bp:
cme_fp:	its	-1,0

cme_1:
cme_devadd:
cme_flags:
	its	-1,1

cme_2:
cme_ptwp:
cme_astep:
	its	-1,2

cme_3:
cme_pin_counter:
cme_synch_page_entryp:
	its	-1,3

sdw_bits: 		" Bits for abs-seg SDW -- it is
			" Address 0, read/write, one unpaged page

	iftarget	L68	" SDW is different format for each
	  vfd	18/0,18/sdw.valid
	  vfd	1/0,14/(1024/16)-1,3/sdw.read+sdw.write,18/sdw.unpaged
	ifend

	iftarget	ADP
	  vfd	18/0,18/sdw.valid
	  vfd	14/(1024/16)-1,4/0,18/sdw.read+sdw.write+sdw.unpaged
	ifend

channel_mask_set:
	oct	17,17

unnull_mask:
	zero	-1-ptw.nulled,-1	mask to resurrect an address

	even
null:	its	-1,1
pc_signal_arglist:
	vfd	18/6,18/4,18/0,18/0

"*********************************************************************
"*********************************************************************
"*********************************************************************
"*********					**********
"*********	HERE ARE THE CONSTANTS ... AND	**********
"*********	HERE BEGINS THE CODE OF PAGE_FAULT.	**********
"*********					**********
"*********************************************************************
"*********************************************************************
"*********************************************************************
"
" " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " "
"
"	Subroutines:
"
" " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " "

lock_ptl:
	sprilp	sp|stack_frame.lp_ptr we don't do a normal 'entry' so ...
lock_ptl_no_lp:
	epbpbb	sst$		bb -> SST through out page
	lda	pds$processid	lock the page table lock
	stac	sst|sst.ptl
	tze	ptl_ok		branch if we think locked it
	read_clock		meter time waiting for lock
	cmpa	sst|sst.ptl	check for mylock on page table lock
	tze	page_error$ptl_mylock  complain if lock already set
	staq	pds$arg_1
	lda	pds$processid	get set to lock again
ptl_repeat:
	stac	sst|sst.ptl	hurry up and wait
	nop
	nop
	tnz	ptlfail		locked, see if wait needed
	read_clock	
	sbaq	pds$arg_1
	adaq	sst|sst.loop_lock_time
	staq	sst|sst.loop_lock_time
	increment	sst|sst.loop_locks	meter times we had to loop lock
ptl_ok:
	lda	pds$processid	did we lock ok?
	cmpa	sst|sst.ptl
	tze	*+2
	tsx5	page_fault_error	"ERROR - PTL STAC FAILED"
	tra	0,.ret

ptlfail:
	cmpx	.ret,pft_lret,du	locking for page fault?
	tnz	ptl_repeat	no, loop some more
	read_clock		account for partial pf time 
	sbaq	pds$time_1	account for partial pf time 
	adaq	tc_data$cpu_pf_time	account for partial pf time 
	staq	tc_data$cpu_pf_time	account for partial pf time 
	tra	pxss$ptl_wait	yes, wait for lock

ptl_wait_return:			"return location from pxss$ptl_wait
	eppap	pds$page_fault_data
	read_clock		account for rest of pf time
	staq	pds$time_1	account for rest of pf time
	tra	masked_switched_legal

pmut_unlock_ptl:
	push
	tsx	.2ret,init_savex_bb
	tsx	.ret,unlock_ptl
	eppap	sp|stack_frame.arg_ptr,*
	sprisp	sb|stack_header.stack_end_ptr
	eppsp	sp|stack_frame.prev_sp,*
	tra	pmut$unwire_unmask
unlock_ptl_ext:
	push
	tsx	.2ret,init_savex_bb
	tsx	.ret,unlock_ptl	unlock the ptl
	tra	return


unlock_ptl:
	tra	core_queue_man$unlock_ptl  Hoo, boy!

lock_ptl_ext:
	eax	.ret,.rt
	tra	lock_ptl_no_lp
.rt:	short_return

non_fatal_error:
	eax5	-1,.ret
	tsx	.2ret,page_error$non_fatal_error
	tra	0,.ret

page_fault_error:
	eax5	-1,5		set x5 to point to actual call to subroutine
	tra	page_error$page_fault_error  die

init_savex_bb:
	epp	sst,sst$
init_savex:
	eaa	save_stack	get address of save stack base
	ora	stack_size*64,dl	set up a tally word for storing into save_stack
	sta	stackp		stash this away
	tra	0,.2ret		return to the caller


savex:
	stx	.ret,stackp,id	store x7 in save stack using tally word
	ttf	0,.2ret		return to the caller if tally not runout
	tsx5	page_fault_error	"ERROR - SAVE STACK OVERFLOW"

unsavex:
	ldx	.ret,stackp,di	pop value of x7 (also updating tally word properly)
	tra	0,.ret
unsavex_1:
	ldx	.ret,stackp,di	pop value of x7 (also updating tally word properly)
	tra	1,.ret

"
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
"						"
"	Subroutines to manage used list threading	"
"						"
"						"
"						"
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

"
"	Move an entry to least-recently-used place
"
thread_to_lru:


"	assumes .cme -> cme

	cmpx	.cme,sst|sst.usedp	see if already at lru point
	tze	0,.ret		leave it if so

	szn	cme_fp,*.cme make sure threaded in (could be postpurge os)
	tmoz	0,.ret


"
"	Load pointers to current brothers, thread out.
"
	ldx	.nxt,cme_fp,*.cme next
	lxl	.lst,cme_bp,*.cme previous

	cmpx	.cme,sst|sst.wusedp	see if write point is on .cme
	tnz	*+2
	stx	.nxt,sst|sst.wusedp	make writes start at next

"	Thread out

	stx	.nxt,cme_fp,*.lst successor(last) = successor
	sxl	.lst,cme_bp,*.nxt last(successor) = last

"	Move to usedp

mv_to_usedp:
	ldx	.nxt,sst|sst.usedp  point to successor to be

"	See if usedp at wusedp. If so, back up wusedp.

	cmpx	.nxt,sst|sst.wusedp	see if wusedp = usedp
	tnz	*+2		no, not equal.
	stx	.cme,sst|sst.wusedp	our cme is new wused

	stx	.cme,sst|sst.usedp	in any case, our cme is new used.

thread_behind:
	lxl	.lst,cme_bp,*.nxt point to last to be

"	Thread to .cme

	stx	.cme,cme_fp,*.lst successor (last) = cme
	sxl	.cme,cme_bp,*.nxt last (successor) = cme

"	Thread cme to environment

	stx	.nxt,cme_fp,*.cme successor (cme) = successor
	sxl	.lst,cme_bp,*.cme last (cme) = last

	tra	0,.ret

"" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
"						"
"	Thread a cme out of the used list.		"
"						"
"" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "

thread_out:

"	Point to environment

	ldx	.nxt,cme_fp,*.cme successor = successor (cme)
	tpnz	*+2
	tsx5	page_fault_error	"ERROR - THREADING OUT UNTHREADED CME"

	lxl	.lst,cme_bp,*.cme last = last (cme)

"	Make sure replacement and writing pointers are not
"	looking at .cme.

	cmpx	.cme,sst|sst.usedp
	tnz	*+2
	stx	.nxt,sst|sst.usedp move usedp to successor if so

	cmpx	.cme,sst|sst.wusedp
	tnz	*+2
	stx	.nxt,sst|sst.wusedp

"	Thread out

	sxl	.lst,cme_bp,*.nxt last (successor) = last
	stx	.nxt,cme_fp,*.lst successor (last) = successor

	stz	cme_fp,*.cme
	tra	0,.ret

"
"" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
"						"
"	Thread an unthreaded entry to lru		"
"						"
"						"
"" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "

thread_in:
	szn	cme_fp,*.cme make sure not threaded in already
	tmoz	mv_to_usedp
	tsx5	page_fault_error	"ERROR - THREADING IN THREADED CME"

"" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
"
"	Thread an unthreaded entry to MRU.              "
"				                    "
"" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "

thread_in_mru:
	ldx	.nxt,sst|sst.wusedp thread in behind wusedp.
	szn	cme_fp,*.cme     make sure not threaded in
	tmoz	thread_behind	move behind wusedp
	tsx5	page_fault_error	"ERROR - MRU THREADING THREADED CME"

"
"	External entry to thread to lru.
"
thread_lru_ext:
	eppbp	ap|2,*		ap -> cmep
	eax	.cme,bp|0,*
	epp	sst,sst$		set up sst ptr
	tsx	.ret,thread_to_lru
	short_return
"

	inhibit	on
	even
meter_virtual_time:
	lca	1,dl		check for recursive metering
	asa	pds$vtime_count	..
	tpl	0,.ret		yes, do no more
	read_clock		get current value of CPU time
	adl	96,dl			add in correction delta
	sbaq	pds$cpu_time	..
	sbaq	pds$time_v_temp	get time used for this fault/interrupt
	staq	pds$time_v_temp
	adaq	pds$virtual_delta	save as virtual time increment
	staq	pds$virtual_delta	..
	ldaq	pds$time_v_temp	also calculate total vcpu
	adaq	tc_data$+delta_vcpu
	staq	tc_data$+delta_vcpu
	tra	0,.ret
	inhibit	off

set_up_abs_seg:
	lda	core_add
	als	coreadd_to_sdw.ls	shift core addr into sdw pos
	eaq	0		clear q-reg
	oraq	sdw_bits		turn on other interesting bits
	eppap	abs_seg1$		get pointer to core area
	ldx	.tem,lp|abs_seg1_link get segno of abs_seg1
	adlx	.tem,lp|abs_seg1_link multiply by 2
	staq	dseg$,.tem	store in descriptor segment
	cams
	tra	0,.2ret

store_pattern:
	tsx	.2ret,set_up_abs_seg get abs_seg1 ready
	ldaq	=vo36/777666333222,o36/444000111555
	staq	ap|0		and store it into the page
	staq	ap|1022		..
	tra	0,.ret

check_pattern:
	tsx	.2ret,set_up_abs_seg
	ldaq	=vo36/777666333222,o36/444000111555
	cmpaq	ap|0		if the same we have trouble
	tze 	1,.ret		take error return
	cmpaq	ap|1022		try the last 2 words
	tnz	0,.ret		ok if not the same
	tra	1,.ret		bad news if the same

clear_core:
	tsx	.2ret,set_up_abs_seg make abs_seg1 point to core_add
	eax	.tem,4096		zero out 4096 characters
	mlr	(),(pr,rl),fill(0)
	desc9a	0,0
	desc9a	ap|0,x0		.tem
	tra	0,.ret

check_for_zero:			" assumes abs_seg1 setup
	eppap	abs_seg1$
	eax	.tem,4096		number of characters in a page
	cmpc	(),(pr,rl),fill(0)
	desc9a	0,0
	desc9a	ap|0,x0		.tem
	tze	1,.ret
	tra	0,.ret


" 
"
"	The following subroutine (reset_mode_reg) is called before masking down.
"	It therefore must be inhibited.
"
	inhibit	on
reset_mode_reg:
	rsw	2			get cpu type in a
	als	mc.cpu_type_shift		get the CPU type
	ana	mc.cpu_type_mask,du
	stca	ap|mc.cpu_type_word,70	store in machine conditions
	arl	18-mc.cpu_type_shift	position in au lower
	eax4	0,au			copy to x4
	szn	pds$mc_trace_sw		is this process tracing machine conditions?
	tpl	no_trace_mc		xfer if no
	szn	pds$mc_trace_seg		Does user want to trace all M. Cs?
	tze	cp_hregs			xfer if seg number zero
	lda	ap|mc.scu.ppr.psr_word	look at the psr
	ana	scu.ppr.psr_mask,du		and out  everything except psr
	cmpa	pds$mc_trace_seg		compare psr to object we are tracing
	tze	cp_hregs			xfer if psr = object we are tracing
	lda	ap|mc.scu.tpr.tsr_word	look at tsr
	ana	scu.tpr.tsr_mask,du		and out everthing except tsr
	cmpa 	pds$mc_trace_seg		compare tsr to object we are tracing
	tnz	no_trace_mc		do not trace if psr and tsr don't have seg
cp_hregs:	scpr	ap|mc.fim_temp,01		save fault register
	ldaq	ap|mc.fim_temp		note that scpr does D.P. store and
	sta	ap|mc.fault_reg		stores zeroes in mc.fault_reg
	qrl	mc.cpu_type_shift		make room for cpu type
	orq	ap|mc.cpu_type_word		or in cpu type
	stcq	ap|mc.cpu_type_word,70	store cpu type and ext fault reg
	lda	prds$processor_tag		get cpu num
	xec	cache_ctr_tab,al		lb=> per-cpu cache err ctrs	
	lda	ap|mc.fault_reg		reload PFR
	ana	=o10,dl			cache dir parity (bit 32)?
	tze	check_efr			no, go check EFR
	aos	lb|1			yes, increment the per-cpu ctr
check_efr:
	anq	mc.ext_fault_reg_mask,du	mask unwanted bits OFF
	tze	no_efr			no bits on, bypass
	qls	2			get EFR bits in Q 1-17
	eaa	0			set up A as incrementer
efr_loop:
	ada	1,dl			increment EFR slot number
	qls	1			is this bit on?
	tpnz	efr_loop			no, but some other bit on
	tze	no_efr			no more EFR bits
	aos	lb|1,al			increment EFR counter
	tra	efr_loop			look for nxt EFR bit

no_efr:	lprplb	pds$mc_trace_buf		get packed ptr to wired trace buffer
	lxl5	lb|mctseg.hr_nxtad		x5 = rel ptr to next H. R. storage location
	cmpx5	lb|mctseg.hr_lim		do we have to roll over the trace?
	tmi	hr_roll			xfer if no
	ldx5	lb|mctseg.hr_strt		yes, pick up initial storage location
	sxl5	lb|mctseg.hr_nxtad		store new location
hr_roll:	eax5	mctseg.hr_size,5		increment storage location
	sxl5	lb|mctseg.hr_nxtad		set rel ptr to next H. R. storage location
	epplb	lb|-mctseg.hr_size,5	lp -> current HR storage location
	ldq	2,du			get a 2 for stepping address
	eax6	4			4 blocks of
scpr1:	eax5	16			16 history registers
	eax3	0			set up for L68 CPU type initally
	cmpx4	1,du			is this a DPS8/70M CPU?
	tnz	scpr2			xfer if no, it is L68
	eax3	48			yes, set up to skip first 48 hregs
	cmpx6	3,du			DU hreg? Don't have one on DPS8/70M
	tnz	scpr2			no, go execute it
	mlr	(),(pr),fill(0)		zero out this 32 word block
	desc9a	0,0
	desc9a	lb|64,32*4
	eax6	-1,6			yes, skip it
scpr2:	lda	scpr-1,6			get correct instruction
	sta	ap|mc.fim_temp		save in stack
scpr3:	xec	ap|mc.fim_temp		execute the instruction
	cmpx3	0,du			are we through skipping hregs?
	tze	scpr4			yes, go increment address
	eax3	-1,3			no, skip another
	tra	scpr3			and go execute scpr again

scpr4:	asq	ap|mc.fim_temp		increment address of instruction
	eax5	-1,5			count down
	tnz	scpr3			more of this 16 double word block
	eax6	-1,6			count down
	tnz	scpr1			another kind of hreg

	eax5	64			initially set clear count to 64
	cmpx4	1,du			is this a DPS8/70M CPU?
	tze	*+2			yes, clear all 64 hregs
	eax5	16			no, clear only 16 hregs
	lcpr	0,03			set all history regs to zero
	eax5	-1,5			count down
	tpnz	*-2			xfer if more to do
	eawplb	0
trace_mc:
	lxl5	lb|mctseg.mc_nxtad		x5 = rel ptr to next M. C. storage loc
	cmpx5	lb|mctseg.mc_lim		do we have to roll over the trace?
	tmi	mc_roll			xfer if no
	ldx5	lb|mctseg.mc_strt		yes, pick up initial storage location
	sxl5	lb|mctseg.mc_nxtad		store new location
mc_roll:
	eax5	mctseg.mc_size,5		increment storage location
	sxl5	lb|mctseg.mc_nxtad		set rel ptr to next M. C. storage location
	epplb	lb|-mctseg.mc_size,5	lp -> current MC storage location
	mlr	(pr),(pr)			move the data to wired buffer
	desc9a	ap|0,mctseg.mc_size*4
	desc9a	lb|0,mctseg.mc_size*4
no_trace_mc:
	epplb	prds$cache_luf_reg		reset cache control reg
	lcpr	lb|0,02			lcpr to reload luf and cache control
	lda	prds$mode_reg		retrieve template mode reg
	ora	mr.enable_mr+mr.enable_hist,dl enable mode reg and hist regs
	sta	prds$mode_reg_enabled	save this mode reg value
	epplb	prds$mode_reg_enabled	get pointer to temp mode reg value
	lcpr	lb|0,04			reload the mode register
	tra	0,.ret			return to caller

scpr:	scpr	lb|0,40			OU History Regs for L68, OU/DU for DPS8
	scpr	lb|32,20			CU History Regs
	scpr	lb|64,10			DU History Regs for L68, not used for DPS8
	scpr	lb|96,00			APU History Regs

cache_ctr_tab:
	epplb	wired_hardcore_data$cpu_a_cache_err_ctr_array
	epplb	wired_hardcore_data$cpu_b_cache_err_ctr_array
	epplb	wired_hardcore_data$cpu_c_cache_err_ctr_array
	epplb	wired_hardcore_data$cpu_d_cache_err_ctr_array
	epplb	wired_hardcore_data$cpu_e_cache_err_ctr_array
	epplb	wired_hardcore_data$cpu_f_cache_err_ctr_array
	epplb	wired_hardcore_data$cpu_g_cache_err_ctr_array
	epplb	wired_hardcore_data$cpu_h_cache_err_ctr_array

fault_ctr_table: 
	eppab	wired_hardcore_data$cpu_a_flt_ctr_array
	eppab	wired_hardcore_data$cpu_b_flt_ctr_array
	eppab	wired_hardcore_data$cpu_c_flt_ctr_array
	eppab	wired_hardcore_data$cpu_d_flt_ctr_array
	eppab	wired_hardcore_data$cpu_e_flt_ctr_array
	eppab	wired_hardcore_data$cpu_f_flt_ctr_array
	eppab	wired_hardcore_data$cpu_g_flt_ctr_array
	eppab	wired_hardcore_data$cpu_h_flt_ctr_array

	inhibit	off

get_pvtx:
	lda	ast|aste.pvtx_word,.aste
	arl	aste.pvtx_shift
	ana	aste.pvtx_mask,dl
	sta	pvtx
	tra	0,.ret


" 
" " " " " " " " " " " " " " "
"
"	enter_data -- entry to add data to the 'system trace list'
"	Call is:
"
"	call page$enter_data(data_word, type)
"
"	where data_word is a word value to be
"	entered into the next available slot in the trace
"	list. If type = 0 (page fault type) then a return is
"	done and the entry is not placed in the list.
"
" " " " " " " " " " " " " " " " " " " " "

	include	sys_trace

trace_signaller:
	epplp	my_lp,*		set linkage pointer
	lda	pds$condition_name	get first four characters of name
	ldq	pds$condition_name+1
	lls	9		shift out ACC count field
	ldq	signaller_type,du	get coded type
	tsx	.ret,enter
	tra	lb|0		return via special code

trace_restart_fault:
	epplp	my_lp,*
	eaa	0		code for restart is zero
	ldq	restart_fault_type,du
	tsx	.ret,enter
	tra	lb|0		return via special code

trace_marker:
	lda	ap|2,*		get char string to use as marker
	ldq	marker_type,du	set type appropriately
	tsx	.ret,enter
	short_return

trace_scheduling:
	eaa	0		code word is all zeros
	ldq	reschedule_type,du	get type code
	tra	enter

enter_data:
	lda	ap|2,*		pick up the data_word
	ldq	ap|4,*		make sure non-zero type given
	qls	30		left justify
	tze	short_return	return if illegal type given
	tsx	.ret,enter
short_return:
	short_return

return:	return

"
"	Subroutine to enter a page fault into the system-trace list
"
page_util_enter:
	stx	.aste,temp	astep
	eax	.tem,-aste_size,.ptw PTW addr - ASTE size
	sblx	.tem,temp		page number
	anx	.tem,=o377,du	only significant bits
	
	szn	tc_data$post_purge_switch	are we post-purging?
	tze	extended_page_util_enter	no -- we can stuff more data into trace

"	We are post-purging, so we need old format trace entry

	ldq	pds$page_fault_data+mc.scu.tpr.tsr_word  get segno in q
	eaa	0,.aste		get astep in a-reg
	arl	18
	lls	18		fabricate entire code word
	eaq	0,.tem		page number (low order bits) in upper
	tra	enter

extended_page_util_enter:
	lda	pds$page_fault_data+mc.scu.ppr.psr_word	PPR in AU
	ana	=o7777,du		Low-order bits only
	arl	18		PPR in AL
	ldq	pds$page_fault_data+mc.scu.ilc_word	IC in QU
	anq	-1,du		strip out garbage (indicators)
	lls	18+6		1st 30 bits or first word
	sta	temp
	lda	pds$page_fault_data+mc.scu.ppr.psr_word	PPR in AU
	ldq	pds$page_fault_data+mc.scu.cu_stat_word	CU status bits
	canq	scu.cu.if,dl	fault on instruction fetch
	tnz	*+2		yes - use PPR
	lda	pds$page_fault_data+mc.scu.tpr.tsr_word	no - use TSR
	ana	=o7777,du		Low-order bits only
	arl	18		segno in AL
	eaq	0,.tem		pageno in QU
	qls	18-8
	lrl	6
	qrl	6
	ora	temp
	orq	extended_page_fault_type,du

enter:	eppap	pds$trace		get pointer to trace structure
	ldx	.tem,ap|trace.next_free_word get current index to next free slot
	staq	ap|trace.data,.tem	save coded information
	read_clock	
	sbaq	ap|trace.ttime	get incremental time
	stq	ap|trace.temp	save in temporary
	adaq	ap|trace.ttime	recalculate last fault time
	staq	ap|trace.ttime
	ldq	ap|trace.temp	retrieve delta-time
	qrl	6		in terms of 64 micro-seconds
	cmpq	=o177777,dl	see if time is too large
	tmi	*+2		no, use it
	ldq	=o177777,dl	yes, time is too large, use standard large value
	orsq	ap|trace.data+1,.tem OR time value into trace entry
	eax	.tem,2,.tem	bump entry index
	cmpx	.tem,ap|trace.last_available_word  check for wrap-around
	tnz	trace.no_wrap	not now, though
	eax	.tem,0		we wrapped. reset to beginning
trace.no_wrap:
	cmpx	.tem,ap|trace.threshold_word signal?
	tnz	trace.no_signal     nope
	lda	ap|trace.send_ips_word  Signals enabled?
	cana	trace.send_ips,dl
	tze	trace.no_signal
	eppbp	pds$apt_ptr,*	no need to lock, we use stacq
trace.retry_ips:
	lda	sys_info$pgt_mask   This cannot recurse,
	ora	bp|apte.ips_message since we only test EQUAL to
	ldq	bp|apte.ips_message threshold. The pgt_ trace
	stacq	bp|apte.ips_message will be GREATER.
	tnz	trace.retry_ips
	lda	1,dl		set ring alarm
	sta	pds$alarm_ring	store in simulated spot
	lra	pds$alarm_ring	set for real
trace.no_signal:
	stx	.tem,ap|trace.next_free_word
	
	tra	0,.ret


reset_working_set:
	short_return

pre_page_info:
	stz	ap|4,*		pre-page calls
	stz	ap|6,*		paging device page faults
	stz	ap|8,*		no pre-paging
	short_return
"

" quota primitives - check for RQO, decrement quota, increment quota

check_quota:
	lda	ptw|0			inspect ptw
	cana	add_type.non_null,dl 	see if not_null address
	tze	check_quota.real_null
	als	0
	tpl	0,.ret			real address, return

check_quota.real_null:
	tsx	.2ret,type_terminal_quota
	tra	*+2			seg quota
	tra	0,.ret			dir quota, skip it for now

	eax	.tem,0,.aste		loop up parents
quota_c:	lxl	.tem,ast|aste.par_astep,.tem	get father
	cana	ast|aste.tqsw_word,.tem	see if terminal
	tze	quota_c			no, loop up

	szn	pds$quota_inhib		special consideration?
	tnz	0,.ret			yes, return

	lda	entry_sw			don't check on read entry
	cmpa	read_entry,dl
	tze	0,.ret			read entry, don't check

	lda	ap|mc.scu.tpr.trr_word	get ring of faulting reference
	cana	scu.tpr.trr_mask,du		see if in ring 0
	tze	0,.ret			yes, don't check quota

	ldx	.2ret,ast|aste.used,.tem 	check seg quota for over
	cmpx	.2ret,ast|aste.quota,.tem
	tnc	0,.ret			not over quota, return
	lda	PAGE_ERROR_RQO,dl		type of error to signal
	eppab	ast|0,.tem		ASTE of quota account
	tra	errquit

" subtract 1 from quota cell

reset_quota:
	eax	.tem,0,.aste		start at current aste
	tsx	.2ret,type_terminal_quota	find quota parent
	lxl	.tem,ast|aste.par_astep,.tem	seg quota applies to parent

quota_r:	xec	quota.lx,ql		fetch correct cell
	tze	*+3			don't decrement thru 0
	sblx	.2ret,1,du
	xec	quota.sx,ql		save back
	cana	ast|aste.tqsw_word,.tem	stop at terminal account
	tnz	0,.ret
	lxl	.tem,ast|aste.par_astep,.tem	parent cell
	tra	quota_r

" add 1 to quota cell

bump_quota:
	lda	aste.fmchanged,du		turn on fmchanged
	orsa	ast|aste.fmchanged_word,.aste
	
	eax	.tem,0,.aste		start at current aste
	tsx	.2ret,type_terminal_quota	find quota parent
	lxl	.tem,ast|aste.par_astep,.tem	seg quota applies to parent

quota_b:	xec	quota.lx,ql		fetch correct cell
	adlx	.2ret,1,du
	xec	quota.sx,ql		save back
	cana	ast|aste.tqsw_word,.tem	stop at terminal account
	tnz	0,.ret
	lxl	.tem,ast|aste.par_astep,.tem	parent cell
	tra	quota_b

bump_quota_covert_check:

" Add 1 to quota cell, also check that there exists a terminal quota node
" before the first upgraded node.  This should be used only for dirs,
" so that we don't require terminal dir quota for upgraded dirs.

	lda	aste.fmchanged,du		turn on fmchanged
	orsa	ast|aste.fmchanged_word,.aste
	
	eax	.tem,0,.aste		start at current aste
	tsx	.2ret,type_terminal_quota	find quota parent
	lxl	.tem,ast|aste.par_astep,.tem	seg quota applies to parent
	ora	aste.multi_class,du		we will "stop" on terminal
"					node or upgraded node
	stz	temp			assume terminal-ness

quota_bc:	xec	quota.lx,ql		fetch correct cell
	adlx	.2ret,1,du
	xec	quota.sx,ql		save back
	cana	ast|aste.tqsw_word,.tem	look at tqsw and multi_class
	tze	quota_bc_next		neither upgraded nor terminal

	lxl	.2ret,ast|aste.tqsw_word,.tem	terminal half-word
	canx	.2ret,quota.tq_mask,ql
	tnz	quota_bc_term		terminal found
	sta	temp			upgraded found first
quota_bc_next:
	lxl	.tem,ast|aste.par_astep,.tem	parent cell
	tra	quota_bc

quota_bc_term:
	lda	temp
	tnz	0,.ret			upgraded found first
	tra	1,.ret			terminal-ness okay

" determines type of quota (seg/dir), returns to call+(1/2) so depending
" also sets a to have corresponding mask bit for tqsw,
" q to have a 0/1 corresponding to (seg/dir)

type_terminal_quota:
	lda	ast|aste.nqsw_word,.aste special seg?
	cana	aste.nqsw,dl	..
	tnz	0,.ret		leave whole biz if so

	cana	aste.dirsw,dl	dirsw_word same as nqsw_word
	tnz	type.dir_quota

	lda	aste.tqsw,dl	seg quota type
	ldq	0,dl
	tra	0,.2ret
type.dir_quota:
	lda	aste.tqsw/2,dl
	ldq	1,dl
	tra	1,.2ret

quota.lx:	ldx	.2ret,ast|aste.used,.tem	instructions to load desired
	lxl	.2ret,ast|aste.used,.tem	quota cell

quota.sx:	stx	.2ret,ast|aste.used,.tem	instructions to store desired
	sxl	.2ret,ast|aste.used,.tem	quota cell

quota.tq_mask:
	arg	aste.tqsw			values for checking for tqsw
	arg	aste.tqsw/2		in bump_quota_covert_check
"
" " " " " " " " " " " " " " " " " " " " " " " "
"
"	check_accessible	subroutine to check if any processor can access
"			the page in question. This tells us whether to
"			clear all the AM's.
"
" " " " " " " " " " " " " " " " " " " " " " " "

check_accessible:
	ldx	.tem,ast|aste.strp,.aste	" get aste.strp
	tnz	0,.2ret		" must CAM
	lda	ast|aste.hc_sdw_word,.aste	" check for HC segment
	cana	aste.hc_sdw,du	" aste.hc_sdw?
	tnz	0,.2ret		" yes, CAM
				" volmap_seg_word same as hc_sdw_word
	cana	aste.volmap_seg,dl	" aste.volmap_seg?
	tnz	0,.2ret		" yes, CAM
	tra	1,.2ret		" we save some connects!
"
" " " " " " " " " " " " " " " " " " " " " " " " "
"
"	Routines to check for pages of synchronized segments
"
"
"	On evict, do housekeeping
"
"	    tsx7	check_synch_cleanup
"
"	On write, check if page must be held
"
"	   tsx7    check_for_synch_hold
"	   <return if page cannot be written>
"	   <normal return>
"
" " " " " " " " " " " " " " " " " " " " " " " " "


check_synch_cleanup:
	lda	cme_flags,*.cme		
	cana	cme.synch_held,dl		synchronized page
	tze	0,.ret			no
	tra	page_synch$cleanup		return to 0,x7

check_for_synch_hold:
	lda	ast|aste.synchronized_word,.aste
	cana	aste.synchronized,dl	synchronized page
	tze	1,.ret			no
	tsx	.2ret,savex		recursive use of x7
	tsx	.ret,page_synch$write	check whether we should write
	tra	unsavex			do not write
	tra	unsavex_1			write OK

"
" " " " " " " " " " " " " " " " " " " " " " " "
"
"	update_csl	subroutine to make sure the csl
"			for a segment is correct. It is called
"			when a page is found to be zero,
"			either by being modified to zeroes or
"			by being a non-modified null address.
"
" " " " " " " " " " " " " " " " " " " " " " " " "

update_csl:
	stz	temp		zero out entire word
	stz	temp+1		and next as well
	eax	.tem,aste_size,.aste get a pointer to the page table
	stx	.tem,temp		save for now
	stx	.tem,temp+1
	eax	.tem,1,.ptw	get page number by subtracting base of PT from ptp
	sblx	.tem,temp		(add 1 to get csl )
	stx	.tem,temp
	lda	ast|aste.csl_word,.aste pick up csl of segment
	ana	aste.csl_mask_inner,du
	arl	aste.csl_shift-18	shift to upper a, right justified
	cmpa	temp		compare with page number
	tnz	0,.ret		not the same, don't change csl
	eax	.tem,-1,.ptw	start search at previous page
	cmpx	.tem,temp+1	end search at first page of segment
	tnc	up_csl.set_csl	done (at page zero)
	ldq	ptw.valid,dl		get in core flag for compares
csl_loop:
	canq	sst|0,.tem	is current page in core ?
	tnz	up_csl.set_csl	yes, stop and set csl here
	lda	sst|0,.tem	get ptw
	cana	add_type.non_null,dl is there a real address?
	tze	up_csl.dont_count
	als	0		test sign
	tpl	up_csl.set_csl	real disk address
up_csl.dont_count:
	eax	.tem,-1,.tem	go to previous PTW
	cmpx	.tem,temp+1	are we passed the start ?
	trc	csl_loop		no, loop back and check this page
up_csl.set_csl:
"update csl into AST entry
	eaa	1,.tem		get curerrent ptp (+1 to convert to csl format)
	sbla	temp+1		subtract out base of page table
	als	aste.csl_shift-18	shift to position in AST entry
	era	ast|aste.csl_word,.aste and store in AST entry
	ana	aste.csl_mask_inner,du
	ersa	ast|aste.csl_word,.aste
	tra	0,.ret		return

" 
" " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " "
"
"	fault
"
"	This entry is transferred to from the fault vector when a page fault
"	occurs. The pointers, registers, etc. must be saved...
"
" " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " "

	even
fault:
	inhibit	on
	spri	pf_prs,*
	eppap	pf_prs,*		get pointer to MC
	sreg	ap|mc.regs	save registers
	spl	ap|mc.eis_info
	epplp	my_lp,*		set up linkage pointer
	read_clock		start metering
	staq	ap|mc.fault_time	save fault time in machine conditions
	staq	pds$time_1	and in pds
	aos	pds$vtime_count	check for recursive virtual metering
	tpnz	already_metering	..
	sbaq	pds$cpu_time	calculate virtual time
	staq	pds$time_v_temp	save until RCU time
already_metering:
	tsx	.ret,reset_mode_reg	reset mode register (turn on history regs)

	rsw	0		get set for possible tracing
	sta	sst$+sst.trace_sw

	lxl1	prds$processor_tag	get set for masking
	lprpab	scs$mask_ptr,1
	xec	scs$read_mask,1
	staq	ap|mc.mask
	ldaq	scs$sys_level
	xec	scs$set_mask,1
	xec	fault_ctr_table,1	AB => per-cpu fault ctr array
	aos	ab|0+FAULT_NO_DF1
	inhibit	off

	eppab	sp|0		save sp in ab
	eppsp	prds$+stack_header.stack_begin_ptr,*  get set for push macro
	epbpsb	sp|0		set stack base pointer
	push

	spriab	sp|stack_frame.prev_sp  now save previous sp
	lca	scu.ir.parm+1,dl	make sure parity mask is OFF
	ansa	ap|mc.scu.indicators_word

"
"	The following code checks to make sure we don't get a fault while
"	we're on the PRDS.
"
	lxl7	ap|mc.prs+6*2	however, if were not in ring 0, OK
	canx7	=o700000,du
	tnz	masked_switched_legal		not in ring 0, OK
	ldx7	ap|mc.prs+6*2	get SP at time of fault
	cmpx7	lp|prds_link	compare segment number to that of PRDS
	tze	fault_while_on_prds	bad news, return to bos
masked_switched_legal:

	tsx	.2ret,init_savex	initialize save_stack for x7
	tsx	.ret,lock_ptl	lock the page table lock
pft_lret:

	stz	entry_sw		fault entry, set switch 
	stz	ap|mc.errcode	zero error code for later use

	eppap	pds$page_fault_data	restore pointer to fault data
	epplb	dseg$		get pointer to descriptor segment

"	If a page fault is taken during an instruction fetch then the CU status
"	bit IF (instruction  fetch) will be ON.

	lxl1	ap|mc.scu.cu_stat_word Get CU status bits
	canx1	scu.cu.if,du	Is IF bit ON? 
	tze	regular_page_fault	not on, must be normal one (so use TSR)

	lda	ap|mc.scu.ppr.psr_word For an IF page fault the PSR is valid
	lxl1	ap|mc.scu.apu_stat_word Reset x1 to APU status bits.
	tra	all_page_faults	Go join normal path
regular_page_fault:
	lxl1	ap|mc.scu.apu_stat_word see what type of fault
	canx1	scu.apu.ptw+scu.apu.dsptw+scu.apu.ptw2,du is it a normal page fault?
	tnz	*+2		if one of these bits is on we're OK
	tsx5	page_fault_error	"ERROR - BAD SCU DATA NO APU BITS"
	lda	ap|mc.scu.tpr.tsr_word This is the normal path. The segno is in TSR

all_page_faults:
	ldq	ap|mc.scu.ca_word	page number is derived from CA field
	canx1	scu.apu.ptw2,du	is it a pre-page (decimal instruction)
	tze	*+2		no, don't increment page number
	adlq	1024,du		yes, up the page number by 1
	ana	scu.tpr.tsr_mask,du	leave just the segno in AU
	sta	temp		save for bound comparison.
	als	1		multiply by sdw size
	eax	.tem,0,au		put in x0
	lda	lb|1		get DSEG sdw bounds word (bound 377770)
	ora	=o7,du		convert bounds to max segno
	cmpa	temp		this is segno 377770000000
	tmi	bad_segno		Segno out of reason.
	stq	temp		save tsr word offset
	ldaq	lb|0		get addr of descriptor segment from its sdw (DBR)
	arl	sdw.add_shift	move to fixed bin
"				see if dseg paged
	sbla	unpaged_page_tables$0+upt.sst_absloc	convert to page table pointer
	tmi	not_dseg		unpaged page tables are below sst
	eppbp	sst|0,al		make bp point to first page table word
	eaa	0,.tem		get two times segno
	arl	10		get page number of dseg

	canx1	scu.apu.dsptw,du	Is this a page fault on the dseg?
	tnz	dseg_page_fault	Yes, skip the following code

	lda	ptw|0,au		get correct PTW for dseg
	cana	ptw.valid,dl		..
	tze	quit		there is fault, go take it
not_dseg:
	ldaq	lb|0,.tem		look for seg-fault, get sdw of segment
	cana	sdw.valid,dl	see if directed fault set
	tze	quit		go handle seg-fault
	staq	pf_sdw		save access fields
	arl	36-24		move to fixed bin
	sbla	sst|sst.ptwbase	no seg-fault, get page table index
	eppbp	sst|0,al		get the astep (+aste_size)
	ldq	temp		get back word offset
	qrl	page_power	convert to page number
	tra	found_faulted_page	skip code for dseg faults

dseg_page_fault:
	stq	pf_sdw+1		address word doesn't matter for dseg
	eaq	0,au		copy page number into q
found_faulted_page:
	eax	.aste,ptw|-aste_size get real astep into x3
	eppbp	ptw|0,qu		adjust ptwp to point to the actual PTW
	eax	.ptw,ptw|0	and save it in x2

	ldq	ptw|0		get PTW in q-reg
	canq	ptw.valid,dl		see if fault still exists
	tnz	quit		no, return
	canq	ptw.os,dl		is the page out of service?
	tnz	short_page_fault	process short pf
	canq	ptw.er,dl		is page in error from earlier read?
	tnz	page_read_error	yes, signal an error.

	lda	ast|aste.npfs_word,.aste see if no-page-fault-switch is on
	cana	aste.npfs,du	..
	tnz	create_segment_fault


"
"	Here the commitment has been made to actually
"	read in one page of virtual memory.
"

	tsx	.ret,pc_trace$page_fault


	tsx	.ret,read_page
	    tra	readin.goon	must wait for page
	    tra	readin.goon	
	    tra	wait_any_event_apte	wait for volmap event (in APTE by now)

readin.goon:
	tsx	.ret,pc_trace$page_fault_end
	tsx	.ret,page_util_enter enter the page in the trace list
"
"	The following are various per-process meters about paging activity
"	as well as some system meters about where page faults are
"	happening.
"
	lda	ast|aste.per_process_word,.aste count pdir faults
	cana	aste.per_process,du
	tze	*+2
	increment	sst|sst.pdir_page_faults

	lxl	.tem,ast|aste.par_astep,.aste	count faults in segs off dirs off root
	lxl	.tem,ast|aste.par_astep,.tem
	cmpx	.tem,sst|sst.root_astep+1
	tnz	*+2
	increment	sst|sst.level_1_page_faults

	lda	ast|aste.dirsw_word,.aste	count dir pfts
	cana	aste.dirsw,dl
	tze	readin.meter_ndir_pft	meter in AST
	increment	sst|sst.dir_page_faults
	tra	readin.meter_sgdir_join

readin.meter_ndir_pft:			"count in ASTE
	cana	aste.gtus,du		" gtus in same word as dirsw
	tnz	readin.meter_sgdir_join	" if transparent, can't count faults
	lda	ast|seg_aste.usage,.aste
	adla	1,dl			LOGICAL arith, please
	sta	ast|seg_aste.usage,.aste

readin.meter_sgdir_join:
	lda	pds$page_fault_data+mc.scu.tpr.trr_word  count ring 0 page faults
	cana	scu.tpr.trr_mask,du
	tnz	*+2
	increment	sst|sst.ring_0_page_faults

	aos	pds$page_waits	meter page waits
	aos	pds$number_of_pages_in_use
	ldq	sst|sst.nused	number of available pages
	eppbb	pds$apt_ptr,*	can also be used to reference tc_data
	epbpbp	bb|0		get pointer to base of apt
	lda	tc_data$n_eligible	make sure it isn't zero (can it ever be?)
	tze	no_eligible
	sta	temp
	div	temp		divide by the eligibility
	eaa	0		clear a-reg
	staq	temp		save measurement
	cmpq	pds$number_of_pages_in_use  are we in equilibrium
	tmi	in_equilibrium	yes
	ldq	pds$number_of_pages_in_use  until then use this value
	staq	temp		save it as the measure
	asq	temp+1		which is doubled when not in equilibrium
in_equilibrium:
	adaq	bp|cumulative_memory_usage
	staq	bp|cumulative_memory_usage
	ldaq	temp		reload measure for updating apte.paging_measure
	adaq	bb|apte.paging_measure add the paging measure
	staq	bb|apte.paging_measure and save it again

no_eligible:
	ldx2      bb|apte.wct_index
	tze	skip_pinning	no WCTEs yet (initialization)
"				bp -> to base of apt (set above)
	lxl	.tem,bp|wcte.pin_weight,2 get pin weight
	stx	.tem,cme_pin_counter,*.cme

skip_pinning:
	epp	sst,sst$		restore sst ptr

          sxl       .cme,cmep           save cmep
          tsx       .ret,claim_mod_core write out mod pages
          lxl       .cme,cmep
	ldx	.ptw,ptp_astep	reload .ptw
	lxl	.aste,ptp_astep	and .aste

	eppbp	tc_data$		restore tcd ptr
	read_clock		meter page fault time
	sbaq	pds$time_1	get cpu time for this fault
	adaq	bp|cpu_pf_time	keep sum of times
	staq	bp|cpu_pf_time
	aos	bp|cpu_pf_count	and count of faults

"
"
"	Wait for the page fault as appropriate.
"
	epp	ptw,sst|0,.ptw


wait_ret:			"here to wait for non/pd i/o
	lda	ptw|0		make this check just in case..
	cana	ptw.os,dl
	tze	quit

				"tra to pxss to wait for PTW I/O.
	ldq	cme.notify_requested,dl set flag for notify
	orsq	cme_flags,*.cme ..
	eaa	0,.ptw		create PTW event
wait_page_fault_event:
	arl	18		right justified
wait_any_event:
	eppap	pds$apt_ptr,*	get apte ptr
	sta	ap|apte.wait_event	make it where can get notified.

wait_any_event_apte:
	store_clock pds$time_1
	tsx	.ret,unlock_ptl	dump posting queue, possibly notifying
				"this event, and unlock ptl.
	meter_time pds$time_1,sst|sst.pf_unlock_ptl_time,sst|sst.pf_unlock_ptl_meterings

	tra	pxss$page_wait


"
"
"	End of page fault processing here.
"	These labels restart the page fault.
"
quit:	tsx	.ret,unlock_ptl	unlock page table lock

wait_return:			"return location from pxss$page_wait
	eppap	pds$page_fault_data	get pointer to fault data

	read_clock
	cmpaq	pds$first_covert_event_time
	tpl	wait_return_no_delay

" must wait until first_covert_event_time is met- that is, until covert channel
" time is up

	ldaq	pds$first_covert_event_time
	staq	pds$arg_1
	tra	pxss$page_pause	" will return at wait_return

wait_return_no_delay:
	inhibit	on
	ldaq	ap|mc.mask	retrieve previous mask
	oraq	channel_mask_set	turn on all channel mask
	anaq	scs$open_level	turn off unconfigured channel mask bits
	lxl1	prds$processor_tag
	lprpab	scs$mask_ptr,1
	xec	scs$set_mask,1

	ldaq	prds$+stack_header.stack_begin_ptr  restore stack end pointer for PRDS
	staq	prds$+stack_header.stack_end_ptr

	odd
	tsx	.ret,meter_virtual_time measure time to be taken out as virtual

restart_fault:
	lpl	ap|mc.eis_info	restore EIS pointers and lengths
	lreg	ap|mc.regs
	lpri	pf_prs,*
	rcu	pf_scuinfo,*
	inhibit	off

"

"
"	Error and unconventional cases in page fault processing.
"
fault_while_on_prds:
	lca	trbl_prds_pf,dl	flag for page fault on prds
	sta	scs$sys_trouble_pending
	lda	pds$processid	save our process ID
	stac	scs$trouble_processid  if we're the first
	lxl1	prds$processor_tag
	cioc	scs$cow_ptrs,1*	send connect to self
	nop
	nop
	nop
	tra	fault_while_on_prds
"
"	Come here when fault taken on page already being read.
"

short_page_fault:
"	Compute cme addr so that wait_ret can turn on notify_requested.
"

	increment	sst|sst.short_pf_count	meter

	iftarget	l68	" Shift different on L68/ADP
	   qrl	ptw_to_cmep.rl
	ifend
	iftarget	adp
	   anq	ptw_add_mask,du	" Must mask off all but page number
	   qls	ptw_to_cmep.ls
	ifend

	eax	.cme,sst|sst.cmp,*qu point to cme.
	tra	wait_ret		and wait for the page

"
"	Error bit set by done_ (done_read). Signal in
"	faulting process.
"
page_read_error:

	tsx	.ret,disk_offlinep	is disk down as per pvt?
	 tra	wait_any_event	yes, wait for it, event in A

	lca	ptw.er+1,dl	turn off error flag
	ansa	ptw|0		in PTW

	lda	PAGE_ERROR_IOERR,dl
	eppab	ast|0,.aste	ASTE
	tra	errquit

bad_segno:
	lda	PAGE_ERROR_BADFAULT,dl
	eppab	null,*
	tra	errquit

errquit:	sta	pc_err_type
	sprpab	pc_err_astep
	sprp	ptw,pc_err_ptwp

	tsx	.ret,unlock_ptl

"
"	Call pc_signal to copy machine conditions, and otherwise set
"	up for the signaller

	ldaq	pc_signal_arglist
	staq	arg
	eppap	pc_err_type
	spriap	arg+2
	eppap	pc_err_astep
	spriap	arg+4
	eppap	pc_err_ptwp
	spriap	arg+6
	call	pc_signal$pc_signal(arg)

"
"	Now change the stack pointer so that if a process takes a page
"	fault while signalling which also gets an error (RQO possibly)
"	that we don't crash the system because our sp will still point
"	to the PRDS.
"
	ldaq	prds$+stack_header.stack_begin_ptr
	staq	prds$+stack_header.stack_end_ptr  reset stack end pointer
	eppap	pds$signal_data
	eppsp	ap|mc.prs+6*2,*	change sp to that at time of the fault

"
"	Now complete the virtual time calculation that were by-passed because we did
"	not do an RCU.
"
	tsx	.ret,meter_virtual_time
	tra	signaller$signaller	now let the signaller do the work

"	data for signal call.


" 
" " " " " " " " " " " " " " " " " " " " " " " " " " " " " "
"
"	pread
"
"	Entry to read a page into core.
"
"	Call is:
"		call page$pread(astep,pageno,waitev)
"
" " " " " " " " " " " " " " " " " " " " " " " " " " " " "

pread:
	push
	stz	ap|6,*
	lda	read_entry,dl	set entry switch
	sta	entry_sw
	tsx	.2ret,init_savex	set up stack

pread.loop:			"may have paged in 2 or more stages, tho.
	eppap	sp|stack_frame.arg_ptr,*
	eppbp	ap|2,*
	epp	sst,sst$
	eppbp	bp|0,*
	eax	.aste,bp|0
	lda	ap|4,*
	eax	.ptw,bp|aste_size,al	 point to ptw
	epp	ptw,sst|0,.ptw

	lda	ptw|0		is page in?
	cana	ptw.valid,dl
	tnz	return		yes, no problem.

	cana	ptw.er,dl		error from previous read?
	tze	pread.read_page	no, just read

	tsx	.ret,disk_offlinep
	 tra	pread.wait_any	go wait global event if needed

pread.read_page:
	tsx	.ret,read_page	do some work.
	 tra	pread.wait	must wait, indicate or loop
	 tra	pread.loop	must check again.

	eppap	pds$apt_ptr,*	retrieve wait event
	lda	ap|apte.wait_event
	 tra	pread.wait_any	volmap event
pread.wait:


pread.wait_ret:
	arl	18		convert to wait event
pread.wait_any:
	eppap	sp|stack_frame.arg_ptr,* retrieve arg pointer
	sta	ap|6,*		return wait event
	tra	return
"
" " " " " " " " " " " " " " " " " " " " " " " " " " " " " " "
"
"	pwrite
"
"	Entry to write a page out.
"
"	Call is:
"		call page$pwrite(astep,pageno)
"
" " " " " " " " " " " " " " " " " " " " " " " " " " " " " "  "

pwrite:
	push
	lda	write_entry,dl	set up entry switch
	sta	entry_sw
	eppbp	ap|2,*		get pointer to APT
	eppbp	bp|0,*
	epbpbb	bp|0		let bb point to base of sst
	eax	.aste,bp|0
	lda	ap|4,*		get page number
	eax2	bp|aste_size,al
	eppbp	sst|0,.ptw	make sure bp points to PTW
	lda	ptw|0		pick up page table word

	iftarget	l68	" Shift different on L68/ADP
	   arl	ptw_to_cmep.rl
	ifend
	iftarget	adp
	   ana	ptw_add_mask,du	" Must mask off all but page number
	   als	ptw_to_cmep.ls
	ifend

	eax	.cme,sst|sst.cmp,*au
	tsx	.2ret,init_savex	initialize save stack for x7
	tsx	.ret,write_page


	tra	return
" 
" " " " " " " " " " " " " " " " " " " " " " " " " " " " " " "
"
"	pcleanup
"
"	Entry to get a page out of core.
"
"	Call is:
"		call page$pcleanup (astep, pageno)
"
" " " " " " " " " " " " " " " " " " " " " " " " " " " " " " "

pcleanup:
	push
	lda	cleanup_entry,dl
	sta	entry_sw

	tsx	.2ret,init_savex_bb

	epp	ptw,ap|2,*
	epp	ptw,ptw|0,*	get astep
	eax	.aste,ptw|0
	lda	ap|4,*		get pageno
	eax	.ptw,ptw|aste_size,al
	epp	ptw,sst|0,.ptw

	lda	ptw|0		get ptw
	cana	add_type.disk+ptw.os,dl
	tze	*+2
	tsx5	page_fault_error	"ERROR - PCLEANUP: CALLED ON BAD-STATE PAGE

	iftarget	l68	" Shift different on L68/ADP
	   arl	ptw_to_cmep.rl
	ifend
	iftarget	adp
	   ana	ptw_add_mask,du	" Must mask off all but page number
	   als	ptw_to_cmep.ls
	ifend

	eax	.cme,sst|sst.cmp,*au
	arl	cmep_to_coreadd.rl
	sta	core_add

	lca	ptw.valid+1,dl
	ansa	ptw|0		turn off ptw access

	tsx	.2ret,check_accessible	" only CAM if needed
	tsx	.ret,cam_cache$cam_cache	make sure it takes

	tsx	.ret,cleanup_page	do the work.
	return
"
" " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " "
"
"	read_page, read_page_abs
"
"	Subroutine called by tsx7 to read a page into core (or if
"	the page has never beeen referenced it will zero the core).
"	A free block of core is found and possibly several 'writes' are
"	queued in searching for the free core for the read_page entry.
"	For the read_page_abs entry the free block of core
"	specified by the caller is used.
"
"	tsx7	read_page
"	<return with wait event in Areg>
"	<return if page in memory>
"	<return with volmap wait event set in APTE>
"
"	The subroutine expects
"
"		x2 = pointer to PTW
"		x3 = pointer to AST entry
"		bp = pointer somewhere into SST
"		bb = pointer to base of SST
"
"	In addition, the read_page_abs entry expects
"
"		x4 = pointer to core map entry of free block
" " " " " " " " "" " " " " " " " " " " " " " " " " " " " " " " " "

read_page_abs:
	tsx	.2ret,savex	recursive use of index 7

	tsx	.ret,check_allocation	make sure we have disk.
	 tsx5	page_fault_error	"ERROR - OOPV ON EHS SEG"
	 tra	read_page_abs.apte_event	volmap event

	tra	read_page_join

read_page_abs.apte_event:
	eppap	pds$apt_ptr,*	event is in APTE
	lda	ap|apte.wait_event
	tra	unsavex_2		return to caller

read_page:
	tsx	.2ret,savex	recursive use of index 7

	tsx	.ret,check_quota	check for quota overflow
	tsx	.ret,check_allocation is there disk available?
	 tra	read_page.oodev	no disk on this PV
	 tra	unsavex_2		must wait for volmap event

	stx	.ptw,ptp_astep	save x2 and x3 for now
	sxl	.aste,ptp_astep		..
	tsx	.ret,find_core	find a free block of core
	ldx	.ptw,ptp_astep	restore x2 and x3
	eppbp	sst|0,.ptw	make sure bp points to PTW as well
	lxl	.aste,ptp_astep		..
"
read_page_join:

"	At this point, a cme to ptw binding is established.  To validate the
"	assumptions of pc_recover_sst, it must be done in following order:
"		Auxiliary info into CME
"		cme.ptwp <= ptwp
"		ptw.add <= CORE

	lca	   ptw.phm+ptw.phm1+ptw.er+1,dl  " turn off bad bits.
	ansa	ptw|0
	lda	ptw|0		copy device address to core map entry
	staddra	cme_devadd,*.cme store address from ptw into cme
	lca	   cme.io+cme.phm_hedge+cme.removing+cme.notify_requested+1,dl
	ansa	cme_flags,*.cme clear random flags

	sxl	.aste,cme_astep,*.cme Associate astep with cme, not ptp yet.
"	Do not store ptwp in cme until cme is ready, core clear, or ptw os.


	eaa	0,.cme		copy rel(cmep) to a-reg
	sbla	sst|sst.cmp+1	to get core address
	arl	cmep_to_coreadd.rl
	sta	core_add		save core address

	ldq	aste.init,du	turn off init bit in aste
	orsq	ast|aste.init_word,.aste	..
	ersq	ast|aste.init_word,.aste	..
	ldq	ast|aste.np_word,.aste increment number of pages in core
	anq	aste.np_mask,dl
	tnz	read.incr_np
"
" Reading in the first page causes dtu to advance.  Also, the dtm may be
" advanced.  Lets see.
"
	ldq	1,dl		this will advance to 1 page
	szn	pds$throttle_segment_state_changes
	tze	read.set_np	don't count events
	szn	entry_sw
	tnz	read.set_np	only count on fault side

" Count this event.  Our assumptions:
" dtm -	w access implies that we can (and must assume we will) advance dtm.
"	Advancing dtm is always lower class visible since it propogates up
"	the hierarchy.  However, we know that dirs advance dtm only when 
"	they want to (in sum$dirmod), so we don't count dirs as setting 
"	dtm here.
"
" dtu -	w access implies that our authorization equals the access class 
"	of the object, hence our setting dtu is not lower class visible.
"	However, multi-class and directories violate this rule.
"
" Hence: a non-directory, multi-class writable object advances dtu and dtm
" in a lower class visible way.  All other cases advance either dtu or dtm
" but not both.

	lda	pf_sdw+1
	cana	sdw.write,du	check for write
	tze	read.covert_1	no write
	lda	ast|aste.dirsw_word,.aste " (also multi_class word)
	cana	aste.multi_class,du
	tze	read.covert_1	non-multi-class
	cana	aste.dirsw,dl
	tnz	read.covert_1	is a dir

	tsx	.ret,limit_covert_channel	both dtu and dtm set
read.covert_1:
	tsx	.ret,limit_covert_channel	only dtu or dtm set
	ldq	1,dl		advance np to 1 page
	tra	read.set_np

read.incr_np:
	adlq	1,dl
	erq	ast|aste.np_word,.aste
	anq	aste.np_mask,dl
read.set_np:
	ersq	ast|aste.np_word,.aste

	lda	cme_devadd,*.cme  pick up cme devadd
	cana	add_type.non_null,dl is there an address?
	tnz	*+2		must have real allocation here
	tsx5	page_fault_error	"ERROR - NO ALLOCATION IN PTW: READ_PAGE"
	als	0		is it a real address?
	tpl	must_read		yes, actually read it

	"
	"Make zeroes for a predeposited address.
	"
	"tra	read.create_zeros	is right on the next page
"
"
"	Page had either a null or nulled address in PTW.
"	Create a fresh page of zeroes.
"

read.create_zeros:
	lda	ast|aste.records_word,.aste
	adla	=o001000,dl		increment records used
	era	ast|aste.records_word,.aste
	ana	aste.records_mask_inner,dl
	ersa	ast|aste.records_word,.aste

" Adding a page can be a covert event, if this is a multi-class object
" (records used, etc. lower class visible) or if this is a dir without
" terminal quota between it and the nearest upgraded node.
" We don't have to worry about questions of setting csl/ru since the only
" cases where page creations are covert events are cases where the page
" creations are performed by trusted code themselves, and in which we know
" that pages are created serially.  The user cannot create any random page
" in these segments, only the next.  Thus, csl and ru contain the same
" information, even though ru may later become less than csl if some of
" these new pages end up zero.

	szn	pds$throttle_segment_state_changes
	tze	read.bump_quota	don't count events
	szn	entry_sw
	tnz	read.bump_quota	only on fault side

	lda	ast|aste.multi_class_word,.aste
	cana	aste.multi_class,du
	tze	read.create_check_dir
	tsx	.ret,limit_covert_channel	multi-class
	tra	read.bump_quota

read.create_check_dir:
	cana	aste.dirsw,dl
	tze	read.bump_quota	non-dir

" We have a dir.  We shall do a special bump quota which checks for
" terminal-ness.

	tsx	.ret,bump_quota_covert_check increment used
	tsx	.ret,limit_covert_channel	upgraded found first
	tra	read.quota_bumped

read.bump_quota:
	tsx	.ret,bump_quota	increment used
read.quota_bumped:
	increment	sst|sst.new_pages	meter new pages created
	tsx	.ret,clear_core	zero out the core
"
"	Now it is safe to store .ptw in cme
"
	stx	.ptw,cme_ptwp,*.cme
	lda	core_add		pick up core address again
	als	coreadd_to_ptw.ls
	ora	add_type.core,dl
	staddra	ptw|0		store in ptw

	lda	ptw.phu+ptw.valid+df1,dl make used, accessible, refresh bit
	orsa	ptw|0

	stx	.aste,temp	calculate page number
	eax	.tem,1-aste_size,.ptw by subtracting astep from (ptwp-aste_size+1)
	sblx	.tem,temp
	stz	temp
	sxl	.tem,temp		save in temp
	lda	ast|aste.csl_word,.aste pick up current csl
	ana	aste.csl_mask_inner,du
	arl	aste.csl_shift
	cmpa	temp		compare ...
	tpl	unsavex_1		csl already larger than this
	ldq	temp		retrieve new csl value
	qls	aste.csl_shift	position for store into ASTE
	erq	ast|aste.csl_word,.aste
	anq	aste.csl_mask_inner,du
	ersq	ast|aste.csl_word,.aste
	tra	unsavex_1
"
" covert channel test - update covert channel event count, test bandwidth
"
limit_covert_channel:
	aos	pds$covert_event_count
	tmi	0,.ret		not enough events to monitor, yet

" arriving here, we need to determine the bandwidth of these covert channel
" events and possible audit or delay

	read_clock
	sbaq	pds$first_covert_event_time
	cmpaq	covert.big_time
	tpl	covert.reset_clock		time too great to count
	div	sst|sst.seg_state_change_limit usecs/bit in q
	stq	temp			and temp
	mpy	sst|sst.audit_seg_state_change_bw
	cmpaq	covert.million
	tpl	covert.test_delay		usecs/bit*max_bps<1000000

" audit here

	increment	sst|sst.audit_seg_state_chg
	tsx	.2ret,page_error$excessive_seg_state_chg

covert.test_delay:
	ldq	temp
	mpy	sst|sst.max_seg_state_change_bw
	cmpaq	covert.million
	tpl	covert.reset_clock		usecs/bit*max_bps<1000000

" delay process

	increment	sst|sst.delayed_seg_state_chg

	ldaq	covert.million
	div	sst|sst.max_seg_state_change_bw  desired usecs/bit
	sbq	temp			   delay as usecs/bit
	mpy	sst|sst.seg_state_change_limit   delay in aq
	staq	pds$first_covert_event_time	   temp storage
	adlaq	sst|sst.seg_state_chg_delay	" this isn't really correct,
				" this is how long we want to delay,
				" not how long we will - but it's not
				" worth metering the real delay
	staq	sst|sst.seg_state_chg_delay

	read_clock			set time to delay until
	adaq	pds$first_covert_event_time	see wait_return for use of time
	tra	covert.reset

covert.reset_clock:
	read_clock
covert.reset:
	staq	pds$first_covert_event_time
	lca	sst|sst.seg_state_change_limit
	sta	pds$covert_event_count
	tra	0,.ret

	even
covert.big_time:
	oct	0,377777777777
covert.million:
	dec	0,1000000
"
"
"	Page had non-null add type. Must actually read page in.
"	PTW is in A register.
"

must_read:
	sta	devadd		save device address in stack


	tsx	.ret,get_pvtx	get segment pvtx for fault

read.must_rd.merge:
	tsx	.ret,device_control$check_ckdv  see if checking device incomplete
	tsx	.ret,store_pattern	if so, store pattern

"
"	Set up os bit before storing ptwp in cme, so page goes back in pc_r_sst.
"
	lca	cme.io+1,dl	set io flag to "read"
	ansa	cme_flags,*.cme

	lda	ptw.os,dl		turn it on
	orsa	ptw|0

	stx	.ptw,cme_ptwp,*.cme


	lda	core_add		set up ptw afresh
	als	coreadd_to_ptw.ls
	ora	add_type.core,dl
	staddra	ptw|0		put in coreadd

	tsx	.ret,thread_out	OS out of list

	lda	int+pri,dl	(almost) always interrupt on reads
	sta	inter
	tsx	.ret,device_control$dev_read  read the page into core
	eaa	0,.ptw		ptw is he wait event
	tra	unsavex		wait this event
"
"
"	Peculiar exits of read_page
"

read_page.oodev:			"out of physical volume.
				"Signal a segfault.
	increment	sst|sst.oopv	meter

	lda	aste.pack_ovfl,dl	turn on aste bit
	orsa	ast|aste.pack_ovfl_word,.aste	in AST

	szn	entry_sw		better be a page_fault
	tze	*+2
	tsx5	page_fault_error	"ERROR - OOPV ON READ_PAGE CALL"
create_segment_fault:
	eppap	pds$page_fault_data	address mc
	lda	ap|mc.scu.apu_stat_word
	cana	scu.apu.dsptw,dl	is this ds fault?
	tze	*+2
	tsx5	page_fault_error	"ERROR - SETFAULT DESCRIPTOR SEGMENT"

	lxl	.tem,ap|mc.scu.cu_stat_word was it IF?
	canx	.tem,scu.cu.if,du
	tnz	*+2
	lda	ap|mc.scu.tpr.tsr_word get TSR if not IF
	als	1		double segno
	ana	=o177776,du

	iftarget	l68	" On Level 68 only, must also set df_no to zero
	  lcq	sdw.valid+sdw.df_no_mask+1,dl
	ifend
	iftarget	adp
	  lcq	sdw.valid+1,dl
	ifend

	ansq	dseg$,au
	tsx	.ret,cam_cache$cam
	tra	quit		seg mover will handle

"
" " " " " " " " " " " " " " " " " " " " " " " " " " "
"					  "
"	disk_offlinep			  "
"					  "
"	Is the seg's disk offline?		  "
"					  "
"	tsx	.ret,disk_offlinep		  "
"	 tra	yes, event in A		  "
"	null	no			  "
"					  "
" " " " " " " " " " " " " " " " " " " " " " " " " " "

disk_offlinep:
	tsx	.2ret,savex
	tsx	.ret,get_pvtx
	tsx	.ret,device_control$disk_offlinep
	 tra	*+2		offline
	tra	unsavex_1		not offline

	lca	ptw.er+1,dl	turn OFF the error bit. This is
	ansa	ptw|0		so that when the guy tries again
				"when the disk finally comes back,
				"the next call to disk_offlinep
				"doesnt cause a signal.
	lda	disk_offline_event
	tra	unsavex

disk_offline_event:
	aci	"dskw"
"
"
"	Check to see if page has allocation. Give one
"	if needed.
"
"	tsx7	check_allocation
"	<return in out of room on physical volume>
"	<return if must wait volmap event, event set in APTE>
"	<return if page has allocation>

check_allocation:
	lda	ptw|0		grab ptw
	cana	add_type.core,dl
	tze	*+2		make sure we're doing this right
	tsx5	page_fault_error	"ERROR - CORE ADDR IN PTW: READ_PAGE"
	cana	   add_type.disk,dl    " real devadd?
	tnz	2,.ret		yes, that's fine.

	stx	.aste,pageno	ASTE offset
	eax	.tem,-aste_size,.ptw
	sblx	.tem,pageno	Page number
	eaq	0,.tem
	qrl	18
	stq	pageno
	ldq	ast|aste.vtocx,.aste
	anq	-1,dl		VTOCE Index
	stq	vtocx

	tsx	.2ret,savex	enter free_store
	tsx	.ret,get_pvtx	get pvtx
	tsx	.ret,free_store$withdraw  get an address
	 tra	unsavex		OOPV
	 tra	unsavex_1		volmap wait event

"
"	Put nulled address where null one was. With respect to pc_recover_sst,
"	this is all the same.
"
	lda	devadd
	ora	ptw.nulled,du	this is semikilled address
	sta	devadd

	staddra	ptw|0		put in new address
unsavex_2:
	ldx	.ret,stackp,di
	tra	2,.ret		return
"
" " " " " " " " " " " " " " " " " " " " " " " " " " " " " " "
"
"	find_core_
"
"	Subroutine to find a block of free core.
"
"	Call is:
"		tsx7 page_fault$find_core_
"
"		tsx7 find_core
"
" " " " " " " " " " " " " " " " " " " " " " " " " " " " " " "

	equ	pre_seek_limit,15	" Mod failure detection

find_core_:			" Externally available to ALM PC

find_core:
	tsx	.2ret,savex	save index 7
	increment	sst|sst.needc	meter times core was needed
	lca	1,du		init ctr for out-of-core to -2**18
	sta	total_steps
fploop:
	stz	count		zero count of steps
	lca	pre_seek_limit,dl	initialize mod failure ctr
	sta	temp1
	ldx	.cme,sst|sst.usedp	set cmep 

"     re-entry from find_core.ptw_ng and find_core.skip_meter_mod

fc1:
	lda	cme_flags,*.cme	check for total acceptability
	cana	cme.removing+cme.abs_w,dl
	tnz	find_core.cme_ng	something unusable- meter & skip

	ldx	.ptw,cme_ptwp,*.cme	Is core free? Set ptp.
	tze	found_core	yes, take it.
	epp	ptw,sst|0,.ptw	point at ptw
	lda	ptw|0		let's examine the ptw...

	cana	ptw.phu+ptw.wired+ptw.os+ptw.phm+ptw.phm1,dl	" make quick check
	tnz	find_core.ptw_ng	something in ptw is unacceptable.

	ldx	.tem,cme_pin_counter,*.cme
	tpnz      find_core.skip_pinned  do not evict if still pinned

"
"	Now attempt to evict the page.
"
"
"
"	Here is where access is taken off for a potential eviction.
"	If we lose timing window, access comes back.  Note that core address
"	in PTW stays valid until cleanup_page has run, and contents of
"	core page can be ignored (we are sure page is pure).

	lca	ptw.valid+1,dl	set directed fault 1 in ptw
	ansa	ptw|0		..
	lda	ptw|0		make sure coreadd gets set
	ana	ptw_add_mask,du	" Mask off all but the page address bits
	arl	ptw_to_coreadd.rl	" Clear the right place in the cache
	sta	core_add		..

	lxl	.aste,cme_astep,*.cme " get astep
	tsx	.2ret,check_accessible	" CAM if needed
	tsx	.ret,cam_cache$cam_cache " make sure the access gets turned off

	lda	ptw|0		retrieve ptw for modified bit test
	cana	ptw.phm+ptw.phm1+ptw.wired,dl has the page been modified now? or wired?
	tnz	restore_ptw_access	appear to have lost race

	stx	.cme,sst|sst.usedp	this frame now LRU
	tsx	.ret,cleanup_page	evict the page

found_core:
	increment	sst|sst.steps	meter
	ldx	.tem,cme_fp,*.cme move to MRU
	stx	.tem,sst|sst.usedp
	tra	unsavex		find_core returns
"
"
"	PTW has some kind of unacceptable state: possibilities:
"
"   1.	out of service-		illegal- crash system
"   2.	wired-			skip and meter
"   3.	modified-			leave alone for claim_m_c to evict/unuse.
"   4.	nypd-			leave alone for c_m_c to write to pd if unused.
"   5.	used-			"unuse" for replacement algorithm.

find_core.ptw_ng:
	cana	ptw.os,dl		this ought not be..
	tze	*+2
	tsx5	page_fault_error	"ERROR - FINDCORE FINDS OS ON LIST

	cana	ptw.phm+ptw.phm1,dl	has it been modified?
	tnz	find_core.skip_meter_mod must be written, can't take.
				"don't care whether used or not -must leave
				"both bits for c_m_c, who will off them.

	cana	ptw.wired,dl	is it wired?
	tnz	find_core.skip_wired
"
"	Must be used, skip and meter, impl. replacement algorithm
"	by turning bit off.
"
	increment	sst|sst.skipu	count used.
	lca	ptw.phu+1,dl	turn off phu bit in PTW
	ansa	ptw|0
	lda	ptw.phu1,dl	turn PHU1 ON in PTW
	orsa	ptw|0

skip:
	ldx	.cme,cme_fp,*.cme	go to next core map entry in list
	increment	sst|sst.steps	count step
	aos	total_steps	up count of steps taken looking for core
	tmi	fc1		if still neg, loop on.
	tra	page_error$out_of_core Multics not in operation.


restore_ptw_access:			"come here when 2nd cpu mod in window
	lda	ptw.valid,dl		remove directed fault from ptw
	orsa	ptw|0		..
find_core.skip_meter_mod:
	increment	sst|sst.skipm	count skip mod
cmod1:	increment	sst|sst.steps
	ldx	.tem,cme_fp,*.cme	pt at next cme
	cmpx	.tem,sst|sst.usedp	have we walked whole queue?
	tze	mods_excessive	will run claim_mod_core on whole mem
	eax	.cme,0,.tem	go to next cme
	aos	temp1		see if too many skipmods
	tpl	mods_excessive	too many
	tra	fc1

find_core.skip_pinned:
	increment sst|sst.fc_skips_pinned  no. of pin skips in find_core
	ldx	.tem,cme_pin_counter,*.cme
	sblx	.tem,1,du
	tmi	skip		never happen
	stx	.tem,cme_pin_counter,*.cme
	tra       skip


"
"
"	cme is unacceptable- following may be the case:
"
"   1.	removing		can't page in, must not be used. skip.
"   2.	abs_w		IN PROCESS of being abs-wired.. may not
"			page in evict_page will do it by special means,
"			must avoid getting vol map in here by accident.

find_core.cme_ng:

	cana	cme.abs_w,dl	abs wiring?
	tze	skip		no, just skip.

find_core.skip_wired:
	increment	sst|sst.skipw
	tra	skip		..

"
"	We arrive here when an excess of skips-mod have been made.
"	Potentially, every page in core can be mod and used. Hence,
"	tentatively, the fast find_core has failed. Do it the old way.
"
mods_excessive:
	stx	.cme,sst|sst.usedp save ptr to NEXT cme
	increment	sst|sst.pre_seeks_failed	meter
	tsx	.ret,claim_mod_core	do writes, may even post.
	tra	fploop		restart find_core_

"
""""""""""""""""""""""""""""""""""""""""""""""""""
"					"
"	Subroutine to evict one		"
"	page from core.			"
"					"
""""""""""""""""""""""""""""""""""""""""""""""""""

cleanup_page:
	tsx	.2ret,savex
	lxl	.aste,cme_astep,*.cme get astep

"
"	Unbind core from ptw here. For validity of pc_recover_sst, this
"	must be done in the following order:
"		Put non-core address back in ptw
"		cme.ptwp <= 000000
"		Clean up cme
"
	lda	cme_devadd,*.cme clear out ptw
	staddra	ptw|0

	lda	ast|aste.np_word,.aste subtract from count of pages in core
	sbla	1,dl
	era	ast|aste.np_word,.aste
	ana	aste.np_mask,dl
	ersa	ast|aste.np_word,.aste
	lda	ast|aste.np_word,.aste
	cana	aste.np_mask,dl	see if any pages left in core
	tnz	cleanup.np_nonzero	yes, continue

	lda	aste.init,du	no, turn init bit ON in ASTE
	ora	ast|aste.init_word,.aste	..
	sta	ast|aste.init_word,.aste  gtus is in same word, so...
	cana	aste.gtus,du	check gtus. If on, leave dtu alone
	tnz	cleanup.np_nonzero  nothing to do

	read_clock		get time
	lls	20		convert to fstime in A
	sta	ast|aste.dtu,.aste	and drop it in

cleanup.np_nonzero:
	tsx	.ret,check_synch_cleanup do housekeeping for synchronized page
	lda	ptw|0		if not live address, must adjust quota...
	cana	add_type.non_null,dl and records_used.
	tze	cleanup.rsq	null, reset recs.
	cana	ptw.nulled,du	is it nulled?
	tze	cleanup.nrsq1	not nulled, don't reset.
cleanup.rsq:
	tsx	.ret,update_csl	make sure csl is correct
	lda	ast|aste.records_word,.aste
	ana	aste.records_mask_inner,dl
	sbla	=o001000,dl	decrement records used
	tpl       cleanup.recused_okay
	szn	pvt$esd_state
	tnz	cleanup.recused_okay
	tsx5	page_fault_error	"ERROR - RECUSED WENT NEG: CLEANUP"
cleanup.recused_okay:
	era	ast|aste.records_word,.aste
	ana	aste.records_mask_inner,dl
	ersa	ast|aste.records_word,.aste
	tsx	.ret,reset_quota	deduct a quotum used
cleanup.nrsq1:
	eax	.tem,0		zero ptw correspondence
	stx	.tem,cme_ptwp,*.cme ..
	sxl	.tem,cme_astep,*.cme zero astep correspondence too
	tsx	.ret,thread_to_lru	move to head of list
	lca	ptw.phm+ptw.phm1+1,dl	" turn off mod
	ansa	ptw|0
	tra	unsavex
"
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
"						"
"						"
"	claim_mod_core				"
"						"
"	Tsx	.ret,claim_mod_core to sweep		"
"			up all the writes that	"
"			find_core chose not to do.	"
"						"
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

claim_mod_core:
	tsx	.2ret,savex	save return
	increment	sst|sst.write_hunts	meter

mc_continue:
	ldx	.cme,sst|sst.wusedp	start at last point

mclp:	cmpx	.cme,sst|sst.usedp	are we up to find_core?
	tze	cl_done
	increment	sst|sst.claim_steps	meter steps

	lda	cme_flags,*.cme look at cme
	cana	cme.removing+cme.abs_w,dl	   " check unacceptable states
	tnz	cl_bad

	ldx	.ptw,cme_ptwp,*.cme point to ptw
	tze	cl_free		this is really bad, for
				"this cme should be
				"in front of usedp.
	epp	ptw,sst|0,.ptw	point to ptw

	lda	ptw|0		consider ptw
	cana	ptw.os+ptw.wired,dl
	tnz	cl_ptwbad
	cana	ptw.phm+ptw.phm1,dl 	" we only care about those f_c_ skipped
	tze	cl_notmod

	cana	ptw.phu,dl	see if used
	tnz	cl_used		turn off used if on

	ldx	.tem,cme_pin_counter,*.cme see if page is pinned
	tpnz      cl_pinned

	increment	sst|sst.claim_writes meters
	ldx	.tem,cme_fp,*.cme peek ahead to next cme
	stx	.tem,sst|sst.wusedp	save pointer

	lxl	.aste,cme_astep,*.cme pick up astep
	tsx	.ret,write_page	write_page will do all necessary
	tra	mc_continue

mc_end:	ldx	.cme,cme_fp,*.cme scan on into map
	tra	mclp

cl_bad:
	increment	sst|sst.claim_skip_cme	A CME had permanent unacceptable state, or RWS
	tra	mc_end

cl_ptwbad:
	increment	sst|sst.claim_skip_ptw	PTW wired
	tra	mc_end

cl_free:
	increment	sst|sst.claim_skip_free	A CME was free to claim_mod_core
	tra	mc_end

cl_notmod:
	increment	sst|sst.claim_notmod	not modified, not interesting
	tra	mc_end

cl_used:
	lcq	ptw.phu+1,dl		mod, but used.
	ansq	ptw|0			turn off used and pray for cam.
	ldq	ptw.phu1,dl		dont screw up working sets
	orsq	ptw|0
	increment	sst|sst.claim_passed_used
	tra	mc_end

cl_pinned:
	increment sst|sst.cl_skips_pinned  no. of pin skips in claim_mod
"				cme_pin_counter in x0
	sblx	.tem,1,du
	tmi	mc_end		never happen
	stx	.tem,cme_pin_counter,*.cme
	tra       mc_end

cl_done:
	stx	.cme,sst|sst.wusedp
	tra	unsavex
"
" " " " " " " " " " " " " " " " " " " " " " " " " " " " " " "
"
"	write_page
"
"	Subroutine to check to see a page should be written out.
"	If so, initiate the I/O.
"
" " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " "

write_page:
"
"	Page has been modified
"
	tsx	.2ret,savex	recursive use of .ret
	tsx	.ret,get_pvtx	get pvtx from AST
	tsx	.ret,pc_trace$write_page
	eaa	0,.cme		compute core_add from cmep
	sbla	sst|sst.cmp+1
	arl	cmep_to_coreadd.rl	..
	sta	core_add
	lda	cme_devadd,*.cme save devadd in stack
	sta	devadd		..

	lda	ptw|0		inspect ptw
	cana	ptw.os,dl		check for o/s
	tze	*+2
	tsx5	page_fault_error	"ERROR - WRITE CALL ON OS PAGE"
	cana	ptw.phm+ptw.phm1,dl 	" if neither on, obsolete call
	tze	unsavex


	lxl	.tem,ast|aste.par_astep,.aste	dont update if no parent
	tze	write.dont_set_fms

	ldq	ast|aste.gtms_word,.aste	check global-transparent-modified-switch
	canq	aste.gtms,du
	tnz	write.dont_set_fms	if on, don't set fms

	cana	ptw.phm,dl	was fms set by pc$update_incore_fms?
	tze	write.dont_set_fms	yes, don't set it

	eax	.tem,0,.aste	copy AST parent to x0 (first time is AST)
	read_clock		get current time
	lrs	16		convert to fstime in Q
	lda	aste.fms,du	get set to turn on all superior fms's

write.set_parent_fms:
	orsa	ast|aste.fms_word,.tem
	stq	ast|aste.dtm,.tem	set dtm as well
	lxl	.tem,ast|aste.par_astep,.tem
	tnz	write.set_parent_fms

write.dont_set_fms:
	tsx	.2ret,set_up_abs_seg abs_seg1 -> page in memory, ap -> abs_seg1
	tsx	.ret,check_for_synch_hold synchronized page, not to be written
	tra	unsavex		yes - don't write

	szn	tc_data$system_shutdown  don't null pages during shutdown
	tnz	page_non_zero	yes, pretend page non-zero(don't deposit anything)
	ldq	ast|aste.dnzp_word,.aste don't null if special flag set
	canq	aste.dnzp,du	..
	tnz	page_non_zero

	lda	ptw|0		Don't null wired pages.
	cana	ptw.wired,dl
	tnz	page_non_zero

	tsx	.ret,check_for_zero	test for a zero page
	tra	page_non_zero	return here if really not zero
	lca	ptw.valid+1,dl	set directed fault 1 in ptw
	ansa	ptw|0		..

	tsx	.2ret,check_accessible	" only CAM if needed
	tsx	.ret,cam_cache$cam_cache make sure people see it

	tsx	.ret,check_for_zero	try again after turning off access
	tra	page_non_zero_a	he just modified it before we zapped access, phooey
"
"	page was all zeroes
"
	increment	sst|sst.zero_pages
	tsx	.ret,pc_trace$zero_page


	lda	ptw.nulled,du	null the disk addr in cme.
	orsa	cme_devadd,*.cme

	lda	aste.fmchanged,du	turn on map changed bit
	orsa	ast|aste.fmchanged_word,.aste
	tsx	.ret,cleanup_page	evict page from core, turns off phm.
	tra	unsavex
" 
"	come here because the page is non-zero and must be written out
"

page_non_zero_a:
	lda	ptw.valid,dl		remove directed fault from ptw
	orsa	ptw|0		..
page_non_zero:
	lda	cme_devadd,*.cme
	cana	add_type.non_null,dl is it real null?
	tnz	write.pnz.to_disk

"
"	Was a real null address- this must not be so at this point!!!
"
write.nz.was_real_null:
"
	tsx5	page_fault_error	"ERROR - NO ALLOCATION AT WRITE TIME"



write.pnz.to_disk:
	lda	unnull_mask	unnull, but not in core map
	ansa	devadd

"
"
"	Actually set up like we're gonna write.
"	Recovery strategy requires cme.io set before os set.
"

do_write:
	tsx	.ret,thread_out	OS out of list

	lda	cme.io,dl		turn on write bit in CME
	orsa	cme_flags,*.cme ..

	lda	ptw.os,dl		set ptw out of service
	orsa	ptw|0

	lca	ptw.phm+ptw.phm1+1,dl turn it off once ptw.os is on.
	ansa	ptw|0

	tsx	.2ret,check_accessible	" if needed:
	tsx	.ret,cam_cache$cam_ptws	turn it off on all cpus.

do_write.not_mod:
	stz	inter		generally don't interrupt on writes
	lda	entry_sw		see if write entry
	cmpa	write_entry,dl
	tnz	do_write.not_pri	not, continue

	lda	int+pri,dl	interrupt on write entry
	sta	inter
do_write.not_pri:
	tsx	.ret,device_control$dev_write  initiate the write
	tra	unsavex

"
" " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " "
"
"	done,done_
"
"	Entry (subroutine) to post the completion of I/O.
"	Call is
"		call done(core_add,errcode)
"	or
"		tsx7 done_
"
" " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " "

done:
	tra	core_queue_man$disk_post


done_:
	eppbb	sst$		bb must point into SST for PAGE
	tsx	.2ret,savex	save return loc in stack
	lda	core_add		get core map entry pointer
	als	coreadd_to_cmep.ls
	eax	.cme,sst|sst.cmp,*au  set up .cme

	tsx	.ret,pc_trace$done
"
"	Flags to A-reg until we know where we're headed.
"
	lxl	.tem,cme_astep,*.cme save astep for later
	stx	.tem,done_astep

	lda	cme_flags,*.cme see if a read/write sequence is active

	ldq	cme_devadd,*.cme pick up device address out of CM entry
	stq	devadd		and save in stack

	ldx	.ptw,cme_ptwp,*.cme	get ptp
	tze	page_error$error_in_done  core must be used
	eppbp	sst|0,.ptw
	lxl	.tem,ptw|0	check for out of service
	canx	.tem,ptw.os,du
	tze	page_error$error_in_done
	lxl	.aste,cme_astep,*.cme get astep

	cana	cme.io,dl		Was this a write?
	tnz	done_write	yes, go handle it
	"tra	done_read		*** is on the next page ***
"
"	done_read -- thread core in mru, 
"		   and turn on PTW access.
"

done_read:
	tsx	.ret,thread_in_mru	make most recently used

	szn	errcode		check error code
	tnz	error_on_read	error ...
"
"	Check for device incomplete
"
	tsx	.ret,device_control$check_ckdv
	 tsx	.ret,check_pattern	dvctl returns here if checking on
	  tra	done.read.no_ckdv_error c_p comes here if no error.
				   "also, dvctl comes here if not checking!
	tsx	.2ret,page_error$device_error
	tra	error_on_read	treat as fatal error

done.read.no_ckdv_error:
	lda	ptw.valid+df1,dl	turn on access
	orsa	ptw|0
	lca	ptw.os+1,dl	turn off os bit
	ansa	ptw|0

"	tra	notify_code	" (Actually, just fall through to this)
"
"

"
"
"	Post a read or write complete, with or without error.
"	Call handler for I/O to volmap_seg.
"	Cause a page faulter to restart his fault, and cause
"	call side to retry.
"
notify_code:
"
"	Check for notify_requested. If none, neither notify
"	nor idle pre_empt.
"
	lda	cme.notify_requested,dl	get flag
	cana	cme_flags,*.cme	see if on in cme
	tze	notify_end	no, just return
	ersa	cme_flags,*.cme	was on. Turn off and
				"notify/preempt.
done.notify.uncond:
	szn	tc_data$pre_empt_flag  see if we're pre-empting (and notifying)
	tnz	check_idle	we're not pre-empting. are we an idle process ?
	eaq	0,.ptw		get event from ptw addr
	qrl	18
	stq	pds$arg_1		save argument
	tra	pxss$page_notify

	entry	notify_return
notify_return:
	epp	sst,sst$		restore sst pr, possibly for done_ entry.
notify_end:
	ldx	.tem,done_astep	astep
	lda	sst|aste.volmap_seg_word,.tem see if this is a volmap_seg
	cana	aste.volmap_seg,dl
	tze	unsavex		no - return to the caller of done
	lda	sst|aste.pvtx_word,.tem
	arl	aste.pvtx_shift
	ana	aste.pvtx_mask,dl	pvtx in Areg
	tsx	.ret,volmap_page$post_io	do asynchronous stuff
	epp	sst,sst$		restore
	tra	unsavex		return to caller of done

check_idle:
	ldaq	pds$apt_ptr	see if we're an idle process
	cmpaq	prds$idle_ptr
	tnz	notify_end	no, just return
	lda	apte.pre_empt_pending,du
	eppbp	pds$apt_ptr,*
	orsa	bp|apte.flags
	lxl1	prds$processor_tag
	stc2	pds$connect_pending
	cioc	scs$cow_ptrs,1*
	tra	notify_end
"
"
"	error_on_read - put Pdisk address back in PTW
"

error_on_read:
	increment	sst|sst.page_read_errors	meter
	tsx	.ret,cleanup_page	out of core

	lca	ptw.os+1,dl	Now oocore, off os.
	ansa	ptw|0

	lda	ptw.er,dl		mark ptw as signalable
	orsa	ptw|0
	tsx	.ret,get_pvtx
	tsx	.ret,call_disk_emergency
	tra	done.notify.uncond
"
"
"	done_write - remove O/S status, 
"		   and thread core in LRU.
"

done_write:

	lca	1,dl		decrement global count of writes.
	asa	sst|sst.wtct
	tpl	*+2
	stz	sst|sst.wtct	make sure stays +.

	lda	ptw.phm+ptw.phu,dl	count uses of pages being written
	cana	ptw|0		..
	tze	*+2		not used, don't count
	increment	sst|sst.mod_during_write
	lca	ptw.os+ptw.er+1,dl	turn off OS and ERR flags.
	ansa	ptw|0
	lda	ptw.valid,dl	turn access on - it's off for synch pages
	orsa	ptw|0

	ldq	errcode		if error, go process it, passing
	tnz	error_on_write	error code in Q.

	lca	cme.phm_hedge+1,dl turn off write
	ansa	cme_flags,*.cme scheduler and pd_upflag

"
resurgo:
	lda	cme_devadd,*.cme
	cana	ptw.nulled,du	is this null?
	tze	rethread		no, ordinary write.
	era	ptw.nulled,du
	sta	cme_devadd,*.cme
	increment	sst|sst.resurrections	meter
resurgo.fmchanged:
	lda	aste.fmchanged,du	turn on fmc bit
	orsa	ast|aste.fmchanged_word,.aste
no_dblw:
rethread:
	tsx	.ret,thread_in	insert in core map at lru
	tra	notify_code	and notify waiting processes
"
"
"	error_on_write - Zero data if data error,
"		       but leave in core as modified if device inop.
"

error_on_write:	"errcode passed in Q.
	increment	sst|sst.page_write_errors meter

	canq	errflags.memory_unusable,dl	page damage or mem problem
	tnz	done.werr.deverr		


"			not pd case- analyze errcode
	canq	errflags.device_inoperative,dl	disk down?
	tnz	write_device_inop	yes, handle it

"
"	Must be data error on write
done.werr.deverr:
"
	lda	aste.damaged,dl
	orsa	ast|aste.damaged_word,.aste
	lda	aste.fmchanged,du	cause vtoce update
	orsa	ast|aste.fmchanged_word,.aste

	tsx	.ret,thread_in	get core in list
	lca	ptw.valid+1,dl	turn off access
	ansa	ptw|0
	tsx	.ret,cam_cache$cam_cache
	tsx	.ret,cleanup_page	drive guy out of core

	lda	ptw.er,dl
	orsa	ptw|0
"
"	Try for an older copy of the page in any case.
"
	eax	.ret,page_error$reverting_page assume some stuff out there
	lda	cme_devadd,*.cme get diskaddr or pdaddr
	cana	add_type.non_null,dl any good stuff atall?
	tnz	done.werr.deverr.printerr ptw ok

	eax	.ret,page_error$zeroing_page
	ldq	errcode		see what case
	lda	page_bad_null,du	assume device lossage
	canq	errflags.memory_unusable,dl
	tze	*+2
	lda	page_devparity_null,du parity case
	staddra	ptw|0		in the ptw
done.werr.deverr.printerr:
	tsx	.ret,0,.ret	print barfage
	lda	errcode		do we have to make main mem vanish?
	cana	errflags.memory_unusable,dl
	tze	done.notify.uncond	exit

	tsx	.ret,delete_mm_frame delete this frame of main mem
	tra	done.notify.uncond
		"cme has been freed, don't know whether
		"to notify or not, so do it.

write_device_inop:
	tsx	.ret,get_pvtx
	tsx	.ret,call_disk_emergency

	lda	ptw.phm1,dl	turn mod bit back on
	orsa	ptw|0

finish_write_error:
	tsx	.ret,thread_in_mru avoid repl algorithm
	tra	notify_code



"
"
"	Clear out and deconfigure main memory frame.
"
delete_mm_frame:
	tsx	.2ret,savex
	tsx	.ret,thread_out	good move
	lca	1,dl		just zap first word
	sta	cme_0,*.cme
	asa	sst|sst.nused	it's not used.
	tsx	.ret,page_error$deleting_mm_frame annuntio
	tra	unsavex

"
"	Subroutine to call disk_emergency on disk-errors,
"	So that he might make assessments of system-wide
"	implications of disk device status.

call_disk_emergency:
	sta	pvtx		pvtx in a-reg
	eppap	pvtx
	spriap	arg+2
	eppap	errcode
	spriap	arg+4
	ldaq	=v18/4,18/4,36/0
	staq	arg
	call	disk_emergency$disk_emergency(sp|arg)
	tra	0,.ret


	end
